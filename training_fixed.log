nohup: ignoring input
[0;34m========================================[0m
[0;34mGo1 Walking Policy Training[0m
[0;34m========================================[0m

[0;32mActivating conda environment...[0m

[0;32mTraining Configuration:[0m
  Task: Isaac-Velocity-Rough-Unitree-Go1-v0
  Number of Environments: 4096
  Max Iterations: 500
  Mode: Headless

[0;32mStarting training...[0m
[1;33mPress Ctrl+C to stop training[0m

[3gH    H    H    H    H    H    H    H    H    H    H    H    H    H    H    H    H    H    H    H   [INFO] Using python from: /home/maxime/miniconda3/envs/env_isaaclab/bin/python
Loading user config located at: '/home/maxime/miniconda3/envs/env_isaaclab/lib/python3.11/site-packages/isaacsim/kit/data/Kit/Isaac-Sim/5.1/user.config.json'
[Info] [carb] Logging to file: /home/maxime/miniconda3/envs/env_isaaclab/lib/python3.11/site-packages/isaacsim/kit/logs/Kit/Isaac-Sim/5.1/kit_20251116_171750.log
2025-11-17T01:17:50Z [109ms] [Warning] [omni.usd_config.extension] Enable omni.materialx.libs extension to use MaterialX
2025-11-17T01:17:51Z [410ms] [Warning] [omni.platforminfo.plugin] failed to open the default display.  Can't verify X Server version.
2025-11-17T01:17:51Z [552ms] [Warning] [carb] Acquiring non optional plugin interface which is not listed as dependency: [omni::physx::IPhysxBenchmarks v1.0] (plugin: <default plugin>), by client: omni.physics.physx.plugin. Add it to CARB_PLUGIN_IMPL_DEPS() macro of a client.
2025-11-17T01:17:51Z [755ms] [Warning] [omni.isaac.dynamic_control] omni.isaac.dynamic_control is deprecated as of Isaac Sim 4.5. No action is needed from end-users.

|---------------------------------------------------------------------------------------------|
| Driver Version: 580.95.05     | Graphics API: Vulkan
|=============================================================================================|
| GPU | Name                             | Active | LDA | GPU Memory | Vendor-ID | LUID       |
|     |                                  |        |     |            | Device-ID | UUID       |
|     |                                  |        |     |            | Bus-ID    |            |
|---------------------------------------------------------------------------------------------|
| 0   | NVIDIA RTX A4500                 | Yes: 0 |     | 20716   MB | 10de      | 0          |
|     |                                  |        |     |            | 2232      | 29db3550.. |
|     |                                  |        |     |            | 1         |            |
|---------------------------------------------------------------------------------------------|
| 1   | NVIDIA RTX A4500                 | Yes: 1 |     | 20716   MB | 10de      | 0          |
|     |                                  |        |     |            | 2232      | cea0e031.. |
|     |                                  |        |     |            | 2b        |            |
|---------------------------------------------------------------------------------------------|
| 2   | NVIDIA RTX A4500                 | Yes: 2 |     | 20716   MB | 10de      | 0          |
|     |                                  |        |     |            | 2232      | 625bf251.. |
|     |                                  |        |     |            | 41        |            |
|---------------------------------------------------------------------------------------------|
| 3   | NVIDIA RTX A4500                 | Yes: 3 |     | 20716   MB | 10de      | 0          |
|     |                                  |        |     |            | 2232      | 1accb290.. |
|     |                                  |        |     |            | 61        |            |
|=============================================================================================|
| OS: 24.04.3 LTS (Noble Numbat) ubuntu, Version: 24.04.3, Kernel: 6.14.0-35-generic
| Processor: AMD Ryzen Threadripper PRO 5995WX 64-Cores
| Cores: 64 | Logical Cores: 128
|---------------------------------------------------------------------------------------------|
| Total Memory (MB): 257521 | Free Memory: 242655
| Total Page/Swap (MB): 8191 | Free Page/Swap: 8191
|---------------------------------------------------------------------------------------------|
2025-11-17T01:17:57Z [6,744ms] [Warning] [gpu.foundation.plugin] CPU performance profile is set to powersave. This profile sets the CPU to the lowest frequency reducing performance.
2025-11-17T01:17:57Z [6,787ms] [Warning] [gpu.foundation.plugin] IOMMU is enabled.
2025-11-17T01:17:57Z [6,787ms] [Warning] [gpu.foundation.plugin] Detected IOMMU is enabled. Running CUDA peer-to-peer bandwidth and latency validation.
Cuda failure ../../../sou[INFO][AppLauncher]: Using device: cuda:0
[INFO][AppLauncher]: Loading experience file: /home/maxime/IsaacLab-main/apps/isaaclab.python.headless.kit
[INFO]: Parsing configuration from: isaaclab_tasks.manager_based.locomotion.velocity.config.go1.rough_env_cfg:UnitreeGo1RoughEnvCfg
[INFO] Logging experiment in directory: /home/maxime/IsaacLab-main/logs/rsl_rl/unitree_go1_rough
[INFO] Environment Configuration:
        viewer: 
            eye: (7.5, 7.5, 7.5)
            lookat: (0.0, 0.0, 0.0)
            cam_prim_path: /OmniverseKit_Persp
            resolution: (1280, 720)
            origin_type: world
            env_index: 0
            asset_name: None
            body_name: None
        sim: 
            physics_prim_path: /physicsScene
            device: cuda:0
            dt: 0.005
            render_interval: 4
            gravity: (0.0, 0.0, -9.81)
            enable_scene_query_support: False
            use_fabric: True
            physx: 
                solver_type: 1
                min_position_iteration_count: 1
                max_position_iteration_count: 255
                min_velocity_iteration_count: 0
                max_velocity_iteration_count: 255
                enable_ccd: False
                enable_stabilization: False
                enable_enhanced_determinism: False
                bounce_threshold_velocity: 0.5
                friction_offset_threshold: 0.04
                friction_correlation_distance: 0.025
                gpu_max_rigid_contact_count: 8388608
                gpu_max_rigid_patch_count: 327680
                gpu_found_lost_pairs_capacity: 2097152
                gpu_found_lost_aggregate_pairs_capacity: 33554432
                gpu_total_aggregate_pairs_capacity: 2097152
                gpu_collision_stack_size: 67108864
                gpu_heap_capacity: 67108864
                gpu_temp_buffer_capacity: 16777216
                gpu_max_num_partitions: 8
                gpu_max_soft_body_contacts: 1048576
                gpu_max_particle_contacts: 1048576
                solve_articulation_contact_last: False
            physics_material: 
                func: isaaclab.sim.spawners.materials.physics_materials:spawn_rigid_body_material
                static_friction: 1.0
                dynamic_friction: 1.0
                restitution: 0.0
                friction_combine_mode: multiply
                restitution_combine_mode: multiply
                compliant_contact_stiffness: 0.0
                compliant_contact_damping: 0.0
            render: 
                enable_translucency: None
                enable_reflections: None
                enable_global_illumination: None
                antialiasing_mode: None
                enable_dlssg: None
                enable_dl_denoiser: None
                dlss_mode: None
                enable_direct_lighting: None
                samples_per_pixel: None
                enable_shadows: None
                enable_ambient_occlusion: None
                dome_light_upper_lower_strategy: None
                carb_settings: None
                rendering_mode: None
            create_stage_in_memory: False
            logging_level: WARNING
            save_logs_to_file: True
        ui_window_class_type: isaaclab.envs.ui.manager_based_rl_env_window:ManagerBasedRLEnvWindow
        seed: 42
        decimation: 4
        scene: 
            num_envs: 4096
            env_spacing: 2.5
            lazy_sensor_update: True
            replicate_physics: True
            filter_collisions: True
            clone_in_fabric: False
            robot: 
                class_type: isaaclab.assets.articulation.articulation:Articulation
                prim_path: {ENV_REGEX_NS}/Robot
                spawn: 
                    func: isaaclab.sim.spawners.from_files.from_files:spawn_from_usd
                    visible: True
                    semantic_tags: None
                    copy_from_source: True
                    mass_props: None
                    deformable_props: None
                    rigid_props: 
                        rigid_body_enabled: None
                        kinematic_enabled: None
                        disable_gravity: False
                        linear_damping: 0.0
                        angular_damping: 0.0
                        max_linear_velocity: 1000.0
                        max_angular_velocity: 1000.0
                        max_depenetration_velocity: 1.0
                        max_contact_impulse: None
                        enable_gyroscopic_forces: None
                        retain_accelerations: False
                        solver_position_iteration_count: None
                        solver_velocity_iteration_count: None
                        sleep_threshold: None
                        stabilization_threshold: None
                    collision_props: None
                    activate_contact_sensors: True
                    scale: None
                    articulation_props: 
                        articulation_enabled: None
                        enabled_self_collisions: False
                        solver_position_iteration_count: 4
                        solver_velocity_iteration_count: 0
                        sleep_threshold: None
                        stabilization_threshold: None
                        fix_root_link: None
                    fixed_tendons_props: None
                    spatial_tendons_props: None
                    joint_drive_props: None
                    visual_material_path: material
                    visual_material: None
                    usd_path: https://omniverse-content-production.s3-us-west-2.amazonaws.com/Assets/Isaac/5.1/Isaac/IsaacLab/Robots/Unitree/Go1/go1.usd
                    variants: None
                init_state: 
                    pos: (0.0, 0.0, 0.4)
                    rot: (1.0, 0.0, 0.0, 0.0)
                    lin_vel: (0.0, 0.0, 0.0)
                    ang_vel: (0.0, 0.0, 0.0)
                    joint_pos: 
                        .*L_hip_joint: 0.1
                        .*R_hip_joint: -0.1
                        F[L,R]_thigh_joint: 0.8
                        R[L,R]_thigh_joint: 1.0
                        .*_calf_joint: -1.5
                    joint_vel: 
                        .*: 0.0
                collision_group: 0
                debug_vis: False
                articulation_root_prim_path: None
                soft_joint_pos_limit_factor: 0.9
                actuators: 
                    base_legs: 
                        class_type: isaaclab.actuators.actuator_net:ActuatorNetMLP
                        joint_names_expr: ['.*_hip_joint', '.*_thigh_joint', '.*_calf_joint']
                        effort_limit: 23.7
                        velocity_limit: 30.0
                        effort_limit_sim: None
                        velocity_limit_sim: None
                        stiffness: None
                        damping: None
                        armature: None
                        friction: None
                        dynamic_friction: None
                        viscous_friction: None
                        saturation_effort: 23.7
                        network_file: https://omniverse-content-production.s3-us-west-2.amazonaws.com/Assets/Isaac/5.1/Isaac/IsaacLab/ActuatorNets/Unitree/unitree_go1.pt
                        pos_scale: -1.0
                        vel_scale: 1.0
                        torque_scale: 1.0
                        input_order: pos_vel
                        input_idx: [0, 1, 2]
                actuator_value_resolution_debug_print: False
            terrain: 
                class_type: isaaclab.terrains.terrain_importer:TerrainImporter
                collision_group: -1
                prim_path: /World/ground
                num_envs: 1
                terrain_type: generator
                terrain_generator: 
                    class_type: isaaclab.terrains.terrain_generator:TerrainGenerator
                    seed: None
                    curriculum: True
                    size: (8.0, 8.0)
                    border_width: 20.0
                    border_height: 1.0
                    num_rows: 10
                    num_cols: 20
                    color_scheme: none
                    horizontal_scale: 0.1
                    vertical_scale: 0.005
                    slope_threshold: 0.75
                    sub_terrains: 
                        pyramid_stairs: 
                            function: isaaclab.terrains.trimesh.mesh_terrains:pyramid_stairs_terrain
                            proportion: 0.2
                            size: (10.0, 10.0)
                            flat_patch_sampling: None
                            border_width: 1.0
                            step_height_range: (0.05, 0.23)
                            step_width: 0.3
                            platform_width: 3.0
                            holes: False
                        pyramid_stairs_inv: 
                            function: isaaclab.terrains.trimesh.mesh_terrains:inverted_pyramid_stairs_terrain
                            proportion: 0.2
                            size: (10.0, 10.0)
                            flat_patch_sampling: None
                            border_width: 1.0
                            step_height_range: (0.05, 0.23)
                            step_width: 0.3
                            platform_width: 3.0
                            holes: False
                        boxes: 
                            function: isaaclab.terrains.trimesh.mesh_terrains:random_grid_terrain
                            proportion: 0.2
                            size: (10.0, 10.0)
                            flat_patch_sampling: None
                            grid_width: 0.45
                            grid_height_range: (0.025, 0.1)
                            platform_width: 2.0
                            holes: False
                        random_rough: 
                            function: isaaclab.terrains.height_field.hf_terrains:random_uniform_terrain
                            proportion: 0.2
                            size: (10.0, 10.0)
                            flat_patch_sampling: None
                            border_width: 0.25
                            horizontal_scale: 0.1
                            vertical_scale: 0.005
                            slope_threshold: None
                            noise_range: (0.01, 0.06)
                            noise_step: 0.01
                            downsampled_scale: None
                        hf_pyramid_slope: 
                            function: isaaclab.terrains.height_field.hf_terrains:pyramid_sloped_terrain
                            proportion: 0.1
                            size: (10.0, 10.0)
                            flat_patch_sampling: None
                            border_width: 0.25
                            horizontal_scale: 0.1
                            vertical_scale: 0.005
                            slope_threshold: None
                            slope_range: (0.0, 0.4)
                            platform_width: 2.0
                            inverted: False
                        hf_pyramid_slope_inv: 
                            function: isaaclab.terrains.height_field.hf_terrains:pyramid_sloped_terrain
                            proportion: 0.1
                            size: (10.0, 10.0)
                            flat_patch_sampling: None
                            border_width: 0.25
                            horizontal_scale: 0.1
                            vertical_scale: 0.005
                            slope_threshold: None
                            slope_range: (0.0, 0.4)
                            platform_width: 2.0
                            inverted: True
                    difficulty_range: (0.0, 1.0)
                    use_cache: False
                    cache_dir: /tmp/isaaclab/terrains
                usd_path: None
                env_spacing: None
                use_terrain_origins: True
                visual_material: 
                    func: isaaclab.sim.spawners.materials.visual_materials:spawn_from_mdl_file
                    mdl_path: https://omniverse-content-production.s3-us-west-2.amazonaws.com/Assets/Isaac/5.1/Isaac/IsaacLab/Materials/TilesMarbleSpiderWhiteBrickBondHoned/TilesMarbleSpiderWhiteBrickBondHoned.mdl
                    project_uvw: True
                    albedo_brightness: None
                    texture_scale: (0.25, 0.25)
                physics_material: 
                    func: isaaclab.sim.spawners.materials.physics_materials:spawn_rigid_body_material
                    static_friction: 1.0
                    dynamic_friction: 1.0
                    restitution: 0.0
                    friction_combine_mode: multiply
                    restitution_combine_mode: multiply
                    compliant_contact_stiffness: 0.0
                    compliant_contact_damping: 0.0
                max_init_terrain_level: 5
                debug_vis: False
            height_scanner: 
                class_type: isaaclab.sensors.ray_caster.ray_caster:RayCaster
                prim_path: {ENV_REGEX_NS}/Robot/trunk
                update_period: 0.02
                history_length: 0
                debug_vis: False
                mesh_prim_paths: ['/World/ground']
                offset: 
                    pos: (0.0, 0.0, 20.0)
                    rot: (1.0, 0.0, 0.0, 0.0)
                attach_yaw_only: None
                ray_alignment: yaw
                pattern_cfg: 
                    func: isaaclab.sensors.ray_caster.patterns.patterns:grid_pattern
                    resolution: 0.1
                    size: [1.6, 1.0]
                    direction: (0.0, 0.0, -1.0)
                    ordering: xy
                max_distance: 1000000.0
                drift_range: (0.0, 0.0)
                ray_cast_drift_range: 
                    x: (0.0, 0.0)
                    y: (0.0, 0.0)
                    z: (0.0, 0.0)
                visualizer_cfg: 
                    prim_path: /Visuals/RayCaster
                    markers: 
                        hit: 
                            func: isaaclab.sim.spawners.shapes.shapes:spawn_sphere
                            visible: True
                            semantic_tags: None
                            copy_from_source: True
                            mass_props: None
                            rigid_props: None
                            collision_props: None
                            activate_contact_sensors: False
                            visual_material_path: material
                            visual_material: 
                                func: isaaclab.sim.spawners.materials.visual_materials:spawn_preview_surface
                                diffuse_color: (1.0, 0.0, 0.0)
                                emissive_color: (0.0, 0.0, 0.0)
                                roughness: 0.5
                                metallic: 0.0
                                opacity: 1.0
                            physics_material_path: material
                            physics_material: None
                            radius: 0.02
            contact_forces: 
                class_type: isaaclab.sensors.contact_sensor.contact_sensor:ContactSensor
                prim_path: {ENV_REGEX_NS}/Robot/.*
                update_period: 0.005
                history_length: 3
                debug_vis: False
                track_pose: False
                track_contact_points: False
                max_contact_data_count_per_prim: 4
                track_air_time: True
                force_threshold: 1.0
                filter_prim_paths_expr: []
                visualizer_cfg: 
                    prim_path: /Visuals/ContactSensor
                    markers: 
                        contact: 
                            func: isaaclab.sim.spawners.shapes.shapes:spawn_sphere
                            visible: True
                            semantic_tags: None
                            copy_from_source: True
                            mass_props: None
                            rigid_props: None
                            collision_props: None
                            activate_contact_sensors: False
                            visual_material_path: material
                            visual_material: 
                                func: isaaclab.sim.spawners.materials.visual_materials:spawn_preview_surface
                                diffuse_color: (1.0, 0.0, 0.0)
                                emissive_color: (0.0, 0.0, 0.0)
                                roughness: 0.5
                                metallic: 0.0
                                opacity: 1.0
                            physics_material_path: material
                            physics_material: None
                            radius: 0.02
                        no_contact: 
                            func: isaaclab.sim.spawners.shapes.shapes:spawn_sphere
                            visible: False
                            semantic_tags: None
                            copy_from_source: True
                            mass_props: None
                            rigid_props: None
                            collision_props: None
                            activate_contact_sensors: False
                            visual_material_path: material
                            visual_material: 
                                func: isaaclab.sim.spawners.materials.visual_materials:spawn_preview_surface
                                diffuse_color: (0.0, 1.0, 0.0)
                                emissive_color: (0.0, 0.0, 0.0)
                                roughness: 0.5
                                metallic: 0.0
                                opacity: 1.0
                            physics_material_path: material
                            physics_material: None
                            radius: 0.02
            sky_light: 
                class_type: None
                prim_path: /World/skyLight
                spawn: 
                    func: isaaclab.sim.spawners.lights.lights:spawn_light
                    visible: True
                    semantic_tags: None
                    copy_from_source: True
                    prim_type: DomeLight
                    color: (1.0, 1.0, 1.0)
                    enable_color_temperature: False
                    color_temperature: 6500.0
                    normalize: False
                    exposure: 0.0
                    intensity: 750.0
                    texture_file: https://omniverse-content-production.s3-us-west-2.amazonaws.com/Assets/Isaac/5.1/Isaac/Materials/Textures/Skies/PolyHaven/kloofendal_43d_clear_puresky_4k.hdr
                    texture_format: automatic
                    visible_in_primary_ray: True
                init_state: 
                    pos: (0.0, 0.0, 0.0)
                    rot: (1.0, 0.0, 0.0, 0.0)
                collision_group: 0
                debug_vis: False
        recorders: 
            dataset_file_handler_class_type: isaaclab.utils.datasets.hdf5_dataset_file_handler:HDF5DatasetFileHandler
            dataset_export_dir_path: /tmp/isaaclab/logs
            dataset_filename: dataset
            dataset_export_mode: 
                _value_: 1
                _name_: EXPORT_ALL
                _sort_order_: 1
            export_in_record_pre_reset: True
        observations: 
            policy: 
                concatenate_terms: True
                concatenate_dim: -1
                enable_corruption: True
                history_length: None
                flatten_history_dim: True
                base_lin_vel: 
                    func: isaaclab.envs.mdp.observations:base_lin_vel
                    params: 
                    modifiers: None
                    noise: 
                        func: isaaclab.utils.noise.noise_model:uniform_noise
                        operation: add
                        n_min: -0.1
                        n_max: 0.1
                    clip: None
                    scale: None
                    history_length: 0
                    flatten_history_dim: True
                base_ang_vel: 
                    func: isaaclab.envs.mdp.observations:base_ang_vel
                    params: 
                    modifiers: None
                    noise: 
                        func: isaaclab.utils.noise.noise_model:uniform_noise
                        operation: add
                        n_min: -0.2
                        n_max: 0.2
                    clip: None
                    scale: None
                    history_length: 0
                    flatten_history_dim: True
                projected_gravity: 
                    func: isaaclab.envs.mdp.observations:projected_gravity
                    params: 
                    modifiers: None
                    noise: 
                        func: isaaclab.utils.noise.noise_model:uniform_noise
                        operation: add
                        n_min: -0.05
                        n_max: 0.05
                    clip: None
                    scale: None
                    history_length: 0
                    flatten_history_dim: True
                velocity_commands: 
                    func: isaaclab.envs.mdp.observations:generated_commands
                    params: 
                        command_name: base_velocity
                    modifiers: None
                    noise: None
                    clip: None
                    scale: None
                    history_length: 0
                    flatten_history_dim: True
                joint_pos: 
                    func: isaaclab.envs.mdp.observations:joint_pos_rel
                    params: 
                    modifiers: None
                    noise: 
                        func: isaaclab.utils.noise.noise_model:uniform_noise
                        operation: add
                        n_min: -0.01
                        n_max: 0.01
                    clip: None
                    scale: None
                    history_length: 0
                    flatten_history_dim: True
                joint_vel: 
                    func: isaaclab.envs.mdp.observations:joint_vel_rel
                    params: 
                    modifiers: None
                    noise: 
                        func: isaaclab.utils.noise.noise_model:uniform_noise
                        operation: add
                        n_min: -1.5
                        n_max: 1.5
                    clip: None
                    scale: None
                    history_length: 0
                    flatten_history_dim: True
                actions: 
                    func: isaaclab.envs.mdp.observations:last_action
                    params: 
                    modifiers: None
                    noise: None
                    clip: None
                    scale: None
                    history_length: 0
                    flatten_history_dim: True
                height_scan: 
                    func: isaaclab.envs.mdp.observations:height_scan
                    params: 
                        sensor_cfg: 
                            name: height_scanner
                            joint_names: None
                            joint_ids: slice(None, None, None)
                            fixed_tendon_names: None
                            fixed_tendon_ids: slice(None, None, None)
                            body_names: None
                            body_ids: slice(None, None, None)
                            object_collection_names: None
                            object_collection_ids: slice(None, None, None)
                            preserve_order: False
                    modifiers: None
                    noise: 
                        func: isaaclab.utils.noise.noise_model:uniform_noise
                        operation: add
                        n_min: -0.1
                        n_max: 0.1
                    clip: (-1.0, 1.0)
                    scale: None
                    history_length: 0
                    flatten_history_dim: True
        actions: 
            joint_pos: 
                class_type: isaaclab.envs.mdp.actions.joint_actions:JointPositionAction
                asset_name: robot
                debug_vis: False
                clip: None
                joint_names: ['.*']
                scale: 0.25
                offset: 0.0
                preserve_order: False
                use_default_offset: True
        events: 
            physics_material: 
                func: isaaclab.envs.mdp.events:randomize_rigid_body_material
                params: 
                    asset_cfg: 
                        name: robot
                        joint_names: None
                        joint_ids: slice(None, None, None)
                        fixed_tendon_names: None
                        fixed_tendon_ids: slice(None, None, None)
                        body_names: .*
                        body_ids: slice(None, None, None)
                        object_collection_names: None
                        object_collection_ids: slice(None, None, None)
                        preserve_order: False
                    static_friction_range: (0.8, 0.8)
                    dynamic_friction_range: (0.6, 0.6)
                    restitution_range: (0.0, 0.0)
                    num_buckets: 64
                mode: startup
                interval_range_s: None
                is_global_time: False
                min_step_count_between_reset: 0
            add_base_mass: 
                func: isaaclab.envs.mdp.events:randomize_rigid_body_mass
                params: 
                    asset_cfg: 
                        name: robot
                        joint_names: None
                        joint_ids: slice(None, None, None)
                        fixed_tendon_names: None
                        fixed_tendon_ids: slice(None, None, None)
                        body_names: trunk
                        body_ids: slice(None, None, None)
                        object_collection_names: None
                        object_collection_ids: slice(None, None, None)
                        preserve_order: False
                    mass_distribution_params: (-1.0, 3.0)
                    operation: add
                mode: startup
                interval_range_s: None
                is_global_time: False
                min_step_count_between_reset: 0
            base_com: None
            base_external_force_torque: 
                func: isaaclab.envs.mdp.events:apply_external_force_torque
                params: 
                    asset_cfg: 
                        name: robot
                        joint_names: None
                        joint_ids: slice(None, None, None)
                        fixed_tendon_names: None
                        fixed_tendon_ids: slice(None, None, None)
                        body_names: trunk
                        body_ids: slice(None, None, None)
                        object_collection_names: None
                        object_collection_ids: slice(None, None, None)
                        preserve_order: False
                    force_range: (0.0, 0.0)
                    torque_range: (-0.0, 0.0)
                mode: reset
                interval_range_s: None
                is_global_time: False
                min_step_count_between_reset: 0
            reset_base: 
                func: isaaclab.envs.mdp.events:reset_root_state_uniform
                params: 
                    pose_range: 
                        x: (-0.5, 0.5)
                        y: (-0.5, 0.5)
                        yaw: (-3.14, 3.14)
                    velocity_range: 
                        x: (0.0, 0.0)
                        y: (0.0, 0.0)
                        z: (0.0, 0.0)
                        roll: (0.0, 0.0)
                        pitch: (0.0, 0.0)
                        yaw: (0.0, 0.0)
                mode: reset
                interval_range_s: None
                is_global_time: False
                min_step_count_between_reset: 0
            reset_robot_joints: 
                func: isaaclab.envs.mdp.events:reset_joints_by_scale
                params: 
                    position_range: (1.0, 1.0)
                    velocity_range: (0.0, 0.0)
                mode: reset
                interval_range_s: None
                is_global_time: False
                min_step_count_between_reset: 0
            push_robot: None
        rerender_on_reset: False
        num_rerenders_on_reset: 0
        wait_for_textures: True
        xr: None
        teleop_devices: 
            devices: 
        export_io_descriptors: False
        log_dir: None
        is_finite_horizon: False
        episode_length_s: 20.0
        rewards: 
            track_lin_vel_xy_exp: 
                func: isaaclab.envs.mdp.rewards:track_lin_vel_xy_exp
                params: 
                    command_name: base_velocity
                    std: 0.5
                weight: 1.0
            track_ang_vel_z_exp: 
                func: isaaclab.envs.mdp.rewards:track_ang_vel_z_exp
                params: 
                    command_name: base_velocity
                    std: 0.5
                weight: 0.5
            lin_vel_z_l2: 
                func: isaaclab.envs.mdp.rewards:lin_vel_z_l2
                params: 
                weight: -2.0
            ang_vel_xy_l2: 
                func: isaaclab.envs.mdp.rewards:ang_vel_xy_l2
                params: 
                weight: -0.05
            dof_torques_l2: 
                func: isaaclab.envs.mdp.rewards:joint_torques_l2
                params: 
                weight: -1e-05
            dof_acc_l2: 
                func: isaaclab.envs.mdp.rewards:joint_acc_l2
                params: 
                weight: -2.5e-07
            action_rate_l2: 
                func: isaaclab.envs.mdp.rewards:action_rate_l2
                params: 
                weight: -0.01
            feet_air_time: 
                func: isaaclab_tasks.manager_based.locomotion.velocity.mdp.rewards:feet_air_time
                params: 
                    sensor_cfg: 
                        name: contact_forces
                        joint_names: None
                        joint_ids: slice(None, None, None)
                        fixed_tendon_names: None
                        fixed_tendon_ids: slice(None, None, None)
                        body_names: .*_foot
                        body_ids: slice(None, None, None)
                        object_collection_names: None
                        object_collection_ids: slice(None, None, None)
                        preserve_order: False
                    command_name: base_velocity
                    threshold: 0.5
                weight: 0.125
            undesired_contacts: None
            flat_orientation_l2: 
                func: isaaclab.envs.mdp.rewards:flat_orientation_l2
                params: 
                weight: -5.0
            dof_pos_limits: 
                func: isaaclab.envs.mdp.rewards:joint_pos_limits
                params: 
                weight: 0.0
        terminations: 
            time_out: 
                func: isaaclab.envs.mdp.terminations:time_out
                params: 
                time_out: True
            base_contact: 
                func: isaaclab.envs.mdp.terminations:illegal_contact
                params: 
                    sensor_cfg: 
                        name: contact_forces
                        joint_names: None
                        joint_ids: slice(None, None, None)
                        fixed_tendon_names: None
                        fixed_tendon_ids: slice(None, None, None)
                        body_names: trunk
                        body_ids: slice(None, None, None)
                        object_collection_names: None
                        object_collection_ids: slice(None, None, None)
                        preserve_order: False
                    threshold: 1.0
                time_out: False
        curriculum: 
            terrain_levels: 
                func: isaaclab_tasks.manager_based.locomotion.velocity.mdp.curriculums:terrain_levels_vel
                params: 
        commands: 
            base_velocity: 
                class_type: isaaclab.envs.mdp.commands.velocity_command:UniformVelocityCommand
                resampling_time_range: (10.0, 10.0)
                debug_vis: True
                asset_name: robot
                heading_command: True
                heading_control_stiffness: 0.5
                rel_standing_envs: 0.02
                rel_heading_envs: 1.0
                ranges: 
                    lin_vel_x: (-1.0, 1.0)
                    lin_vel_y: (-1.0, 1.0)
                    ang_vel_z: (-1.0, 1.0)
                    heading: (-3.141592653589793, 3.141592653589793)
                goal_vel_visualizer_cfg: 
                    prim_path: /Visuals/Command/velocity_goal
                    markers: 
                        arrow: 
                            func: isaaclab.sim.spawners.from_files.from_files:spawn_from_usd
                            visible: True
                            semantic_tags: None
                            copy_from_source: True
                            mass_props: None
                            deformable_props: None
                            rigid_props: None
                            collision_props: None
                            activate_contact_sensors: False
                            scale: (0.5, 0.5, 0.5)
                            articulation_props: None
                            fixed_tendons_props: None
                            spatial_tendons_props: None
                            joint_drive_props: None
                            visual_material_path: material
                            visual_material: 
                                func: isaaclab.sim.spawners.materials.visual_materials:spawn_preview_surface
                                diffuse_color: (0.0, 1.0, 0.0)
                                emissive_color: (0.0, 0.0, 0.0)
                                roughness: 0.5
                                metallic: 0.0
                                opacity: 1.0
                            usd_path: https://omniverse-content-production.s3-us-west-2.amazonaws.com/Assets/Isaac/5.1/Isaac/Props/UIElements/arrow_x.usd
                            variants: None
                current_vel_visualizer_cfg: 
                    prim_path: /Visuals/Command/velocity_current
                    markers: 
                        arrow: 
                            func: isaaclab.sim.spawners.from_files.from_files:spawn_from_usd
                            visible: True
                            semantic_tags: None
                            copy_from_source: True
                            mass_props: None
                            deformable_props: None
                            rigid_props: None
                            collision_props: None
                            activate_contact_sensors: False
                            scale: (0.5, 0.5, 0.5)
                            articulation_props: None
                            fixed_tendons_props: None
                            spatial_tendons_props: None
                            joint_drive_props: None
                            visual_material_path: material
                            visual_material: 
                                func: isaaclab.sim.spawners.materials.visual_materials:spawn_preview_surface
                                diffuse_color: (0.0, 0.0, 1.0)
                                emissive_color: (0.0, 0.0, 0.0)
                                roughness: 0.5
                                metallic: 0.0
                                opacity: 1.0
                            usd_path: https://omniverse-content-production.s3-us-west-2.amazonaws.com/Assets/Isaac/5.1/Isaac/Props/UIElements/arrow_x.usd
                            variants: None
[INFO] Agent Configuration:
        seed: 42
        device: cuda:0
        num_steps_per_env: 24
        max_iterations: 500
        empirical_normalization: None
        obs_groups: 
        clip_actions: None
        save_interval: 50
        experiment_name: unitree_go1_rough
        run_name: 
        logger: tensorboard
        neptune_project: isaaclab
        wandb_project: isaaclab
        resume: False
        load_run: .*
        load_checkpoint: model_.*.pt
        class_name: OnPolicyRunner
        policy: 
            class_name: ActorCritic
            init_noise_std: 1.0
            noise_std_type: scalar
            actor_obs_normalization: False
            critic_obs_normalization: False
            actor_hidden_dims: [512, 256, 128]
            critic_hidden_dims: [512, 256, 128]
            activation: elu
        algorithm: 
            class_name: PPO
            num_learning_epochs: 5
            num_mini_batches: 4
            learning_rate: 0.001
            schedule: adaptive
            gamma: 0.99
            lam: 0.95
            entropy_coef: 0.01
            desired_kl: 0.01
            max_grad_norm: 1.0
            value_loss_coef: 1.0
            use_clipped_value_loss: True
            clip_param: 0.2
            normalize_advantage_per_mini_batch: False
            rnd_cfg: None
            symmetry_cfg: None
[INFO] IsaacLab logging to file: /tmp/isaaclab_2025-11-16_17-17-58.log
[INFO]: Base environment:
	Environment device    : cuda:0
	Environment seed      : 42
	Physics step-size     : 0.005
	Rendering step-size   : 0.02
	Environment step-size : 0.02
[INFO] Generating terrains based on curriculum took : 1.251364 seconds
[INFO]: Time taken for scene creation : 4.493936 seconds
[INFO]: Scene manager:  <class InteractiveScene>
	Number of environments: 4096
	Environment spacing   : 2.5
	Source prim name      : /World/envs/env_0
	Global prim paths     : ['/World/ground']
	Replicate physics     : True
[INFO]: Starting the simulation. This may take a few seconds. Please wait...
[INFO]: Time taken for simulation start : 4.501571 seconds
[INFO] Command Manager:  <CommandManager> contains 1 active terms.
+------------------------------------------------+
|              Active Command Terms              |
+-------+---------------+------------------------+
| Index | Name          |          Type          |
+-------+---------------+------------------------+
|   0   | base_velocity | UniformVelocityCommand |
+-------+---------------+------------------------+

[INFO] Event Manager:  <EventManager> contains 2 active terms.
+--------------------------------------+
| Active Event Terms in Mode: 'startup' |
+----------+---------------------------+
|  Index   | Name                      |
+----------+---------------------------+
|    0     | physics_material          |
|    1     | add_base_mass             |
+----------+---------------------------+
+---------------------------------------+
|  Active Event Terms in Mode: 'reset'  |
+--------+------------------------------+
| Index  | Name                         |
+--------+------------------------------+
|   0    | base_external_force_torque   |
|   1    | reset_base                   |
|   2    | reset_robot_joints           |
+--------+------------------------------+

[INFO] Recorder Manager:  <RecorderManager> contains 0 active terms.
+---------------------+
| Active Recorder Terms |
+-----------+---------+
|   Index   | Name    |
+-----------+---------+
+-----------+---------+

[INFO] Action Manager:  <ActionManager> contains 1 active terms.
+------------------------------------+
|  Active Action Terms (shape: 12)   |
+--------+-------------+-------------+
| Index  | Name        |   Dimension |
+--------+-------------+-------------+
|   0    | joint_pos   |          12 |
+--------+-------------+-------------+

[INFO] Observation Manager: <ObservationManager> contains 1 groups.
+----------------------------------------------------------+
| Active Observation Terms in Group: 'policy' (shape: (235,)) |
+-----------+--------------------------------+-------------+
|   Index   | Name                           |    Shape    |
+-----------+--------------------------------+-------------+
|     0     | base_lin_vel                   |     (3,)    |
|     1     | base_ang_vel                   |     (3,)    |
|     2     | projected_gravity              |     (3,)    |
|     3     | velocity_commands              |     (3,)    |
|     4     | joint_pos                      |    (12,)    |
|     5     | joint_vel                      |    (12,)    |
|     6     | actions                        |    (12,)    |
|     7     | height_scan                    |    (187,)   |
+-----------+--------------------------------+-------------+
/home/maxime/miniconda3/envs/env_isaaclab/lib/python3.11/site-packages/rsl_rl/utils/utils.py:245: UserWarning: The observation configuration dictionary 'obs_groups' must contain the 'policy' key. As an observation group with the name 'policy' was found, this is assumed to be the observation set. Consider adding the 'policy' key to the 'obs_groups' dictionary for clarity. This behavior will be removed in a future version.
  warnings.warn(
/home/maxime/miniconda3/envs/env_isaaclab/lib/python3.11/site-packages/rsl_rl/utils/utils.py:291: UserWarning: The observation configuration dictionary 'obs_groups' must contain the 'critic' key. As the configuration for 'critic' is missing, the observations from the 'policy' set are used. Consider adding the 'critic' key to the 'obs_groups' dictionary for clarity. This behavior will be removed in a future version.
  warnings.warn(

[INFO] Termination Manager:  <TerminationManager> contains 2 active terms.
+---------------------------------+
|     Active Termination Terms    |
+-------+--------------+----------+
| Index | Name         | Time Out |
+-------+--------------+----------+
|   0   | time_out     |   True   |
|   1   | base_contact |  False   |
+-------+--------------+----------+

[INFO] Reward Manager:  <RewardManager> contains 10 active terms.
+-----------------------------------------+
|           Active Reward Terms           |
+-------+----------------------+----------+
| Index | Name                 |   Weight |
+-------+----------------------+----------+
|   0   | track_lin_vel_xy_exp |      1.0 |
|   1   | track_ang_vel_z_exp  |      0.5 |
|   2   | lin_vel_z_l2         |     -2.0 |
|   3   | ang_vel_xy_l2        |    -0.05 |
|   4   | dof_torques_l2       |   -1e-05 |
|   5   | dof_acc_l2           | -2.5e-07 |
|   6   | action_rate_l2       |    -0.01 |
|   7   | feet_air_time        |    0.125 |
|   8   | flat_orientation_l2  |     -5.0 |
|   9   | dof_pos_limits       |      0.0 |
+-------+----------------------+----------+

[INFO] Curriculum Manager:  <CurriculumManager> contains 1 active terms.
+---------------------------+
|  Active Curriculum Terms  |
+--------+------------------+
| Index  | Name             |
+--------+------------------+
|   0    | terrain_levels   |
+--------+------------------+

[INFO]: Completed setting up the environment...
[INFO] Starting training for 500 iterations...
--------------------------------------------------------------------------------
Resolved observation sets: 
	 policy :  ['policy']
	 critic :  ['policy']
--------------------------------------------------------------------------------
Actor MLP: MLP(
  (0): Linear(in_features=235, out_features=512, bias=True)
  (1): ELU(alpha=1.0)
  (2): Linear(in_features=512, out_features=256, bias=True)
  (3): ELU(alpha=1.0)
  (4): Linear(in_features=256, out_features=128, bias=True)
  (5): ELU(alpha=1.0)
  (6): Linear(in_features=128, out_features=12, bias=True)
)
Critic MLP: MLP(
  (0): Linear(in_features=235, out_features=512, bias=True)
  (1): ELU(alpha=1.0)
  (2): Linear(in_features=512, out_features=256, bias=True)
  (3): ELU(alpha=1.0)
  (4): Linear(in_features=256, out_features=128, bias=True)
  (5): ELU(alpha=1.0)
  (6): Linear(in_features=128, out_features=1, bias=True)
)
################################################################################
                       [1m Learning iteration 0/500 [0m                       

                       Computation: 29835 steps/s (collection: 3.014s, learning 0.281s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0642
               Mean surrogate loss: 0.0131
                 Mean entropy loss: 17.0184
                       Mean reward: -0.78
               Mean episode length: 17.55
Episode_Reward/track_lin_vel_xy_exp: 0.0028
Episode_Reward/track_ang_vel_z_exp: 0.0017
       Episode_Reward/lin_vel_z_l2: -0.0154
      Episode_Reward/ang_vel_xy_l2: -0.0045
     Episode_Reward/dof_torques_l2: -0.0001
         Episode_Reward/dof_acc_l2: -0.0058
     Episode_Reward/action_rate_l2: -0.0029
      Episode_Reward/feet_air_time: -0.0002
Episode_Reward/flat_orientation_l2: -0.0012
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.5162
Metrics/base_velocity/error_vel_xy: 0.0167
Metrics/base_velocity/error_vel_yaw: 0.0183
      Episode_Termination/time_out: 0.0130
  Episode_Termination/base_contact: 0.0093
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 3.29s
                      Time elapsed: 00:00:03
                               ETA: 00:27:27

Could not find git repository in /home/maxime/miniconda3/envs/env_isaaclab/lib/python3.11/site-packages/rsl_rl/__init__.py. Skipping.
################################################################################
                       [1m Learning iteration 1/500 [0m                       

                       Computation: 46015 steps/s (collection: 1.995s, learning 0.141s)
             Mean action noise std: 0.99
          Mean value_function loss: 0.0128
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 16.9799
                       Mean reward: -0.96
               Mean episode length: 37.38
Episode_Reward/track_lin_vel_xy_exp: 0.0074
Episode_Reward/track_ang_vel_z_exp: 0.0052
       Episode_Reward/lin_vel_z_l2: -0.0221
      Episode_Reward/ang_vel_xy_l2: -0.0125
     Episode_Reward/dof_torques_l2: -0.0001
         Episode_Reward/dof_acc_l2: -0.0096
     Episode_Reward/action_rate_l2: -0.0082
      Episode_Reward/feet_air_time: -0.0009
Episode_Reward/flat_orientation_l2: -0.0053
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.4746
Metrics/base_velocity/error_vel_xy: 0.0532
Metrics/base_velocity/error_vel_yaw: 0.0570
      Episode_Termination/time_out: 0.0352
  Episode_Termination/base_contact: 0.0265
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 2.14s
                      Time elapsed: 00:00:05
                               ETA: 00:22:35

################################################################################
                       [1m Learning iteration 2/500 [0m                       

                       Computation: 45751 steps/s (collection: 2.009s, learning 0.140s)
             Mean action noise std: 0.97
          Mean value_function loss: 0.0113
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 16.8042
                       Mean reward: -1.47
               Mean episode length: 64.31
Episode_Reward/track_lin_vel_xy_exp: 0.0116
Episode_Reward/track_ang_vel_z_exp: 0.0093
       Episode_Reward/lin_vel_z_l2: -0.0250
      Episode_Reward/ang_vel_xy_l2: -0.0219
     Episode_Reward/dof_torques_l2: -0.0002
         Episode_Reward/dof_acc_l2: -0.0146
     Episode_Reward/action_rate_l2: -0.0142
      Episode_Reward/feet_air_time: -0.0017
Episode_Reward/flat_orientation_l2: -0.0145
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.4442
Metrics/base_velocity/error_vel_xy: 0.0934
Metrics/base_velocity/error_vel_yaw: 0.0949
      Episode_Termination/time_out: 0.0586
  Episode_Termination/base_contact: 0.0323
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 2.15s
                      Time elapsed: 00:00:07
                               ETA: 00:20:58

################################################################################
                       [1m Learning iteration 3/500 [0m                       

                       Computation: 45421 steps/s (collection: 2.024s, learning 0.140s)
             Mean action noise std: 0.96
          Mean value_function loss: 0.0086
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 16.6090
                       Mean reward: -1.69
               Mean episode length: 83.41
Episode_Reward/track_lin_vel_xy_exp: 0.0146
Episode_Reward/track_ang_vel_z_exp: 0.0115
       Episode_Reward/lin_vel_z_l2: -0.0232
      Episode_Reward/ang_vel_xy_l2: -0.0281
     Episode_Reward/dof_torques_l2: -0.0003
         Episode_Reward/dof_acc_l2: -0.0158
     Episode_Reward/action_rate_l2: -0.0188
      Episode_Reward/feet_air_time: -0.0025
Episode_Reward/flat_orientation_l2: -0.0149
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.4143
Metrics/base_velocity/error_vel_xy: 0.1302
Metrics/base_velocity/error_vel_yaw: 0.1346
      Episode_Termination/time_out: 0.0804
  Episode_Termination/base_contact: 0.0396
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 2.16s
                      Time elapsed: 00:00:09
                               ETA: 00:20:10

################################################################################
                       [1m Learning iteration 4/500 [0m                       

                       Computation: 45087 steps/s (collection: 2.039s, learning 0.142s)
             Mean action noise std: 0.94
          Mean value_function loss: 0.0074
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 16.3974
                       Mean reward: -1.82
               Mean episode length: 108.02
Episode_Reward/track_lin_vel_xy_exp: 0.0202
Episode_Reward/track_ang_vel_z_exp: 0.0169
       Episode_Reward/lin_vel_z_l2: -0.0263
      Episode_Reward/ang_vel_xy_l2: -0.0361
     Episode_Reward/dof_torques_l2: -0.0004
         Episode_Reward/dof_acc_l2: -0.0194
     Episode_Reward/action_rate_l2: -0.0245
      Episode_Reward/feet_air_time: -0.0031
Episode_Reward/flat_orientation_l2: -0.0205
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.3841
Metrics/base_velocity/error_vel_xy: 0.1671
Metrics/base_velocity/error_vel_yaw: 0.1632
      Episode_Termination/time_out: 0.1019
  Episode_Termination/base_contact: 0.0466
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 2.18s
                      Time elapsed: 00:00:11
                               ETA: 00:19:42

################################################################################
                       [1m Learning iteration 5/500 [0m                       

                       Computation: 45217 steps/s (collection: 2.033s, learning 0.141s)
             Mean action noise std: 0.93
          Mean value_function loss: 0.0065
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 16.2230
                       Mean reward: -2.02
               Mean episode length: 130.36
Episode_Reward/track_lin_vel_xy_exp: 0.0322
Episode_Reward/track_ang_vel_z_exp: 0.0216
       Episode_Reward/lin_vel_z_l2: -0.0279
      Episode_Reward/ang_vel_xy_l2: -0.0428
     Episode_Reward/dof_torques_l2: -0.0005
         Episode_Reward/dof_acc_l2: -0.0220
     Episode_Reward/action_rate_l2: -0.0297
      Episode_Reward/feet_air_time: -0.0038
Episode_Reward/flat_orientation_l2: -0.0257
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.3543
Metrics/base_velocity/error_vel_xy: 0.1881
Metrics/base_velocity/error_vel_yaw: 0.1996
      Episode_Termination/time_out: 0.1256
  Episode_Termination/base_contact: 0.0527
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 2.17s
                      Time elapsed: 00:00:14
                               ETA: 00:19:23

################################################################################
                       [1m Learning iteration 6/500 [0m                       

                       Computation: 45474 steps/s (collection: 2.021s, learning 0.140s)
             Mean action noise std: 0.92
          Mean value_function loss: 0.0059
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 16.0173
                       Mean reward: -2.34
               Mean episode length: 159.37
Episode_Reward/track_lin_vel_xy_exp: 0.0282
Episode_Reward/track_ang_vel_z_exp: 0.0266
       Episode_Reward/lin_vel_z_l2: -0.0292
      Episode_Reward/ang_vel_xy_l2: -0.0506
     Episode_Reward/dof_torques_l2: -0.0006
         Episode_Reward/dof_acc_l2: -0.0250
     Episode_Reward/action_rate_l2: -0.0354
      Episode_Reward/feet_air_time: -0.0047
Episode_Reward/flat_orientation_l2: -0.0256
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.3267
Metrics/base_velocity/error_vel_xy: 0.2489
Metrics/base_velocity/error_vel_yaw: 0.2369
      Episode_Termination/time_out: 0.1471
  Episode_Termination/base_contact: 0.0583
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 2.16s
                      Time elapsed: 00:00:16
                               ETA: 00:19:07

################################################################################
                       [1m Learning iteration 7/500 [0m                       

                       Computation: 45379 steps/s (collection: 2.026s, learning 0.140s)
             Mean action noise std: 0.91
          Mean value_function loss: 0.0096
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 15.9218
                       Mean reward: -2.51
               Mean episode length: 177.92
Episode_Reward/track_lin_vel_xy_exp: 0.0327
Episode_Reward/track_ang_vel_z_exp: 0.0269
       Episode_Reward/lin_vel_z_l2: -0.0300
      Episode_Reward/ang_vel_xy_l2: -0.0566
     Episode_Reward/dof_torques_l2: -0.0007
         Episode_Reward/dof_acc_l2: -0.0262
     Episode_Reward/action_rate_l2: -0.0401
      Episode_Reward/feet_air_time: -0.0054
Episode_Reward/flat_orientation_l2: -0.0301
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.2987
Metrics/base_velocity/error_vel_xy: 0.2844
Metrics/base_velocity/error_vel_yaw: 0.2899
      Episode_Termination/time_out: 0.1714
  Episode_Termination/base_contact: 0.0621
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 2.17s
                      Time elapsed: 00:00:18
                               ETA: 00:18:55

################################################################################
                       [1m Learning iteration 8/500 [0m                       

                       Computation: 45317 steps/s (collection: 2.030s, learning 0.140s)
             Mean action noise std: 0.90
          Mean value_function loss: 0.0092
               Mean surrogate loss: 0.0009
                 Mean entropy loss: 15.8275
                       Mean reward: -2.75
               Mean episode length: 202.44
Episode_Reward/track_lin_vel_xy_exp: 0.0483
Episode_Reward/track_ang_vel_z_exp: 0.0318
       Episode_Reward/lin_vel_z_l2: -0.0322
      Episode_Reward/ang_vel_xy_l2: -0.0624
     Episode_Reward/dof_torques_l2: -0.0008
         Episode_Reward/dof_acc_l2: -0.0293
     Episode_Reward/action_rate_l2: -0.0446
      Episode_Reward/feet_air_time: -0.0058
Episode_Reward/flat_orientation_l2: -0.0335
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.2754
Metrics/base_velocity/error_vel_xy: 0.2935
Metrics/base_velocity/error_vel_yaw: 0.3178
      Episode_Termination/time_out: 0.1906
  Episode_Termination/base_contact: 0.0658
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 2.17s
                      Time elapsed: 00:00:20
                               ETA: 00:18:45

################################################################################
                       [1m Learning iteration 9/500 [0m                       

                       Computation: 45148 steps/s (collection: 2.036s, learning 0.142s)
             Mean action noise std: 0.89
          Mean value_function loss: 0.0066
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 15.6606
                       Mean reward: -2.95
               Mean episode length: 226.93
Episode_Reward/track_lin_vel_xy_exp: 0.0501
Episode_Reward/track_ang_vel_z_exp: 0.0344
       Episode_Reward/lin_vel_z_l2: -0.0329
      Episode_Reward/ang_vel_xy_l2: -0.0686
     Episode_Reward/dof_torques_l2: -0.0009
         Episode_Reward/dof_acc_l2: -0.0311
     Episode_Reward/action_rate_l2: -0.0488
      Episode_Reward/feet_air_time: -0.0065
Episode_Reward/flat_orientation_l2: -0.0425
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.2479
Metrics/base_velocity/error_vel_xy: 0.3410
Metrics/base_velocity/error_vel_yaw: 0.3636
      Episode_Termination/time_out: 0.2124
  Episode_Termination/base_contact: 0.0707
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 2.18s
                      Time elapsed: 00:00:22
                               ETA: 00:18:38

################################################################################
                      [1m Learning iteration 10/500 [0m                       

                       Computation: 44820 steps/s (collection: 2.053s, learning 0.141s)
             Mean action noise std: 0.89
          Mean value_function loss: 0.0343
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 15.5460
                       Mean reward: -3.49
               Mean episode length: 251.84
Episode_Reward/track_lin_vel_xy_exp: 0.0404
Episode_Reward/track_ang_vel_z_exp: 0.0424
       Episode_Reward/lin_vel_z_l2: -0.0341
      Episode_Reward/ang_vel_xy_l2: -0.0752
     Episode_Reward/dof_torques_l2: -0.0010
         Episode_Reward/dof_acc_l2: -0.0350
     Episode_Reward/action_rate_l2: -0.0536
      Episode_Reward/feet_air_time: -0.0072
Episode_Reward/flat_orientation_l2: -0.0499
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.2206
Metrics/base_velocity/error_vel_xy: 0.3998
Metrics/base_velocity/error_vel_yaw: 0.3770
      Episode_Termination/time_out: 0.2341
  Episode_Termination/base_contact: 0.0755
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 2.19s
                      Time elapsed: 00:00:24
                               ETA: 00:18:32

################################################################################
                      [1m Learning iteration 11/500 [0m                       

                       Computation: 44786 steps/s (collection: 2.051s, learning 0.144s)
             Mean action noise std: 0.88
          Mean value_function loss: 0.0220
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 15.4869
                       Mean reward: -3.43
               Mean episode length: 266.11
Episode_Reward/track_lin_vel_xy_exp: 0.0587
Episode_Reward/track_ang_vel_z_exp: 0.0394
       Episode_Reward/lin_vel_z_l2: -0.0343
      Episode_Reward/ang_vel_xy_l2: -0.0783
     Episode_Reward/dof_torques_l2: -0.0010
         Episode_Reward/dof_acc_l2: -0.0354
     Episode_Reward/action_rate_l2: -0.0564
      Episode_Reward/feet_air_time: -0.0077
Episode_Reward/flat_orientation_l2: -0.0535
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.1913
Metrics/base_velocity/error_vel_xy: 0.4016
Metrics/base_velocity/error_vel_yaw: 0.4439
      Episode_Termination/time_out: 0.2557
  Episode_Termination/base_contact: 0.0820
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 2.19s
                      Time elapsed: 00:00:27
                               ETA: 00:18:26

################################################################################
                      [1m Learning iteration 12/500 [0m                       

                       Computation: 44812 steps/s (collection: 2.052s, learning 0.141s)
             Mean action noise std: 0.87
          Mean value_function loss: 0.0095
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 15.3562
                       Mean reward: -3.77
               Mean episode length: 296.92
Episode_Reward/track_lin_vel_xy_exp: 0.0580
Episode_Reward/track_ang_vel_z_exp: 0.0469
       Episode_Reward/lin_vel_z_l2: -0.0353
      Episode_Reward/ang_vel_xy_l2: -0.0844
     Episode_Reward/dof_torques_l2: -0.0011
         Episode_Reward/dof_acc_l2: -0.0387
     Episode_Reward/action_rate_l2: -0.0619
      Episode_Reward/feet_air_time: -0.0085
Episode_Reward/flat_orientation_l2: -0.0580
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.1608
Metrics/base_velocity/error_vel_xy: 0.4641
Metrics/base_velocity/error_vel_yaw: 0.4635
      Episode_Termination/time_out: 0.2771
  Episode_Termination/base_contact: 0.0893
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 2.19s
                      Time elapsed: 00:00:29
                               ETA: 00:18:21

################################################################################
                      [1m Learning iteration 13/500 [0m                       

                       Computation: 44296 steps/s (collection: 2.075s, learning 0.144s)
             Mean action noise std: 0.86
          Mean value_function loss: 0.0079
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 15.2814
                       Mean reward: -3.63
               Mean episode length: 319.70
Episode_Reward/track_lin_vel_xy_exp: 0.0668
Episode_Reward/track_ang_vel_z_exp: 0.0491
       Episode_Reward/lin_vel_z_l2: -0.0361
      Episode_Reward/ang_vel_xy_l2: -0.0889
     Episode_Reward/dof_torques_l2: -0.0012
         Episode_Reward/dof_acc_l2: -0.0411
     Episode_Reward/action_rate_l2: -0.0654
      Episode_Reward/feet_air_time: -0.0088
Episode_Reward/flat_orientation_l2: -0.0617
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.1270
Metrics/base_velocity/error_vel_xy: 0.4810
Metrics/base_velocity/error_vel_yaw: 0.4988
      Episode_Termination/time_out: 0.3003
  Episode_Termination/base_contact: 0.0978
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 2.22s
                      Time elapsed: 00:00:31
                               ETA: 00:18:18

################################################################################
                      [1m Learning iteration 14/500 [0m                       

                       Computation: 44424 steps/s (collection: 2.071s, learning 0.142s)
             Mean action noise std: 0.86
          Mean value_function loss: 0.0072
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 15.1831
                       Mean reward: -3.86
               Mean episode length: 330.22
Episode_Reward/track_lin_vel_xy_exp: 0.0750
Episode_Reward/track_ang_vel_z_exp: 0.0492
       Episode_Reward/lin_vel_z_l2: -0.0378
      Episode_Reward/ang_vel_xy_l2: -0.0937
     Episode_Reward/dof_torques_l2: -0.0012
         Episode_Reward/dof_acc_l2: -0.0416
     Episode_Reward/action_rate_l2: -0.0674
      Episode_Reward/feet_air_time: -0.0090
Episode_Reward/flat_orientation_l2: -0.0750
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.0896
Metrics/base_velocity/error_vel_xy: 0.4824
Metrics/base_velocity/error_vel_yaw: 0.5377
      Episode_Termination/time_out: 0.3228
  Episode_Termination/base_contact: 0.1105
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 2.21s
                      Time elapsed: 00:00:33
                               ETA: 00:18:14

################################################################################
                      [1m Learning iteration 15/500 [0m                       

                       Computation: 44429 steps/s (collection: 2.068s, learning 0.145s)
             Mean action noise std: 0.85
          Mean value_function loss: 0.0073
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 15.1353
                       Mean reward: -3.71
               Mean episode length: 339.70
Episode_Reward/track_lin_vel_xy_exp: 0.0865
Episode_Reward/track_ang_vel_z_exp: 0.0540
       Episode_Reward/lin_vel_z_l2: -0.0368
      Episode_Reward/ang_vel_xy_l2: -0.0930
     Episode_Reward/dof_torques_l2: -0.0013
         Episode_Reward/dof_acc_l2: -0.0447
     Episode_Reward/action_rate_l2: -0.0695
      Episode_Reward/feet_air_time: -0.0098
Episode_Reward/flat_orientation_l2: -0.0613
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.0566
Metrics/base_velocity/error_vel_xy: 0.5027
Metrics/base_velocity/error_vel_yaw: 0.5362
      Episode_Termination/time_out: 0.3411
  Episode_Termination/base_contact: 0.1231
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 2.21s
                      Time elapsed: 00:00:35
                               ETA: 00:18:11

################################################################################
                      [1m Learning iteration 16/500 [0m                       

                       Computation: 44623 steps/s (collection: 2.062s, learning 0.141s)
             Mean action noise std: 0.85
          Mean value_function loss: 0.0068
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 15.0027
                       Mean reward: -4.13
               Mean episode length: 362.08
Episode_Reward/track_lin_vel_xy_exp: 0.0730
Episode_Reward/track_ang_vel_z_exp: 0.0531
       Episode_Reward/lin_vel_z_l2: -0.0363
      Episode_Reward/ang_vel_xy_l2: -0.0952
     Episode_Reward/dof_torques_l2: -0.0014
         Episode_Reward/dof_acc_l2: -0.0426
     Episode_Reward/action_rate_l2: -0.0724
      Episode_Reward/feet_air_time: -0.0099
Episode_Reward/flat_orientation_l2: -0.0640
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.0250
Metrics/base_velocity/error_vel_xy: 0.5468
Metrics/base_velocity/error_vel_yaw: 0.5911
      Episode_Termination/time_out: 0.3545
  Episode_Termination/base_contact: 0.1371
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 2.20s
                      Time elapsed: 00:00:38
                               ETA: 00:18:07

################################################################################
                      [1m Learning iteration 17/500 [0m                       

                       Computation: 44144 steps/s (collection: 2.085s, learning 0.142s)
             Mean action noise std: 0.84
          Mean value_function loss: 0.0204
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 14.9323
                       Mean reward: -3.90
               Mean episode length: 382.42
Episode_Reward/track_lin_vel_xy_exp: 0.0742
Episode_Reward/track_ang_vel_z_exp: 0.0561
       Episode_Reward/lin_vel_z_l2: -0.0369
      Episode_Reward/ang_vel_xy_l2: -0.0955
     Episode_Reward/dof_torques_l2: -0.0014
         Episode_Reward/dof_acc_l2: -0.0437
     Episode_Reward/action_rate_l2: -0.0726
      Episode_Reward/feet_air_time: -0.0100
Episode_Reward/flat_orientation_l2: -0.0674
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.9869
Metrics/base_velocity/error_vel_xy: 0.5570
Metrics/base_velocity/error_vel_yaw: 0.5859
      Episode_Termination/time_out: 0.3685
  Episode_Termination/base_contact: 0.1535
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 2.23s
                      Time elapsed: 00:00:40
                               ETA: 00:18:04

################################################################################
                      [1m Learning iteration 18/500 [0m                       

                       Computation: 44324 steps/s (collection: 2.075s, learning 0.143s)
             Mean action noise std: 0.83
          Mean value_function loss: 0.0100
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 14.8324
                       Mean reward: -3.56
               Mean episode length: 381.30
Episode_Reward/track_lin_vel_xy_exp: 0.0924
Episode_Reward/track_ang_vel_z_exp: 0.0674
       Episode_Reward/lin_vel_z_l2: -0.0362
      Episode_Reward/ang_vel_xy_l2: -0.0993
     Episode_Reward/dof_torques_l2: -0.0015
         Episode_Reward/dof_acc_l2: -0.0434
     Episode_Reward/action_rate_l2: -0.0765
      Episode_Reward/feet_air_time: -0.0102
Episode_Reward/flat_orientation_l2: -0.0733
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.9503
Metrics/base_velocity/error_vel_xy: 0.5673
Metrics/base_velocity/error_vel_yaw: 0.5697
      Episode_Termination/time_out: 0.3804
  Episode_Termination/base_contact: 0.1690
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 2.22s
                      Time elapsed: 00:00:42
                               ETA: 00:18:01

################################################################################
                      [1m Learning iteration 19/500 [0m                       

                       Computation: 44081 steps/s (collection: 2.087s, learning 0.143s)
             Mean action noise std: 0.83
          Mean value_function loss: 0.0066
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 14.7685
                       Mean reward: -4.26
               Mean episode length: 415.74
Episode_Reward/track_lin_vel_xy_exp: 0.0784
Episode_Reward/track_ang_vel_z_exp: 0.0647
       Episode_Reward/lin_vel_z_l2: -0.0369
      Episode_Reward/ang_vel_xy_l2: -0.1014
     Episode_Reward/dof_torques_l2: -0.0015
         Episode_Reward/dof_acc_l2: -0.0456
     Episode_Reward/action_rate_l2: -0.0790
      Episode_Reward/feet_air_time: -0.0107
Episode_Reward/flat_orientation_l2: -0.0649
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.9094
Metrics/base_velocity/error_vel_xy: 0.6478
Metrics/base_velocity/error_vel_yaw: 0.6318
      Episode_Termination/time_out: 0.3928
  Episode_Termination/base_contact: 0.1883
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 2.23s
                      Time elapsed: 00:00:44
                               ETA: 00:17:59

################################################################################
                      [1m Learning iteration 20/500 [0m                       

                       Computation: 44108 steps/s (collection: 2.080s, learning 0.149s)
             Mean action noise std: 0.83
          Mean value_function loss: 0.0115
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 14.7342
                       Mean reward: -3.92
               Mean episode length: 409.44
Episode_Reward/track_lin_vel_xy_exp: 0.0720
Episode_Reward/track_ang_vel_z_exp: 0.0602
       Episode_Reward/lin_vel_z_l2: -0.0350
      Episode_Reward/ang_vel_xy_l2: -0.0934
     Episode_Reward/dof_torques_l2: -0.0014
         Episode_Reward/dof_acc_l2: -0.0429
     Episode_Reward/action_rate_l2: -0.0727
      Episode_Reward/feet_air_time: -0.0101
Episode_Reward/flat_orientation_l2: -0.0606
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.8625
Metrics/base_velocity/error_vel_xy: 0.6080
Metrics/base_velocity/error_vel_yaw: 0.5913
      Episode_Termination/time_out: 0.4007
  Episode_Termination/base_contact: 0.2136
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 2.23s
                      Time elapsed: 00:00:47
                               ETA: 00:17:56

################################################################################
                      [1m Learning iteration 21/500 [0m                       

                       Computation: 44308 steps/s (collection: 2.077s, learning 0.142s)
             Mean action noise std: 0.82
          Mean value_function loss: 0.0059
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 14.6263
                       Mean reward: -3.14
               Mean episode length: 370.62
Episode_Reward/track_lin_vel_xy_exp: 0.0740
Episode_Reward/track_ang_vel_z_exp: 0.0611
       Episode_Reward/lin_vel_z_l2: -0.0320
      Episode_Reward/ang_vel_xy_l2: -0.0902
     Episode_Reward/dof_torques_l2: -0.0014
         Episode_Reward/dof_acc_l2: -0.0419
     Episode_Reward/action_rate_l2: -0.0722
      Episode_Reward/feet_air_time: -0.0103
Episode_Reward/flat_orientation_l2: -0.0536
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.8136
Metrics/base_velocity/error_vel_xy: 0.6074
Metrics/base_velocity/error_vel_yaw: 0.5868
      Episode_Termination/time_out: 0.4028
  Episode_Termination/base_contact: 0.2421
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 2.22s
                      Time elapsed: 00:00:49
                               ETA: 00:17:53

################################################################################
                      [1m Learning iteration 22/500 [0m                       

                       Computation: 43678 steps/s (collection: 2.105s, learning 0.146s)
             Mean action noise std: 0.82
          Mean value_function loss: 0.0064
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 14.5566
                       Mean reward: -2.82
               Mean episode length: 398.18
Episode_Reward/track_lin_vel_xy_exp: 0.0827
Episode_Reward/track_ang_vel_z_exp: 0.0673
       Episode_Reward/lin_vel_z_l2: -0.0316
      Episode_Reward/ang_vel_xy_l2: -0.0886
     Episode_Reward/dof_torques_l2: -0.0013
         Episode_Reward/dof_acc_l2: -0.0412
     Episode_Reward/action_rate_l2: -0.0706
      Episode_Reward/feet_air_time: -0.0100
Episode_Reward/flat_orientation_l2: -0.0486
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.7555
Metrics/base_velocity/error_vel_xy: 0.5698
Metrics/base_velocity/error_vel_yaw: 0.5352
      Episode_Termination/time_out: 0.3984
  Episode_Termination/base_contact: 0.2772
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 2.25s
                      Time elapsed: 00:00:51
                               ETA: 00:17:51

################################################################################
                      [1m Learning iteration 23/500 [0m                       

                       Computation: 43942 steps/s (collection: 2.093s, learning 0.144s)
             Mean action noise std: 0.81
          Mean value_function loss: 0.0065
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 14.4995
                       Mean reward: -3.07
               Mean episode length: 390.06
Episode_Reward/track_lin_vel_xy_exp: 0.0851
Episode_Reward/track_ang_vel_z_exp: 0.0680
       Episode_Reward/lin_vel_z_l2: -0.0310
      Episode_Reward/ang_vel_xy_l2: -0.0907
     Episode_Reward/dof_torques_l2: -0.0014
         Episode_Reward/dof_acc_l2: -0.0418
     Episode_Reward/action_rate_l2: -0.0732
      Episode_Reward/feet_air_time: -0.0104
Episode_Reward/flat_orientation_l2: -0.0529
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.6909
Metrics/base_velocity/error_vel_xy: 0.6041
Metrics/base_velocity/error_vel_yaw: 0.5728
      Episode_Termination/time_out: 0.3964
  Episode_Termination/base_contact: 0.3151
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 2.24s
                      Time elapsed: 00:00:53
                               ETA: 00:17:49

################################################################################
                      [1m Learning iteration 24/500 [0m                       

                       Computation: 43984 steps/s (collection: 2.091s, learning 0.144s)
             Mean action noise std: 0.81
          Mean value_function loss: 0.0063
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 14.4091
                       Mean reward: -3.18
               Mean episode length: 397.46
Episode_Reward/track_lin_vel_xy_exp: 0.0841
Episode_Reward/track_ang_vel_z_exp: 0.0651
       Episode_Reward/lin_vel_z_l2: -0.0307
      Episode_Reward/ang_vel_xy_l2: -0.0866
     Episode_Reward/dof_torques_l2: -0.0013
         Episode_Reward/dof_acc_l2: -0.0399
     Episode_Reward/action_rate_l2: -0.0695
      Episode_Reward/feet_air_time: -0.0100
Episode_Reward/flat_orientation_l2: -0.0543
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.6140
Metrics/base_velocity/error_vel_xy: 0.5653
Metrics/base_velocity/error_vel_yaw: 0.5490
      Episode_Termination/time_out: 0.3879
  Episode_Termination/base_contact: 0.3612
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 2.23s
                      Time elapsed: 00:00:56
                               ETA: 00:17:47

################################################################################
                      [1m Learning iteration 25/500 [0m                       

                       Computation: 44141 steps/s (collection: 2.085s, learning 0.142s)
             Mean action noise std: 0.80
          Mean value_function loss: 0.0070
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 14.3410
                       Mean reward: -2.25
               Mean episode length: 339.29
Episode_Reward/track_lin_vel_xy_exp: 0.0768
Episode_Reward/track_ang_vel_z_exp: 0.0619
       Episode_Reward/lin_vel_z_l2: -0.0281
      Episode_Reward/ang_vel_xy_l2: -0.0774
     Episode_Reward/dof_torques_l2: -0.0012
         Episode_Reward/dof_acc_l2: -0.0366
     Episode_Reward/action_rate_l2: -0.0627
      Episode_Reward/feet_air_time: -0.0092
Episode_Reward/flat_orientation_l2: -0.0456
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.5400
Metrics/base_velocity/error_vel_xy: 0.5258
Metrics/base_velocity/error_vel_yaw: 0.4873
      Episode_Termination/time_out: 0.3735
  Episode_Termination/base_contact: 0.4064
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 2.23s
                      Time elapsed: 00:00:58
                               ETA: 00:17:44

################################################################################
                      [1m Learning iteration 26/500 [0m                       

                       Computation: 44183 steps/s (collection: 2.081s, learning 0.144s)
             Mean action noise std: 0.80
          Mean value_function loss: 0.0066
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 14.2478
                       Mean reward: -1.78
               Mean episode length: 248.42
Episode_Reward/track_lin_vel_xy_exp: 0.0651
Episode_Reward/track_ang_vel_z_exp: 0.0533
       Episode_Reward/lin_vel_z_l2: -0.0264
      Episode_Reward/ang_vel_xy_l2: -0.0661
     Episode_Reward/dof_torques_l2: -0.0011
         Episode_Reward/dof_acc_l2: -0.0317
     Episode_Reward/action_rate_l2: -0.0541
      Episode_Reward/feet_air_time: -0.0080
Episode_Reward/flat_orientation_l2: -0.0408
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.4570
Metrics/base_velocity/error_vel_xy: 0.4565
Metrics/base_velocity/error_vel_yaw: 0.4320
      Episode_Termination/time_out: 0.3588
  Episode_Termination/base_contact: 0.4508
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 2.22s
                      Time elapsed: 00:01:00
                               ETA: 00:17:42

################################################################################
                      [1m Learning iteration 27/500 [0m                       

                       Computation: 44055 steps/s (collection: 2.088s, learning 0.144s)
             Mean action noise std: 0.79
          Mean value_function loss: 0.0090
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 14.1831
                       Mean reward: -1.73
               Mean episode length: 242.12
Episode_Reward/track_lin_vel_xy_exp: 0.0644
Episode_Reward/track_ang_vel_z_exp: 0.0477
       Episode_Reward/lin_vel_z_l2: -0.0251
      Episode_Reward/ang_vel_xy_l2: -0.0569
     Episode_Reward/dof_torques_l2: -0.0009
         Episode_Reward/dof_acc_l2: -0.0279
     Episode_Reward/action_rate_l2: -0.0462
      Episode_Reward/feet_air_time: -0.0068
Episode_Reward/flat_orientation_l2: -0.0358
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.3674
Metrics/base_velocity/error_vel_xy: 0.3787
Metrics/base_velocity/error_vel_yaw: 0.3660
      Episode_Termination/time_out: 0.3422
  Episode_Termination/base_contact: 0.4918
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 2.23s
                      Time elapsed: 00:01:02
                               ETA: 00:17:39

################################################################################
                      [1m Learning iteration 28/500 [0m                       

                       Computation: 44018 steps/s (collection: 2.088s, learning 0.146s)
             Mean action noise std: 0.79
          Mean value_function loss: 0.0062
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 14.0993
                       Mean reward: -1.31
               Mean episode length: 215.37
Episode_Reward/track_lin_vel_xy_exp: 0.0671
Episode_Reward/track_ang_vel_z_exp: 0.0504
       Episode_Reward/lin_vel_z_l2: -0.0234
      Episode_Reward/ang_vel_xy_l2: -0.0585
     Episode_Reward/dof_torques_l2: -0.0010
         Episode_Reward/dof_acc_l2: -0.0275
     Episode_Reward/action_rate_l2: -0.0481
      Episode_Reward/feet_air_time: -0.0071
Episode_Reward/flat_orientation_l2: -0.0340
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.2876
Metrics/base_velocity/error_vel_xy: 0.3941
Metrics/base_velocity/error_vel_yaw: 0.3820
      Episode_Termination/time_out: 0.3267
  Episode_Termination/base_contact: 0.5288
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 2.23s
                      Time elapsed: 00:01:04
                               ETA: 00:17:37

################################################################################
                      [1m Learning iteration 29/500 [0m                       

                       Computation: 43446 steps/s (collection: 2.119s, learning 0.143s)
             Mean action noise std: 0.78
          Mean value_function loss: 0.0058
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 14.0137
                       Mean reward: -1.51
               Mean episode length: 266.28
Episode_Reward/track_lin_vel_xy_exp: 0.0607
Episode_Reward/track_ang_vel_z_exp: 0.0448
       Episode_Reward/lin_vel_z_l2: -0.0228
      Episode_Reward/ang_vel_xy_l2: -0.0503
     Episode_Reward/dof_torques_l2: -0.0008
         Episode_Reward/dof_acc_l2: -0.0245
     Episode_Reward/action_rate_l2: -0.0415
      Episode_Reward/feet_air_time: -0.0061
Episode_Reward/flat_orientation_l2: -0.0309
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.2189
Metrics/base_velocity/error_vel_xy: 0.3399
Metrics/base_velocity/error_vel_yaw: 0.3316
      Episode_Termination/time_out: 0.3138
  Episode_Termination/base_contact: 0.5574
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 2.26s
                      Time elapsed: 00:01:07
                               ETA: 00:17:35

################################################################################
                      [1m Learning iteration 30/500 [0m                       

                       Computation: 43377 steps/s (collection: 2.119s, learning 0.147s)
             Mean action noise std: 0.77
          Mean value_function loss: 0.0066
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 13.9167
                       Mean reward: -1.20
               Mean episode length: 254.41
Episode_Reward/track_lin_vel_xy_exp: 0.0725
Episode_Reward/track_ang_vel_z_exp: 0.0492
       Episode_Reward/lin_vel_z_l2: -0.0229
      Episode_Reward/ang_vel_xy_l2: -0.0551
     Episode_Reward/dof_torques_l2: -0.0009
         Episode_Reward/dof_acc_l2: -0.0266
     Episode_Reward/action_rate_l2: -0.0453
      Episode_Reward/feet_air_time: -0.0066
Episode_Reward/flat_orientation_l2: -0.0354
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.1536
Metrics/base_velocity/error_vel_xy: 0.3537
Metrics/base_velocity/error_vel_yaw: 0.3593
      Episode_Termination/time_out: 0.3055
  Episode_Termination/base_contact: 0.5813
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 2.27s
                      Time elapsed: 00:01:09
                               ETA: 00:17:33

################################################################################
                      [1m Learning iteration 31/500 [0m                       

                       Computation: 43396 steps/s (collection: 2.119s, learning 0.146s)
             Mean action noise std: 0.77
          Mean value_function loss: 0.0148
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 13.8614
                       Mean reward: -1.41
               Mean episode length: 242.55
Episode_Reward/track_lin_vel_xy_exp: 0.0674
Episode_Reward/track_ang_vel_z_exp: 0.0493
       Episode_Reward/lin_vel_z_l2: -0.0230
      Episode_Reward/ang_vel_xy_l2: -0.0554
     Episode_Reward/dof_torques_l2: -0.0009
         Episode_Reward/dof_acc_l2: -0.0267
     Episode_Reward/action_rate_l2: -0.0450
      Episode_Reward/feet_air_time: -0.0068
Episode_Reward/flat_orientation_l2: -0.0338
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.0901
Metrics/base_velocity/error_vel_xy: 0.3706
Metrics/base_velocity/error_vel_yaw: 0.3602
      Episode_Termination/time_out: 0.3024
  Episode_Termination/base_contact: 0.6007
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 2.27s
                      Time elapsed: 00:01:11
                               ETA: 00:17:31

################################################################################
                      [1m Learning iteration 32/500 [0m                       

                       Computation: 43462 steps/s (collection: 2.115s, learning 0.147s)
             Mean action noise std: 0.76
          Mean value_function loss: 0.0072
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 13.7627
                       Mean reward: -1.18
               Mean episode length: 213.14
Episode_Reward/track_lin_vel_xy_exp: 0.0667
Episode_Reward/track_ang_vel_z_exp: 0.0494
       Episode_Reward/lin_vel_z_l2: -0.0238
      Episode_Reward/ang_vel_xy_l2: -0.0534
     Episode_Reward/dof_torques_l2: -0.0009
         Episode_Reward/dof_acc_l2: -0.0255
     Episode_Reward/action_rate_l2: -0.0438
      Episode_Reward/feet_air_time: -0.0064
Episode_Reward/flat_orientation_l2: -0.0353
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.0325
Metrics/base_velocity/error_vel_xy: 0.3708
Metrics/base_velocity/error_vel_yaw: 0.3523
      Episode_Termination/time_out: 0.2974
  Episode_Termination/base_contact: 0.6204
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 2.26s
                      Time elapsed: 00:01:14
                               ETA: 00:17:29

################################################################################
                      [1m Learning iteration 33/500 [0m                       

                       Computation: 41255 steps/s (collection: 2.240s, learning 0.142s)
             Mean action noise std: 0.76
          Mean value_function loss: 0.0051
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 13.6920
                       Mean reward: -0.56
               Mean episode length: 270.54
Episode_Reward/track_lin_vel_xy_exp: 0.0772
Episode_Reward/track_ang_vel_z_exp: 0.0503
       Episode_Reward/lin_vel_z_l2: -0.0218
      Episode_Reward/ang_vel_xy_l2: -0.0502
     Episode_Reward/dof_torques_l2: -0.0008
         Episode_Reward/dof_acc_l2: -0.0241
     Episode_Reward/action_rate_l2: -0.0416
      Episode_Reward/feet_air_time: -0.0061
Episode_Reward/flat_orientation_l2: -0.0287
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.9801
Metrics/base_velocity/error_vel_xy: 0.3245
Metrics/base_velocity/error_vel_yaw: 0.3240
      Episode_Termination/time_out: 0.2905
  Episode_Termination/base_contact: 0.6391
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 2.38s
                      Time elapsed: 00:01:16
                               ETA: 00:17:29

################################################################################
                      [1m Learning iteration 34/500 [0m                       

                       Computation: 43811 steps/s (collection: 2.100s, learning 0.144s)
             Mean action noise std: 0.75
          Mean value_function loss: 0.0045
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 13.6328
                       Mean reward: -1.20
               Mean episode length: 297.15
Episode_Reward/track_lin_vel_xy_exp: 0.0694
Episode_Reward/track_ang_vel_z_exp: 0.0516
       Episode_Reward/lin_vel_z_l2: -0.0219
      Episode_Reward/ang_vel_xy_l2: -0.0525
     Episode_Reward/dof_torques_l2: -0.0009
         Episode_Reward/dof_acc_l2: -0.0243
     Episode_Reward/action_rate_l2: -0.0438
      Episode_Reward/feet_air_time: -0.0066
Episode_Reward/flat_orientation_l2: -0.0365
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.9344
Metrics/base_velocity/error_vel_xy: 0.3744
Metrics/base_velocity/error_vel_yaw: 0.3549
      Episode_Termination/time_out: 0.2825
  Episode_Termination/base_contact: 0.6563
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 2.24s
                      Time elapsed: 00:01:18
                               ETA: 00:17:27

################################################################################
                      [1m Learning iteration 35/500 [0m                       

                       Computation: 43639 steps/s (collection: 2.105s, learning 0.147s)
             Mean action noise std: 0.75
          Mean value_function loss: 0.0052
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 13.5217
                       Mean reward: -1.42
               Mean episode length: 249.85
Episode_Reward/track_lin_vel_xy_exp: 0.0584
Episode_Reward/track_ang_vel_z_exp: 0.0517
       Episode_Reward/lin_vel_z_l2: -0.0214
      Episode_Reward/ang_vel_xy_l2: -0.0506
     Episode_Reward/dof_torques_l2: -0.0009
         Episode_Reward/dof_acc_l2: -0.0245
     Episode_Reward/action_rate_l2: -0.0421
      Episode_Reward/feet_air_time: -0.0063
Episode_Reward/flat_orientation_l2: -0.0298
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.8900
Metrics/base_velocity/error_vel_xy: 0.3832
Metrics/base_velocity/error_vel_yaw: 0.3360
      Episode_Termination/time_out: 0.2773
  Episode_Termination/base_contact: 0.6713
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 2.25s
                      Time elapsed: 00:01:20
                               ETA: 00:17:24

################################################################################
                      [1m Learning iteration 36/500 [0m                       

                       Computation: 44107 steps/s (collection: 2.086s, learning 0.143s)
             Mean action noise std: 0.75
          Mean value_function loss: 0.0059
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 13.4734
                       Mean reward: -1.28
               Mean episode length: 276.55
Episode_Reward/track_lin_vel_xy_exp: 0.0718
Episode_Reward/track_ang_vel_z_exp: 0.0588
       Episode_Reward/lin_vel_z_l2: -0.0210
      Episode_Reward/ang_vel_xy_l2: -0.0544
     Episode_Reward/dof_torques_l2: -0.0010
         Episode_Reward/dof_acc_l2: -0.0258
     Episode_Reward/action_rate_l2: -0.0458
      Episode_Reward/feet_air_time: -0.0070
Episode_Reward/flat_orientation_l2: -0.0412
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.8558
Metrics/base_velocity/error_vel_xy: 0.4045
Metrics/base_velocity/error_vel_yaw: 0.3561
      Episode_Termination/time_out: 0.2743
  Episode_Termination/base_contact: 0.6826
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 2.23s
                      Time elapsed: 00:01:23
                               ETA: 00:17:22

################################################################################
                      [1m Learning iteration 37/500 [0m                       

                       Computation: 44026 steps/s (collection: 2.089s, learning 0.143s)
             Mean action noise std: 0.74
          Mean value_function loss: 0.0054
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 13.4151
                       Mean reward: -1.15
               Mean episode length: 264.50
Episode_Reward/track_lin_vel_xy_exp: 0.0633
Episode_Reward/track_ang_vel_z_exp: 0.0566
       Episode_Reward/lin_vel_z_l2: -0.0210
      Episode_Reward/ang_vel_xy_l2: -0.0511
     Episode_Reward/dof_torques_l2: -0.0010
         Episode_Reward/dof_acc_l2: -0.0230
     Episode_Reward/action_rate_l2: -0.0436
      Episode_Reward/feet_air_time: -0.0064
Episode_Reward/flat_orientation_l2: -0.0346
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.8236
Metrics/base_velocity/error_vel_xy: 0.3990
Metrics/base_velocity/error_vel_yaw: 0.3443
      Episode_Termination/time_out: 0.2689
  Episode_Termination/base_contact: 0.6946
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 2.23s
                      Time elapsed: 00:01:25
                               ETA: 00:17:20

################################################################################
                      [1m Learning iteration 38/500 [0m                       

                       Computation: 43258 steps/s (collection: 2.129s, learning 0.143s)
             Mean action noise std: 0.74
          Mean value_function loss: 0.0047
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 13.3550
                       Mean reward: -1.69
               Mean episode length: 341.21
Episode_Reward/track_lin_vel_xy_exp: 0.0809
Episode_Reward/track_ang_vel_z_exp: 0.0670
       Episode_Reward/lin_vel_z_l2: -0.0244
      Episode_Reward/ang_vel_xy_l2: -0.0647
     Episode_Reward/dof_torques_l2: -0.0011
         Episode_Reward/dof_acc_l2: -0.0298
     Episode_Reward/action_rate_l2: -0.0542
      Episode_Reward/feet_air_time: -0.0084
Episode_Reward/flat_orientation_l2: -0.0448
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.7948
Metrics/base_velocity/error_vel_xy: 0.4721
Metrics/base_velocity/error_vel_yaw: 0.4366
      Episode_Termination/time_out: 0.2673
  Episode_Termination/base_contact: 0.7033
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 2.27s
                      Time elapsed: 00:01:27
                               ETA: 00:17:18

################################################################################
                      [1m Learning iteration 39/500 [0m                       

                       Computation: 43446 steps/s (collection: 2.111s, learning 0.152s)
             Mean action noise std: 0.73
          Mean value_function loss: 0.0054
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 13.2653
                       Mean reward: -2.28
               Mean episode length: 428.73
Episode_Reward/track_lin_vel_xy_exp: 0.0943
Episode_Reward/track_ang_vel_z_exp: 0.0717
       Episode_Reward/lin_vel_z_l2: -0.0261
      Episode_Reward/ang_vel_xy_l2: -0.0729
     Episode_Reward/dof_torques_l2: -0.0013
         Episode_Reward/dof_acc_l2: -0.0324
     Episode_Reward/action_rate_l2: -0.0619
      Episode_Reward/feet_air_time: -0.0094
Episode_Reward/flat_orientation_l2: -0.0608
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.7710
Metrics/base_velocity/error_vel_xy: 0.5278
Metrics/base_velocity/error_vel_yaw: 0.5151
      Episode_Termination/time_out: 0.2686
  Episode_Termination/base_contact: 0.7102
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 2.26s
                      Time elapsed: 00:01:29
                               ETA: 00:17:16

################################################################################
                      [1m Learning iteration 40/500 [0m                       

                       Computation: 43465 steps/s (collection: 2.107s, learning 0.155s)
             Mean action noise std: 0.73
          Mean value_function loss: 0.0042
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 13.1810
                       Mean reward: -1.86
               Mean episode length: 455.47
Episode_Reward/track_lin_vel_xy_exp: 0.0975
Episode_Reward/track_ang_vel_z_exp: 0.0844
       Episode_Reward/lin_vel_z_l2: -0.0251
      Episode_Reward/ang_vel_xy_l2: -0.0777
     Episode_Reward/dof_torques_l2: -0.0014
         Episode_Reward/dof_acc_l2: -0.0341
     Episode_Reward/action_rate_l2: -0.0659
      Episode_Reward/feet_air_time: -0.0100
Episode_Reward/flat_orientation_l2: -0.0549
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.7467
Metrics/base_velocity/error_vel_xy: 0.5919
Metrics/base_velocity/error_vel_yaw: 0.5169
      Episode_Termination/time_out: 0.2699
  Episode_Termination/base_contact: 0.7184
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 2.26s
                      Time elapsed: 00:01:32
                               ETA: 00:17:13

################################################################################
                      [1m Learning iteration 41/500 [0m                       

                       Computation: 43601 steps/s (collection: 2.105s, learning 0.149s)
             Mean action noise std: 0.73
          Mean value_function loss: 0.0054
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 13.1493
                       Mean reward: -2.52
               Mean episode length: 493.11
Episode_Reward/track_lin_vel_xy_exp: 0.1542
Episode_Reward/track_ang_vel_z_exp: 0.1067
       Episode_Reward/lin_vel_z_l2: -0.0290
      Episode_Reward/ang_vel_xy_l2: -0.1027
     Episode_Reward/dof_torques_l2: -0.0018
         Episode_Reward/dof_acc_l2: -0.0447
     Episode_Reward/action_rate_l2: -0.0875
      Episode_Reward/feet_air_time: -0.0131
Episode_Reward/flat_orientation_l2: -0.0994
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.7222
Metrics/base_velocity/error_vel_xy: 0.7326
Metrics/base_velocity/error_vel_yaw: 0.7193
      Episode_Termination/time_out: 0.2707
  Episode_Termination/base_contact: 0.7273
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 2.25s
                      Time elapsed: 00:01:34
                               ETA: 00:17:11

################################################################################
                      [1m Learning iteration 42/500 [0m                       

                       Computation: 43645 steps/s (collection: 2.106s, learning 0.147s)
             Mean action noise std: 0.72
          Mean value_function loss: 0.0067
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 13.0594
                       Mean reward: -1.91
               Mean episode length: 545.25
Episode_Reward/track_lin_vel_xy_exp: 0.1001
Episode_Reward/track_ang_vel_z_exp: 0.0974
       Episode_Reward/lin_vel_z_l2: -0.0275
      Episode_Reward/ang_vel_xy_l2: -0.0880
     Episode_Reward/dof_torques_l2: -0.0017
         Episode_Reward/dof_acc_l2: -0.0363
     Episode_Reward/action_rate_l2: -0.0766
      Episode_Reward/feet_air_time: -0.0110
Episode_Reward/flat_orientation_l2: -0.0453
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.6964
Metrics/base_velocity/error_vel_xy: 0.7304
Metrics/base_velocity/error_vel_yaw: 0.6320
      Episode_Termination/time_out: 0.2685
  Episode_Termination/base_contact: 0.7318
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 2.25s
                      Time elapsed: 00:01:36
                               ETA: 00:17:09

################################################################################
                      [1m Learning iteration 43/500 [0m                       

                       Computation: 43747 steps/s (collection: 2.104s, learning 0.143s)
             Mean action noise std: 0.72
          Mean value_function loss: 0.0064
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 13.0223
                       Mean reward: -1.23
               Mean episode length: 439.87
Episode_Reward/track_lin_vel_xy_exp: 0.1066
Episode_Reward/track_ang_vel_z_exp: 0.0928
       Episode_Reward/lin_vel_z_l2: -0.0246
      Episode_Reward/ang_vel_xy_l2: -0.0775
     Episode_Reward/dof_torques_l2: -0.0015
         Episode_Reward/dof_acc_l2: -0.0329
     Episode_Reward/action_rate_l2: -0.0680
      Episode_Reward/feet_air_time: -0.0101
Episode_Reward/flat_orientation_l2: -0.0515
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.6717
Metrics/base_velocity/error_vel_xy: 0.6156
Metrics/base_velocity/error_vel_yaw: 0.5426
      Episode_Termination/time_out: 0.2641
  Episode_Termination/base_contact: 0.7361
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 2.25s
                      Time elapsed: 00:01:38
                               ETA: 00:17:07

################################################################################
                      [1m Learning iteration 44/500 [0m                       

                       Computation: 43857 steps/s (collection: 2.096s, learning 0.146s)
             Mean action noise std: 0.72
          Mean value_function loss: 0.0074
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 12.9651
                       Mean reward: -1.69
               Mean episode length: 503.67
Episode_Reward/track_lin_vel_xy_exp: 0.1027
Episode_Reward/track_ang_vel_z_exp: 0.1108
       Episode_Reward/lin_vel_z_l2: -0.0268
      Episode_Reward/ang_vel_xy_l2: -0.0916
     Episode_Reward/dof_torques_l2: -0.0018
         Episode_Reward/dof_acc_l2: -0.0389
     Episode_Reward/action_rate_l2: -0.0808
      Episode_Reward/feet_air_time: -0.0124
Episode_Reward/flat_orientation_l2: -0.0614
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.6492
Metrics/base_velocity/error_vel_xy: 0.7876
Metrics/base_velocity/error_vel_yaw: 0.6443
      Episode_Termination/time_out: 0.2571
  Episode_Termination/base_contact: 0.7432
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 2.24s
                      Time elapsed: 00:01:41
                               ETA: 00:17:05

################################################################################
                      [1m Learning iteration 45/500 [0m                       

                       Computation: 43508 steps/s (collection: 2.116s, learning 0.143s)
             Mean action noise std: 0.72
          Mean value_function loss: 0.0071
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 12.9542
                       Mean reward: -1.47
               Mean episode length: 497.47
Episode_Reward/track_lin_vel_xy_exp: 0.0973
Episode_Reward/track_ang_vel_z_exp: 0.1059
       Episode_Reward/lin_vel_z_l2: -0.0260
      Episode_Reward/ang_vel_xy_l2: -0.0891
     Episode_Reward/dof_torques_l2: -0.0017
         Episode_Reward/dof_acc_l2: -0.0385
     Episode_Reward/action_rate_l2: -0.0778
      Episode_Reward/feet_air_time: -0.0122
Episode_Reward/flat_orientation_l2: -0.0411
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.6261
Metrics/base_velocity/error_vel_xy: 0.8037
Metrics/base_velocity/error_vel_yaw: 0.6605
      Episode_Termination/time_out: 0.2525
  Episode_Termination/base_contact: 0.7477
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 2.26s
                      Time elapsed: 00:01:43
                               ETA: 00:17:02

################################################################################
                      [1m Learning iteration 46/500 [0m                       

                       Computation: 43612 steps/s (collection: 2.111s, learning 0.143s)
             Mean action noise std: 0.71
          Mean value_function loss: 0.0069
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 12.9039
                       Mean reward: -1.01
               Mean episode length: 545.25
Episode_Reward/track_lin_vel_xy_exp: 0.1207
Episode_Reward/track_ang_vel_z_exp: 0.1157
       Episode_Reward/lin_vel_z_l2: -0.0263
      Episode_Reward/ang_vel_xy_l2: -0.0909
     Episode_Reward/dof_torques_l2: -0.0018
         Episode_Reward/dof_acc_l2: -0.0368
     Episode_Reward/action_rate_l2: -0.0810
      Episode_Reward/feet_air_time: -0.0121
Episode_Reward/flat_orientation_l2: -0.0532
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.6027
Metrics/base_velocity/error_vel_xy: 0.8166
Metrics/base_velocity/error_vel_yaw: 0.6684
      Episode_Termination/time_out: 0.2496
  Episode_Termination/base_contact: 0.7506
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 2.25s
                      Time elapsed: 00:01:45
                               ETA: 00:17:00

################################################################################
                      [1m Learning iteration 47/500 [0m                       

                       Computation: 43870 steps/s (collection: 2.098s, learning 0.143s)
             Mean action noise std: 0.71
          Mean value_function loss: 0.0087
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 12.8727
                       Mean reward: -0.60
               Mean episode length: 440.87
Episode_Reward/track_lin_vel_xy_exp: 0.1120
Episode_Reward/track_ang_vel_z_exp: 0.1106
       Episode_Reward/lin_vel_z_l2: -0.0240
      Episode_Reward/ang_vel_xy_l2: -0.0800
     Episode_Reward/dof_torques_l2: -0.0016
         Episode_Reward/dof_acc_l2: -0.0330
     Episode_Reward/action_rate_l2: -0.0710
      Episode_Reward/feet_air_time: -0.0107
Episode_Reward/flat_orientation_l2: -0.0464
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.5814
Metrics/base_velocity/error_vel_xy: 0.7065
Metrics/base_velocity/error_vel_yaw: 0.5648
      Episode_Termination/time_out: 0.2444
  Episode_Termination/base_contact: 0.7558
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 2.24s
                      Time elapsed: 00:01:47
                               ETA: 00:16:58

################################################################################
                      [1m Learning iteration 48/500 [0m                       

                       Computation: 43604 steps/s (collection: 2.110s, learning 0.144s)
             Mean action noise std: 0.71
          Mean value_function loss: 0.0087
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 12.8243
                       Mean reward: -0.84
               Mean episode length: 507.32
Episode_Reward/track_lin_vel_xy_exp: 0.1132
Episode_Reward/track_ang_vel_z_exp: 0.1078
       Episode_Reward/lin_vel_z_l2: -0.0240
      Episode_Reward/ang_vel_xy_l2: -0.0829
     Episode_Reward/dof_torques_l2: -0.0017
         Episode_Reward/dof_acc_l2: -0.0320
     Episode_Reward/action_rate_l2: -0.0745
      Episode_Reward/feet_air_time: -0.0112
Episode_Reward/flat_orientation_l2: -0.0364
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.5601
Metrics/base_velocity/error_vel_xy: 0.7892
Metrics/base_velocity/error_vel_yaw: 0.6604
      Episode_Termination/time_out: 0.2385
  Episode_Termination/base_contact: 0.7617
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 2.25s
                      Time elapsed: 00:01:50
                               ETA: 00:16:56

################################################################################
                      [1m Learning iteration 49/500 [0m                       

                       Computation: 43667 steps/s (collection: 2.108s, learning 0.143s)
             Mean action noise std: 0.71
          Mean value_function loss: 0.0076
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 12.7774
                       Mean reward: -0.30
               Mean episode length: 449.68
Episode_Reward/track_lin_vel_xy_exp: 0.1017
Episode_Reward/track_ang_vel_z_exp: 0.1069
       Episode_Reward/lin_vel_z_l2: -0.0219
      Episode_Reward/ang_vel_xy_l2: -0.0714
     Episode_Reward/dof_torques_l2: -0.0016
         Episode_Reward/dof_acc_l2: -0.0276
     Episode_Reward/action_rate_l2: -0.0655
      Episode_Reward/feet_air_time: -0.0094
Episode_Reward/flat_orientation_l2: -0.0281
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.5410
Metrics/base_velocity/error_vel_xy: 0.6910
Metrics/base_velocity/error_vel_yaw: 0.5443
      Episode_Termination/time_out: 0.2350
  Episode_Termination/base_contact: 0.7653
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 2.25s
                      Time elapsed: 00:01:52
                               ETA: 00:16:53

################################################################################
                      [1m Learning iteration 50/500 [0m                       

                       Computation: 43312 steps/s (collection: 2.125s, learning 0.145s)
             Mean action noise std: 0.71
          Mean value_function loss: 0.0085
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 12.7784
                       Mean reward: -0.08
               Mean episode length: 513.37
Episode_Reward/track_lin_vel_xy_exp: 0.1280
Episode_Reward/track_ang_vel_z_exp: 0.1175
       Episode_Reward/lin_vel_z_l2: -0.0228
      Episode_Reward/ang_vel_xy_l2: -0.0775
     Episode_Reward/dof_torques_l2: -0.0016
         Episode_Reward/dof_acc_l2: -0.0314
     Episode_Reward/action_rate_l2: -0.0702
      Episode_Reward/feet_air_time: -0.0109
Episode_Reward/flat_orientation_l2: -0.0368
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.5221
Metrics/base_velocity/error_vel_xy: 0.7173
Metrics/base_velocity/error_vel_yaw: 0.5673
      Episode_Termination/time_out: 0.2309
  Episode_Termination/base_contact: 0.7693
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 2.27s
                      Time elapsed: 00:01:54
                               ETA: 00:16:51

################################################################################
                      [1m Learning iteration 51/500 [0m                       

                       Computation: 43233 steps/s (collection: 2.128s, learning 0.146s)
             Mean action noise std: 0.70
          Mean value_function loss: 0.0067
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 12.7407
                       Mean reward: 0.20
               Mean episode length: 462.77
Episode_Reward/track_lin_vel_xy_exp: 0.1217
Episode_Reward/track_ang_vel_z_exp: 0.1100
       Episode_Reward/lin_vel_z_l2: -0.0215
      Episode_Reward/ang_vel_xy_l2: -0.0703
     Episode_Reward/dof_torques_l2: -0.0015
         Episode_Reward/dof_acc_l2: -0.0288
     Episode_Reward/action_rate_l2: -0.0648
      Episode_Reward/feet_air_time: -0.0095
Episode_Reward/flat_orientation_l2: -0.0533
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.4999
Metrics/base_velocity/error_vel_xy: 0.6603
Metrics/base_velocity/error_vel_yaw: 0.5406
      Episode_Termination/time_out: 0.2275
  Episode_Termination/base_contact: 0.7727
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 2.27s
                      Time elapsed: 00:01:56
                               ETA: 00:16:49

################################################################################
                      [1m Learning iteration 52/500 [0m                       

                       Computation: 43250 steps/s (collection: 2.126s, learning 0.147s)
             Mean action noise std: 0.70
          Mean value_function loss: 0.0064
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 12.6770
                       Mean reward: 0.25
               Mean episode length: 486.91
Episode_Reward/track_lin_vel_xy_exp: 0.0946
Episode_Reward/track_ang_vel_z_exp: 0.1093
       Episode_Reward/lin_vel_z_l2: -0.0203
      Episode_Reward/ang_vel_xy_l2: -0.0643
     Episode_Reward/dof_torques_l2: -0.0015
         Episode_Reward/dof_acc_l2: -0.0257
     Episode_Reward/action_rate_l2: -0.0606
      Episode_Reward/feet_air_time: -0.0087
Episode_Reward/flat_orientation_l2: -0.0227
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.4809
Metrics/base_velocity/error_vel_xy: 0.6780
Metrics/base_velocity/error_vel_yaw: 0.4842
      Episode_Termination/time_out: 0.2221
  Episode_Termination/base_contact: 0.7782
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 2.27s
                      Time elapsed: 00:01:59
                               ETA: 00:16:47

################################################################################
                      [1m Learning iteration 53/500 [0m                       

                       Computation: 43467 steps/s (collection: 2.119s, learning 0.143s)
             Mean action noise std: 0.70
          Mean value_function loss: 0.0073
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 12.6277
                       Mean reward: 0.71
               Mean episode length: 450.13
Episode_Reward/track_lin_vel_xy_exp: 0.1309
Episode_Reward/track_ang_vel_z_exp: 0.1134
       Episode_Reward/lin_vel_z_l2: -0.0205
      Episode_Reward/ang_vel_xy_l2: -0.0668
     Episode_Reward/dof_torques_l2: -0.0014
         Episode_Reward/dof_acc_l2: -0.0270
     Episode_Reward/action_rate_l2: -0.0620
      Episode_Reward/feet_air_time: -0.0088
Episode_Reward/flat_orientation_l2: -0.0245
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.4603
Metrics/base_velocity/error_vel_xy: 0.6170
Metrics/base_velocity/error_vel_yaw: 0.4826
      Episode_Termination/time_out: 0.2179
  Episode_Termination/base_contact: 0.7823
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 2.26s
                      Time elapsed: 00:02:01
                               ETA: 00:16:45

################################################################################
                      [1m Learning iteration 54/500 [0m                       

                       Computation: 43170 steps/s (collection: 2.134s, learning 0.143s)
             Mean action noise std: 0.69
          Mean value_function loss: 0.0062
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 12.5793
                       Mean reward: -0.04
               Mean episode length: 507.16
Episode_Reward/track_lin_vel_xy_exp: 0.1042
Episode_Reward/track_ang_vel_z_exp: 0.1235
       Episode_Reward/lin_vel_z_l2: -0.0215
      Episode_Reward/ang_vel_xy_l2: -0.0729
     Episode_Reward/dof_torques_l2: -0.0016
         Episode_Reward/dof_acc_l2: -0.0296
     Episode_Reward/action_rate_l2: -0.0679
      Episode_Reward/feet_air_time: -0.0104
Episode_Reward/flat_orientation_l2: -0.0303
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.4387
Metrics/base_velocity/error_vel_xy: 0.7630
Metrics/base_velocity/error_vel_yaw: 0.5328
      Episode_Termination/time_out: 0.2156
  Episode_Termination/base_contact: 0.7847
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 2.28s
                      Time elapsed: 00:02:03
                               ETA: 00:16:43

################################################################################
                      [1m Learning iteration 55/500 [0m                       

                       Computation: 43587 steps/s (collection: 2.114s, learning 0.142s)
             Mean action noise std: 0.69
          Mean value_function loss: 0.0060
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 12.5558
                       Mean reward: 0.26
               Mean episode length: 534.63
Episode_Reward/track_lin_vel_xy_exp: 0.1312
Episode_Reward/track_ang_vel_z_exp: 0.1355
       Episode_Reward/lin_vel_z_l2: -0.0222
      Episode_Reward/ang_vel_xy_l2: -0.0770
     Episode_Reward/dof_torques_l2: -0.0016
         Episode_Reward/dof_acc_l2: -0.0312
     Episode_Reward/action_rate_l2: -0.0712
      Episode_Reward/feet_air_time: -0.0109
Episode_Reward/flat_orientation_l2: -0.0296
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.4143
Metrics/base_velocity/error_vel_xy: 0.7332
Metrics/base_velocity/error_vel_yaw: 0.5259
      Episode_Termination/time_out: 0.2145
  Episode_Termination/base_contact: 0.7858
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 2.26s
                      Time elapsed: 00:02:06
                               ETA: 00:16:41

################################################################################
                      [1m Learning iteration 56/500 [0m                       

                       Computation: 43187 steps/s (collection: 2.127s, learning 0.150s)
             Mean action noise std: 0.69
          Mean value_function loss: 0.0064
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 12.5220
                       Mean reward: -0.07
               Mean episode length: 431.73
Episode_Reward/track_lin_vel_xy_exp: 0.1006
Episode_Reward/track_ang_vel_z_exp: 0.1097
       Episode_Reward/lin_vel_z_l2: -0.0209
      Episode_Reward/ang_vel_xy_l2: -0.0690
     Episode_Reward/dof_torques_l2: -0.0015
         Episode_Reward/dof_acc_l2: -0.0284
     Episode_Reward/action_rate_l2: -0.0640
      Episode_Reward/feet_air_time: -0.0096
Episode_Reward/flat_orientation_l2: -0.0251
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.3916
Metrics/base_velocity/error_vel_xy: 0.7090
Metrics/base_velocity/error_vel_yaw: 0.5509
      Episode_Termination/time_out: 0.2127
  Episode_Termination/base_contact: 0.7876
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 2.28s
                      Time elapsed: 00:02:08
                               ETA: 00:16:39

################################################################################
                      [1m Learning iteration 57/500 [0m                       

                       Computation: 43475 steps/s (collection: 2.117s, learning 0.144s)
             Mean action noise std: 0.69
          Mean value_function loss: 0.0066
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 12.4764
                       Mean reward: 0.81
               Mean episode length: 542.77
Episode_Reward/track_lin_vel_xy_exp: 0.1286
Episode_Reward/track_ang_vel_z_exp: 0.1387
       Episode_Reward/lin_vel_z_l2: -0.0216
      Episode_Reward/ang_vel_xy_l2: -0.0784
     Episode_Reward/dof_torques_l2: -0.0018
         Episode_Reward/dof_acc_l2: -0.0303
     Episode_Reward/action_rate_l2: -0.0731
      Episode_Reward/feet_air_time: -0.0113
Episode_Reward/flat_orientation_l2: -0.0295
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.3695
Metrics/base_velocity/error_vel_xy: 0.7865
Metrics/base_velocity/error_vel_yaw: 0.5767
      Episode_Termination/time_out: 0.2096
  Episode_Termination/base_contact: 0.7906
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 2.26s
                      Time elapsed: 00:02:10
                               ETA: 00:16:37

################################################################################
                      [1m Learning iteration 58/500 [0m                       

                       Computation: 43626 steps/s (collection: 2.111s, learning 0.142s)
             Mean action noise std: 0.69
          Mean value_function loss: 0.0048
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 12.4363
                       Mean reward: 0.17
               Mean episode length: 474.96
Episode_Reward/track_lin_vel_xy_exp: 0.0898
Episode_Reward/track_ang_vel_z_exp: 0.1108
       Episode_Reward/lin_vel_z_l2: -0.0203
      Episode_Reward/ang_vel_xy_l2: -0.0626
     Episode_Reward/dof_torques_l2: -0.0015
         Episode_Reward/dof_acc_l2: -0.0251
     Episode_Reward/action_rate_l2: -0.0599
      Episode_Reward/feet_air_time: -0.0088
Episode_Reward/flat_orientation_l2: -0.0234
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.3473
Metrics/base_velocity/error_vel_xy: 0.7031
Metrics/base_velocity/error_vel_yaw: 0.5068
      Episode_Termination/time_out: 0.2092
  Episode_Termination/base_contact: 0.7910
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 2.25s
                      Time elapsed: 00:02:12
                               ETA: 00:16:34

################################################################################
                      [1m Learning iteration 59/500 [0m                       

                       Computation: 43474 steps/s (collection: 2.118s, learning 0.143s)
             Mean action noise std: 0.68
          Mean value_function loss: 0.0056
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 12.3811
                       Mean reward: 0.55
               Mean episode length: 539.55
Episode_Reward/track_lin_vel_xy_exp: 0.1320
Episode_Reward/track_ang_vel_z_exp: 0.1377
       Episode_Reward/lin_vel_z_l2: -0.0214
      Episode_Reward/ang_vel_xy_l2: -0.0756
     Episode_Reward/dof_torques_l2: -0.0018
         Episode_Reward/dof_acc_l2: -0.0299
     Episode_Reward/action_rate_l2: -0.0722
      Episode_Reward/feet_air_time: -0.0109
Episode_Reward/flat_orientation_l2: -0.0254
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.3286
Metrics/base_velocity/error_vel_xy: 0.7669
Metrics/base_velocity/error_vel_yaw: 0.5886
      Episode_Termination/time_out: 0.2094
  Episode_Termination/base_contact: 0.7909
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 2.26s
                      Time elapsed: 00:02:15
                               ETA: 00:16:32

################################################################################
                      [1m Learning iteration 60/500 [0m                       

                       Computation: 43136 steps/s (collection: 2.134s, learning 0.145s)
             Mean action noise std: 0.68
          Mean value_function loss: 0.0064
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 12.3456
                       Mean reward: 0.88
               Mean episode length: 565.25
Episode_Reward/track_lin_vel_xy_exp: 0.1186
Episode_Reward/track_ang_vel_z_exp: 0.1467
       Episode_Reward/lin_vel_z_l2: -0.0211
      Episode_Reward/ang_vel_xy_l2: -0.0751
     Episode_Reward/dof_torques_l2: -0.0018
         Episode_Reward/dof_acc_l2: -0.0291
     Episode_Reward/action_rate_l2: -0.0723
      Episode_Reward/feet_air_time: -0.0102
Episode_Reward/flat_orientation_l2: -0.0256
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.3137
Metrics/base_velocity/error_vel_xy: 0.8202
Metrics/base_velocity/error_vel_yaw: 0.5402
      Episode_Termination/time_out: 0.2094
  Episode_Termination/base_contact: 0.7909
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 2.28s
                      Time elapsed: 00:02:17
                               ETA: 00:16:30

################################################################################
                      [1m Learning iteration 61/500 [0m                       

                       Computation: 43050 steps/s (collection: 2.141s, learning 0.142s)
             Mean action noise std: 0.68
          Mean value_function loss: 0.0079
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 12.2881
                       Mean reward: 1.56
               Mean episode length: 626.96
Episode_Reward/track_lin_vel_xy_exp: 0.1690
Episode_Reward/track_ang_vel_z_exp: 0.1490
       Episode_Reward/lin_vel_z_l2: -0.0214
      Episode_Reward/ang_vel_xy_l2: -0.0785
     Episode_Reward/dof_torques_l2: -0.0018
         Episode_Reward/dof_acc_l2: -0.0298
     Episode_Reward/action_rate_l2: -0.0741
      Episode_Reward/feet_air_time: -0.0108
Episode_Reward/flat_orientation_l2: -0.0242
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.2986
Metrics/base_velocity/error_vel_xy: 0.7231
Metrics/base_velocity/error_vel_yaw: 0.5582
      Episode_Termination/time_out: 0.2108
  Episode_Termination/base_contact: 0.7894
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 2.28s
                      Time elapsed: 00:02:19
                               ETA: 00:16:28

################################################################################
                      [1m Learning iteration 62/500 [0m                       

                       Computation: 43117 steps/s (collection: 2.136s, learning 0.144s)
             Mean action noise std: 0.68
          Mean value_function loss: 0.0052
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 12.2796
                       Mean reward: 1.27
               Mean episode length: 599.30
Episode_Reward/track_lin_vel_xy_exp: 0.1529
Episode_Reward/track_ang_vel_z_exp: 0.1655
       Episode_Reward/lin_vel_z_l2: -0.0218
      Episode_Reward/ang_vel_xy_l2: -0.0809
     Episode_Reward/dof_torques_l2: -0.0019
         Episode_Reward/dof_acc_l2: -0.0320
     Episode_Reward/action_rate_l2: -0.0782
      Episode_Reward/feet_air_time: -0.0121
Episode_Reward/flat_orientation_l2: -0.0250
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.2818
Metrics/base_velocity/error_vel_xy: 0.8517
Metrics/base_velocity/error_vel_yaw: 0.5708
      Episode_Termination/time_out: 0.2138
  Episode_Termination/base_contact: 0.7865
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 2.28s
                      Time elapsed: 00:02:21
                               ETA: 00:16:26

################################################################################
                      [1m Learning iteration 63/500 [0m                       

                       Computation: 43225 steps/s (collection: 2.130s, learning 0.144s)
             Mean action noise std: 0.68
          Mean value_function loss: 0.0066
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 12.2342
                       Mean reward: 1.37
               Mean episode length: 664.01
Episode_Reward/track_lin_vel_xy_exp: 0.1639
Episode_Reward/track_ang_vel_z_exp: 0.1753
       Episode_Reward/lin_vel_z_l2: -0.0224
      Episode_Reward/ang_vel_xy_l2: -0.0866
     Episode_Reward/dof_torques_l2: -0.0021
         Episode_Reward/dof_acc_l2: -0.0327
     Episode_Reward/action_rate_l2: -0.0840
      Episode_Reward/feet_air_time: -0.0121
Episode_Reward/flat_orientation_l2: -0.0268
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.2624
Metrics/base_velocity/error_vel_xy: 0.9028
Metrics/base_velocity/error_vel_yaw: 0.6269
      Episode_Termination/time_out: 0.2184
  Episode_Termination/base_contact: 0.7818
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 2.27s
                      Time elapsed: 00:02:24
                               ETA: 00:16:24

################################################################################
                      [1m Learning iteration 64/500 [0m                       

                       Computation: 43615 steps/s (collection: 2.110s, learning 0.144s)
             Mean action noise std: 0.68
          Mean value_function loss: 0.0056
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 12.2166
                       Mean reward: 1.06
               Mean episode length: 658.64
Episode_Reward/track_lin_vel_xy_exp: 0.1453
Episode_Reward/track_ang_vel_z_exp: 0.1697
       Episode_Reward/lin_vel_z_l2: -0.0223
      Episode_Reward/ang_vel_xy_l2: -0.0851
     Episode_Reward/dof_torques_l2: -0.0021
         Episode_Reward/dof_acc_l2: -0.0319
     Episode_Reward/action_rate_l2: -0.0829
      Episode_Reward/feet_air_time: -0.0125
Episode_Reward/flat_orientation_l2: -0.0266
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.2378
Metrics/base_velocity/error_vel_xy: 0.9313
Metrics/base_velocity/error_vel_yaw: 0.6462
      Episode_Termination/time_out: 0.2280
  Episode_Termination/base_contact: 0.7722
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 2.25s
                      Time elapsed: 00:02:26
                               ETA: 00:16:22

################################################################################
                      [1m Learning iteration 65/500 [0m                       

                       Computation: 43528 steps/s (collection: 2.116s, learning 0.143s)
             Mean action noise std: 0.67
          Mean value_function loss: 0.0066
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 12.1851
                       Mean reward: 2.45
               Mean episode length: 724.51
Episode_Reward/track_lin_vel_xy_exp: 0.2059
Episode_Reward/track_ang_vel_z_exp: 0.1978
       Episode_Reward/lin_vel_z_l2: -0.0244
      Episode_Reward/ang_vel_xy_l2: -0.0970
     Episode_Reward/dof_torques_l2: -0.0024
         Episode_Reward/dof_acc_l2: -0.0359
     Episode_Reward/action_rate_l2: -0.0945
      Episode_Reward/feet_air_time: -0.0141
Episode_Reward/flat_orientation_l2: -0.0275
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.2152
Metrics/base_velocity/error_vel_xy: 0.9914
Metrics/base_velocity/error_vel_yaw: 0.7204
      Episode_Termination/time_out: 0.2373
  Episode_Termination/base_contact: 0.7630
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 2.26s
                      Time elapsed: 00:02:28
                               ETA: 00:16:20

################################################################################
                      [1m Learning iteration 66/500 [0m                       

                       Computation: 43445 steps/s (collection: 2.119s, learning 0.143s)
             Mean action noise std: 0.67
          Mean value_function loss: 0.0072
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 12.1728
                       Mean reward: 1.70
               Mean episode length: 649.02
Episode_Reward/track_lin_vel_xy_exp: 0.1567
Episode_Reward/track_ang_vel_z_exp: 0.1818
       Episode_Reward/lin_vel_z_l2: -0.0230
      Episode_Reward/ang_vel_xy_l2: -0.0875
     Episode_Reward/dof_torques_l2: -0.0021
         Episode_Reward/dof_acc_l2: -0.0333
     Episode_Reward/action_rate_l2: -0.0855
      Episode_Reward/feet_air_time: -0.0127
Episode_Reward/flat_orientation_l2: -0.0460
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.1901
Metrics/base_velocity/error_vel_xy: 0.9683
Metrics/base_velocity/error_vel_yaw: 0.6605
      Episode_Termination/time_out: 0.2497
  Episode_Termination/base_contact: 0.7505
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 2.26s
                      Time elapsed: 00:02:30
                               ETA: 00:16:17

################################################################################
                      [1m Learning iteration 67/500 [0m                       

                       Computation: 43441 steps/s (collection: 2.120s, learning 0.143s)
             Mean action noise std: 0.67
          Mean value_function loss: 0.0062
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 12.1462
                       Mean reward: 1.43
               Mean episode length: 659.91
Episode_Reward/track_lin_vel_xy_exp: 0.1771
Episode_Reward/track_ang_vel_z_exp: 0.1932
       Episode_Reward/lin_vel_z_l2: -0.0233
      Episode_Reward/ang_vel_xy_l2: -0.0920
     Episode_Reward/dof_torques_l2: -0.0023
         Episode_Reward/dof_acc_l2: -0.0353
     Episode_Reward/action_rate_l2: -0.0908
      Episode_Reward/feet_air_time: -0.0139
Episode_Reward/flat_orientation_l2: -0.0252
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.1669
Metrics/base_velocity/error_vel_xy: 1.0092
Metrics/base_velocity/error_vel_yaw: 0.7051
      Episode_Termination/time_out: 0.2615
  Episode_Termination/base_contact: 0.7385
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 2.26s
                      Time elapsed: 00:02:33
                               ETA: 00:16:15

################################################################################
                      [1m Learning iteration 68/500 [0m                       

                       Computation: 43457 steps/s (collection: 2.118s, learning 0.144s)
             Mean action noise std: 0.67
          Mean value_function loss: 0.0083
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 12.1309
                       Mean reward: 1.63
               Mean episode length: 700.39
Episode_Reward/track_lin_vel_xy_exp: 0.1924
Episode_Reward/track_ang_vel_z_exp: 0.1930
       Episode_Reward/lin_vel_z_l2: -0.0235
      Episode_Reward/ang_vel_xy_l2: -0.0927
     Episode_Reward/dof_torques_l2: -0.0023
         Episode_Reward/dof_acc_l2: -0.0352
     Episode_Reward/action_rate_l2: -0.0913
      Episode_Reward/feet_air_time: -0.0133
Episode_Reward/flat_orientation_l2: -0.0246
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.1400
Metrics/base_velocity/error_vel_xy: 0.9932
Metrics/base_velocity/error_vel_yaw: 0.7209
      Episode_Termination/time_out: 0.2795
  Episode_Termination/base_contact: 0.7205
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 2.26s
                      Time elapsed: 00:02:35
                               ETA: 00:16:13

################################################################################
                      [1m Learning iteration 69/500 [0m                       

                       Computation: 43426 steps/s (collection: 2.121s, learning 0.143s)
             Mean action noise std: 0.67
          Mean value_function loss: 0.0076
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 12.1378
                       Mean reward: 2.53
               Mean episode length: 794.00
Episode_Reward/track_lin_vel_xy_exp: 0.2050
Episode_Reward/track_ang_vel_z_exp: 0.2142
       Episode_Reward/lin_vel_z_l2: -0.0242
      Episode_Reward/ang_vel_xy_l2: -0.0982
     Episode_Reward/dof_torques_l2: -0.0025
         Episode_Reward/dof_acc_l2: -0.0371
     Episode_Reward/action_rate_l2: -0.0975
      Episode_Reward/feet_air_time: -0.0139
Episode_Reward/flat_orientation_l2: -0.0248
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.1110
Metrics/base_velocity/error_vel_xy: 1.0894
Metrics/base_velocity/error_vel_yaw: 0.7524
      Episode_Termination/time_out: 0.3046
  Episode_Termination/base_contact: 0.6954
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 2.26s
                      Time elapsed: 00:02:37
                               ETA: 00:16:11

################################################################################
                      [1m Learning iteration 70/500 [0m                       

                       Computation: 43180 steps/s (collection: 2.132s, learning 0.144s)
             Mean action noise std: 0.67
          Mean value_function loss: 0.0065
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 12.1102
                       Mean reward: 2.35
               Mean episode length: 745.85
Episode_Reward/track_lin_vel_xy_exp: 0.1783
Episode_Reward/track_ang_vel_z_exp: 0.2067
       Episode_Reward/lin_vel_z_l2: -0.0231
      Episode_Reward/ang_vel_xy_l2: -0.0913
     Episode_Reward/dof_torques_l2: -0.0023
         Episode_Reward/dof_acc_l2: -0.0353
     Episode_Reward/action_rate_l2: -0.0910
      Episode_Reward/feet_air_time: -0.0136
Episode_Reward/flat_orientation_l2: -0.0251
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.0847
Metrics/base_velocity/error_vel_xy: 1.0245
Metrics/base_velocity/error_vel_yaw: 0.6702
      Episode_Termination/time_out: 0.3281
  Episode_Termination/base_contact: 0.6719
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 2.28s
                      Time elapsed: 00:02:40
                               ETA: 00:16:09

################################################################################
                      [1m Learning iteration 71/500 [0m                       

                       Computation: 43303 steps/s (collection: 2.125s, learning 0.145s)
             Mean action noise std: 0.67
          Mean value_function loss: 0.0079
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 12.0789
                       Mean reward: 2.03
               Mean episode length: 660.69
Episode_Reward/track_lin_vel_xy_exp: 0.1779
Episode_Reward/track_ang_vel_z_exp: 0.1899
       Episode_Reward/lin_vel_z_l2: -0.0218
      Episode_Reward/ang_vel_xy_l2: -0.0826
     Episode_Reward/dof_torques_l2: -0.0022
         Episode_Reward/dof_acc_l2: -0.0321
     Episode_Reward/action_rate_l2: -0.0832
      Episode_Reward/feet_air_time: -0.0126
Episode_Reward/flat_orientation_l2: -0.0221
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.0600
Metrics/base_velocity/error_vel_xy: 0.9161
Metrics/base_velocity/error_vel_yaw: 0.6283
      Episode_Termination/time_out: 0.3494
  Episode_Termination/base_contact: 0.6506
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 2.27s
                      Time elapsed: 00:02:42
                               ETA: 00:16:07

################################################################################
                      [1m Learning iteration 72/500 [0m                       

                       Computation: 43440 steps/s (collection: 2.119s, learning 0.144s)
             Mean action noise std: 0.67
          Mean value_function loss: 0.0064
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 12.0684
                       Mean reward: 2.04
               Mean episode length: 717.61
Episode_Reward/track_lin_vel_xy_exp: 0.1661
Episode_Reward/track_ang_vel_z_exp: 0.2017
       Episode_Reward/lin_vel_z_l2: -0.0225
      Episode_Reward/ang_vel_xy_l2: -0.0900
     Episode_Reward/dof_torques_l2: -0.0024
         Episode_Reward/dof_acc_l2: -0.0339
     Episode_Reward/action_rate_l2: -0.0899
      Episode_Reward/feet_air_time: -0.0133
Episode_Reward/flat_orientation_l2: -0.0244
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.0379
Metrics/base_velocity/error_vel_xy: 1.0680
Metrics/base_velocity/error_vel_yaw: 0.7128
      Episode_Termination/time_out: 0.3642
  Episode_Termination/base_contact: 0.6358
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 2.26s
                      Time elapsed: 00:02:44
                               ETA: 00:16:04

################################################################################
                      [1m Learning iteration 73/500 [0m                       

                       Computation: 43512 steps/s (collection: 2.115s, learning 0.144s)
             Mean action noise std: 0.67
          Mean value_function loss: 0.0081
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 12.0559
                       Mean reward: 1.98
               Mean episode length: 723.10
Episode_Reward/track_lin_vel_xy_exp: 0.1713
Episode_Reward/track_ang_vel_z_exp: 0.1934
       Episode_Reward/lin_vel_z_l2: -0.0211
      Episode_Reward/ang_vel_xy_l2: -0.0820
     Episode_Reward/dof_torques_l2: -0.0022
         Episode_Reward/dof_acc_l2: -0.0306
     Episode_Reward/action_rate_l2: -0.0825
      Episode_Reward/feet_air_time: -0.0123
Episode_Reward/flat_orientation_l2: -0.0207
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.0154
Metrics/base_velocity/error_vel_xy: 0.9479
Metrics/base_velocity/error_vel_yaw: 0.6176
      Episode_Termination/time_out: 0.3770
  Episode_Termination/base_contact: 0.6230
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 2.26s
                      Time elapsed: 00:02:46
                               ETA: 00:16:02

################################################################################
                      [1m Learning iteration 74/500 [0m                       

                       Computation: 43465 steps/s (collection: 2.119s, learning 0.142s)
             Mean action noise std: 0.67
          Mean value_function loss: 0.0073
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 12.0481
                       Mean reward: 2.40
               Mean episode length: 701.97
Episode_Reward/track_lin_vel_xy_exp: 0.1766
Episode_Reward/track_ang_vel_z_exp: 0.2042
       Episode_Reward/lin_vel_z_l2: -0.0218
      Episode_Reward/ang_vel_xy_l2: -0.0851
     Episode_Reward/dof_torques_l2: -0.0023
         Episode_Reward/dof_acc_l2: -0.0328
     Episode_Reward/action_rate_l2: -0.0870
      Episode_Reward/feet_air_time: -0.0128
Episode_Reward/flat_orientation_l2: -0.0220
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.9931
Metrics/base_velocity/error_vel_xy: 0.9997
Metrics/base_velocity/error_vel_yaw: 0.6615
      Episode_Termination/time_out: 0.3911
  Episode_Termination/base_contact: 0.6089
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 2.26s
                      Time elapsed: 00:02:49
                               ETA: 00:16:00

################################################################################
                      [1m Learning iteration 75/500 [0m                       

                       Computation: 43522 steps/s (collection: 2.114s, learning 0.145s)
             Mean action noise std: 0.67
          Mean value_function loss: 0.0064
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 12.0270
                       Mean reward: 2.30
               Mean episode length: 692.26
Episode_Reward/track_lin_vel_xy_exp: 0.1703
Episode_Reward/track_ang_vel_z_exp: 0.2060
       Episode_Reward/lin_vel_z_l2: -0.0213
      Episode_Reward/ang_vel_xy_l2: -0.0835
     Episode_Reward/dof_torques_l2: -0.0022
         Episode_Reward/dof_acc_l2: -0.0332
     Episode_Reward/action_rate_l2: -0.0848
      Episode_Reward/feet_air_time: -0.0134
Episode_Reward/flat_orientation_l2: -0.0227
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.9713
Metrics/base_velocity/error_vel_xy: 1.0013
Metrics/base_velocity/error_vel_yaw: 0.6116
      Episode_Termination/time_out: 0.4064
  Episode_Termination/base_contact: 0.5936
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 2.26s
                      Time elapsed: 00:02:51
                               ETA: 00:15:58

################################################################################
                      [1m Learning iteration 76/500 [0m                       

                       Computation: 43160 steps/s (collection: 2.134s, learning 0.144s)
             Mean action noise std: 0.67
          Mean value_function loss: 0.0058
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 11.9999
                       Mean reward: 2.66
               Mean episode length: 745.62
Episode_Reward/track_lin_vel_xy_exp: 0.1799
Episode_Reward/track_ang_vel_z_exp: 0.2070
       Episode_Reward/lin_vel_z_l2: -0.0211
      Episode_Reward/ang_vel_xy_l2: -0.0802
     Episode_Reward/dof_torques_l2: -0.0022
         Episode_Reward/dof_acc_l2: -0.0316
     Episode_Reward/action_rate_l2: -0.0828
      Episode_Reward/feet_air_time: -0.0127
Episode_Reward/flat_orientation_l2: -0.0208
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.9518
Metrics/base_velocity/error_vel_xy: 0.9237
Metrics/base_velocity/error_vel_yaw: 0.5913
      Episode_Termination/time_out: 0.4209
  Episode_Termination/base_contact: 0.5791
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 2.28s
                      Time elapsed: 00:02:53
                               ETA: 00:15:56

################################################################################
                      [1m Learning iteration 77/500 [0m                       

                       Computation: 43489 steps/s (collection: 2.118s, learning 0.143s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0057
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 11.9579
                       Mean reward: 2.14
               Mean episode length: 644.75
Episode_Reward/track_lin_vel_xy_exp: 0.1501
Episode_Reward/track_ang_vel_z_exp: 0.2074
       Episode_Reward/lin_vel_z_l2: -0.0210
      Episode_Reward/ang_vel_xy_l2: -0.0799
     Episode_Reward/dof_torques_l2: -0.0021
         Episode_Reward/dof_acc_l2: -0.0323
     Episode_Reward/action_rate_l2: -0.0831
      Episode_Reward/feet_air_time: -0.0136
Episode_Reward/flat_orientation_l2: -0.0217
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.9303
Metrics/base_velocity/error_vel_xy: 1.0007
Metrics/base_velocity/error_vel_yaw: 0.5850
      Episode_Termination/time_out: 0.4336
  Episode_Termination/base_contact: 0.5664
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 2.26s
                      Time elapsed: 00:02:55
                               ETA: 00:15:53

################################################################################
                      [1m Learning iteration 78/500 [0m                       

                       Computation: 43326 steps/s (collection: 2.120s, learning 0.148s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0063
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 11.9109
                       Mean reward: 2.24
               Mean episode length: 655.62
Episode_Reward/track_lin_vel_xy_exp: 0.1540
Episode_Reward/track_ang_vel_z_exp: 0.2046
       Episode_Reward/lin_vel_z_l2: -0.0199
      Episode_Reward/ang_vel_xy_l2: -0.0756
     Episode_Reward/dof_torques_l2: -0.0021
         Episode_Reward/dof_acc_l2: -0.0303
     Episode_Reward/action_rate_l2: -0.0787
      Episode_Reward/feet_air_time: -0.0121
Episode_Reward/flat_orientation_l2: -0.0204
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.9135
Metrics/base_velocity/error_vel_xy: 0.9460
Metrics/base_velocity/error_vel_yaw: 0.5191
      Episode_Termination/time_out: 0.4445
  Episode_Termination/base_contact: 0.5555
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 2.27s
                      Time elapsed: 00:02:58
                               ETA: 00:15:51

################################################################################
                      [1m Learning iteration 79/500 [0m                       

                       Computation: 43334 steps/s (collection: 2.124s, learning 0.144s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0057
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 11.8736
                       Mean reward: 3.01
               Mean episode length: 684.67
Episode_Reward/track_lin_vel_xy_exp: 0.1606
Episode_Reward/track_ang_vel_z_exp: 0.2101
       Episode_Reward/lin_vel_z_l2: -0.0203
      Episode_Reward/ang_vel_xy_l2: -0.0780
     Episode_Reward/dof_torques_l2: -0.0021
         Episode_Reward/dof_acc_l2: -0.0312
     Episode_Reward/action_rate_l2: -0.0809
      Episode_Reward/feet_air_time: -0.0125
Episode_Reward/flat_orientation_l2: -0.0197
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.8983
Metrics/base_velocity/error_vel_xy: 0.9544
Metrics/base_velocity/error_vel_yaw: 0.5380
      Episode_Termination/time_out: 0.4529
  Episode_Termination/base_contact: 0.5471
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 2.27s
                      Time elapsed: 00:03:00
                               ETA: 00:15:49

################################################################################
                      [1m Learning iteration 80/500 [0m                       

                       Computation: 43075 steps/s (collection: 2.137s, learning 0.145s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0051
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 11.8416
                       Mean reward: 2.68
               Mean episode length: 672.34
Episode_Reward/track_lin_vel_xy_exp: 0.1664
Episode_Reward/track_ang_vel_z_exp: 0.1985
       Episode_Reward/lin_vel_z_l2: -0.0201
      Episode_Reward/ang_vel_xy_l2: -0.0733
     Episode_Reward/dof_torques_l2: -0.0021
         Episode_Reward/dof_acc_l2: -0.0310
     Episode_Reward/action_rate_l2: -0.0776
      Episode_Reward/feet_air_time: -0.0122
Episode_Reward/flat_orientation_l2: -0.0205
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.8833
Metrics/base_velocity/error_vel_xy: 0.9081
Metrics/base_velocity/error_vel_yaw: 0.5514
      Episode_Termination/time_out: 0.4626
  Episode_Termination/base_contact: 0.5374
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 2.28s
                      Time elapsed: 00:03:02
                               ETA: 00:15:47

################################################################################
                      [1m Learning iteration 81/500 [0m                       

                       Computation: 43303 steps/s (collection: 2.126s, learning 0.144s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0049
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 11.8030
                       Mean reward: 2.86
               Mean episode length: 642.54
Episode_Reward/track_lin_vel_xy_exp: 0.1547
Episode_Reward/track_ang_vel_z_exp: 0.1942
       Episode_Reward/lin_vel_z_l2: -0.0189
      Episode_Reward/ang_vel_xy_l2: -0.0672
     Episode_Reward/dof_torques_l2: -0.0019
         Episode_Reward/dof_acc_l2: -0.0286
     Episode_Reward/action_rate_l2: -0.0716
      Episode_Reward/feet_air_time: -0.0112
Episode_Reward/flat_orientation_l2: -0.0218
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.8707
Metrics/base_velocity/error_vel_xy: 0.8276
Metrics/base_velocity/error_vel_yaw: 0.4521
      Episode_Termination/time_out: 0.4697
  Episode_Termination/base_contact: 0.5303
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 2.27s
                      Time elapsed: 00:03:04
                               ETA: 00:15:45

################################################################################
                      [1m Learning iteration 82/500 [0m                       

                       Computation: 43001 steps/s (collection: 2.142s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0047
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 11.7583
                       Mean reward: 2.78
               Mean episode length: 654.49
Episode_Reward/track_lin_vel_xy_exp: 0.1565
Episode_Reward/track_ang_vel_z_exp: 0.2032
       Episode_Reward/lin_vel_z_l2: -0.0193
      Episode_Reward/ang_vel_xy_l2: -0.0710
     Episode_Reward/dof_torques_l2: -0.0020
         Episode_Reward/dof_acc_l2: -0.0292
     Episode_Reward/action_rate_l2: -0.0755
      Episode_Reward/feet_air_time: -0.0119
Episode_Reward/flat_orientation_l2: -0.0178
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.8555
Metrics/base_velocity/error_vel_xy: 0.8937
Metrics/base_velocity/error_vel_yaw: 0.4992
      Episode_Termination/time_out: 0.4745
  Episode_Termination/base_contact: 0.5255
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 2.29s
                      Time elapsed: 00:03:07
                               ETA: 00:15:43

################################################################################
                      [1m Learning iteration 83/500 [0m                       

                       Computation: 42999 steps/s (collection: 2.141s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0060
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 11.7288
                       Mean reward: 3.50
               Mean episode length: 738.87
Episode_Reward/track_lin_vel_xy_exp: 0.1945
Episode_Reward/track_ang_vel_z_exp: 0.2231
       Episode_Reward/lin_vel_z_l2: -0.0210
      Episode_Reward/ang_vel_xy_l2: -0.0789
     Episode_Reward/dof_torques_l2: -0.0023
         Episode_Reward/dof_acc_l2: -0.0320
     Episode_Reward/action_rate_l2: -0.0845
      Episode_Reward/feet_air_time: -0.0122
Episode_Reward/flat_orientation_l2: -0.0203
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.8432
Metrics/base_velocity/error_vel_xy: 0.9638
Metrics/base_velocity/error_vel_yaw: 0.5993
      Episode_Termination/time_out: 0.4809
  Episode_Termination/base_contact: 0.5191
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 2.29s
                      Time elapsed: 00:03:09
                               ETA: 00:15:40

################################################################################
                      [1m Learning iteration 84/500 [0m                       

                       Computation: 43121 steps/s (collection: 2.137s, learning 0.143s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0048
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 11.6939
                       Mean reward: 3.30
               Mean episode length: 666.35
Episode_Reward/track_lin_vel_xy_exp: 0.1941
Episode_Reward/track_ang_vel_z_exp: 0.2168
       Episode_Reward/lin_vel_z_l2: -0.0197
      Episode_Reward/ang_vel_xy_l2: -0.0743
     Episode_Reward/dof_torques_l2: -0.0023
         Episode_Reward/dof_acc_l2: -0.0292
     Episode_Reward/action_rate_l2: -0.0801
      Episode_Reward/feet_air_time: -0.0111
Episode_Reward/flat_orientation_l2: -0.0198
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.8296
Metrics/base_velocity/error_vel_xy: 0.9111
Metrics/base_velocity/error_vel_yaw: 0.5472
      Episode_Termination/time_out: 0.4844
  Episode_Termination/base_contact: 0.5156
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 2.28s
                      Time elapsed: 00:03:11
                               ETA: 00:15:38

################################################################################
                      [1m Learning iteration 85/500 [0m                       

                       Computation: 43033 steps/s (collection: 2.141s, learning 0.143s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0065
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 11.6440
                       Mean reward: 2.89
               Mean episode length: 614.49
Episode_Reward/track_lin_vel_xy_exp: 0.1610
Episode_Reward/track_ang_vel_z_exp: 0.2064
       Episode_Reward/lin_vel_z_l2: -0.0191
      Episode_Reward/ang_vel_xy_l2: -0.0677
     Episode_Reward/dof_torques_l2: -0.0020
         Episode_Reward/dof_acc_l2: -0.0286
     Episode_Reward/action_rate_l2: -0.0733
      Episode_Reward/feet_air_time: -0.0115
Episode_Reward/flat_orientation_l2: -0.0185
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.8149
Metrics/base_velocity/error_vel_xy: 0.8549
Metrics/base_velocity/error_vel_yaw: 0.4513
      Episode_Termination/time_out: 0.4869
  Episode_Termination/base_contact: 0.5131
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 2.28s
                      Time elapsed: 00:03:14
                               ETA: 00:15:36

################################################################################
                      [1m Learning iteration 86/500 [0m                       

                       Computation: 42839 steps/s (collection: 2.150s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0068
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 11.6123
                       Mean reward: 3.18
               Mean episode length: 695.17
Episode_Reward/track_lin_vel_xy_exp: 0.1639
Episode_Reward/track_ang_vel_z_exp: 0.2211
       Episode_Reward/lin_vel_z_l2: -0.0205
      Episode_Reward/ang_vel_xy_l2: -0.0746
     Episode_Reward/dof_torques_l2: -0.0023
         Episode_Reward/dof_acc_l2: -0.0308
     Episode_Reward/action_rate_l2: -0.0814
      Episode_Reward/feet_air_time: -0.0120
Episode_Reward/flat_orientation_l2: -0.0192
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.8017
Metrics/base_velocity/error_vel_xy: 0.9789
Metrics/base_velocity/error_vel_yaw: 0.5626
      Episode_Termination/time_out: 0.4889
  Episode_Termination/base_contact: 0.5111
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 2.29s
                      Time elapsed: 00:03:16
                               ETA: 00:15:34

################################################################################
                      [1m Learning iteration 87/500 [0m                       

                       Computation: 42924 steps/s (collection: 2.145s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0056
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 11.6032
                       Mean reward: 2.77
               Mean episode length: 694.14
Episode_Reward/track_lin_vel_xy_exp: 0.1693
Episode_Reward/track_ang_vel_z_exp: 0.2175
       Episode_Reward/lin_vel_z_l2: -0.0200
      Episode_Reward/ang_vel_xy_l2: -0.0739
     Episode_Reward/dof_torques_l2: -0.0021
         Episode_Reward/dof_acc_l2: -0.0323
     Episode_Reward/action_rate_l2: -0.0793
      Episode_Reward/feet_air_time: -0.0130
Episode_Reward/flat_orientation_l2: -0.0181
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.7871
Metrics/base_velocity/error_vel_xy: 0.9340
Metrics/base_velocity/error_vel_yaw: 0.5406
      Episode_Termination/time_out: 0.4952
  Episode_Termination/base_contact: 0.5048
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 2.29s
                      Time elapsed: 00:03:18
                               ETA: 00:15:32

################################################################################
                      [1m Learning iteration 88/500 [0m                       

                       Computation: 42412 steps/s (collection: 2.175s, learning 0.143s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0063
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 11.5953
                       Mean reward: 4.16
               Mean episode length: 741.40
Episode_Reward/track_lin_vel_xy_exp: 0.2051
Episode_Reward/track_ang_vel_z_exp: 0.2366
       Episode_Reward/lin_vel_z_l2: -0.0202
      Episode_Reward/ang_vel_xy_l2: -0.0756
     Episode_Reward/dof_torques_l2: -0.0023
         Episode_Reward/dof_acc_l2: -0.0316
     Episode_Reward/action_rate_l2: -0.0825
      Episode_Reward/feet_air_time: -0.0122
Episode_Reward/flat_orientation_l2: -0.0187
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.7751
Metrics/base_velocity/error_vel_xy: 0.9248
Metrics/base_velocity/error_vel_yaw: 0.5144
      Episode_Termination/time_out: 0.4993
  Episode_Termination/base_contact: 0.5007
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 2.32s
                      Time elapsed: 00:03:21
                               ETA: 00:15:30

################################################################################
                      [1m Learning iteration 89/500 [0m                       

                       Computation: 43138 steps/s (collection: 2.135s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0074
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 11.5857
                       Mean reward: 4.19
               Mean episode length: 773.13
Episode_Reward/track_lin_vel_xy_exp: 0.2353
Episode_Reward/track_ang_vel_z_exp: 0.2561
       Episode_Reward/lin_vel_z_l2: -0.0211
      Episode_Reward/ang_vel_xy_l2: -0.0815
     Episode_Reward/dof_torques_l2: -0.0024
         Episode_Reward/dof_acc_l2: -0.0340
     Episode_Reward/action_rate_l2: -0.0887
      Episode_Reward/feet_air_time: -0.0142
Episode_Reward/flat_orientation_l2: -0.0202
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.7621
Metrics/base_velocity/error_vel_xy: 0.9840
Metrics/base_velocity/error_vel_yaw: 0.5376
      Episode_Termination/time_out: 0.5040
  Episode_Termination/base_contact: 0.4960
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 2.28s
                      Time elapsed: 00:03:23
                               ETA: 00:15:28

################################################################################
                      [1m Learning iteration 90/500 [0m                       

                       Computation: 42791 steps/s (collection: 2.154s, learning 0.143s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0081
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 11.5921
                       Mean reward: 3.48
               Mean episode length: 641.29
Episode_Reward/track_lin_vel_xy_exp: 0.1729
Episode_Reward/track_ang_vel_z_exp: 0.2196
       Episode_Reward/lin_vel_z_l2: -0.0191
      Episode_Reward/ang_vel_xy_l2: -0.0687
     Episode_Reward/dof_torques_l2: -0.0021
         Episode_Reward/dof_acc_l2: -0.0296
     Episode_Reward/action_rate_l2: -0.0749
      Episode_Reward/feet_air_time: -0.0119
Episode_Reward/flat_orientation_l2: -0.0186
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.7488
Metrics/base_velocity/error_vel_xy: 0.8844
Metrics/base_velocity/error_vel_yaw: 0.4500
      Episode_Termination/time_out: 0.5069
  Episode_Termination/base_contact: 0.4931
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 2.30s
                      Time elapsed: 00:03:25
                               ETA: 00:15:26

################################################################################
                      [1m Learning iteration 91/500 [0m                       

                       Computation: 42807 steps/s (collection: 2.152s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0077
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 11.5885
                       Mean reward: 3.12
               Mean episode length: 652.02
Episode_Reward/track_lin_vel_xy_exp: 0.1781
Episode_Reward/track_ang_vel_z_exp: 0.2271
       Episode_Reward/lin_vel_z_l2: -0.0197
      Episode_Reward/ang_vel_xy_l2: -0.0699
     Episode_Reward/dof_torques_l2: -0.0022
         Episode_Reward/dof_acc_l2: -0.0302
     Episode_Reward/action_rate_l2: -0.0771
      Episode_Reward/feet_air_time: -0.0120
Episode_Reward/flat_orientation_l2: -0.0201
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.7372
Metrics/base_velocity/error_vel_xy: 0.9060
Metrics/base_velocity/error_vel_yaw: 0.4629
      Episode_Termination/time_out: 0.5102
  Episode_Termination/base_contact: 0.4898
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 2.30s
                      Time elapsed: 00:03:27
                               ETA: 00:15:24

################################################################################
                      [1m Learning iteration 92/500 [0m                       

                       Computation: 42860 steps/s (collection: 2.148s, learning 0.146s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0060
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 11.5906
                       Mean reward: 3.82
               Mean episode length: 636.93
Episode_Reward/track_lin_vel_xy_exp: 0.2187
Episode_Reward/track_ang_vel_z_exp: 0.2292
       Episode_Reward/lin_vel_z_l2: -0.0197
      Episode_Reward/ang_vel_xy_l2: -0.0696
     Episode_Reward/dof_torques_l2: -0.0022
         Episode_Reward/dof_acc_l2: -0.0309
     Episode_Reward/action_rate_l2: -0.0772
      Episode_Reward/feet_air_time: -0.0116
Episode_Reward/flat_orientation_l2: -0.0188
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.7244
Metrics/base_velocity/error_vel_xy: 0.8358
Metrics/base_velocity/error_vel_yaw: 0.4645
      Episode_Termination/time_out: 0.5137
  Episode_Termination/base_contact: 0.4863
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 2.29s
                      Time elapsed: 00:03:30
                               ETA: 00:15:22

################################################################################
                      [1m Learning iteration 93/500 [0m                       

                       Computation: 42821 steps/s (collection: 2.152s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0063
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 11.5622
                       Mean reward: 4.01
               Mean episode length: 710.07
Episode_Reward/track_lin_vel_xy_exp: 0.1821
Episode_Reward/track_ang_vel_z_exp: 0.2370
       Episode_Reward/lin_vel_z_l2: -0.0192
      Episode_Reward/ang_vel_xy_l2: -0.0713
     Episode_Reward/dof_torques_l2: -0.0022
         Episode_Reward/dof_acc_l2: -0.0316
     Episode_Reward/action_rate_l2: -0.0785
      Episode_Reward/feet_air_time: -0.0124
Episode_Reward/flat_orientation_l2: -0.0185
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.7140
Metrics/base_velocity/error_vel_xy: 0.9169
Metrics/base_velocity/error_vel_yaw: 0.4520
      Episode_Termination/time_out: 0.5169
  Episode_Termination/base_contact: 0.4831
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 2.30s
                      Time elapsed: 00:03:32
                               ETA: 00:15:19

################################################################################
                      [1m Learning iteration 94/500 [0m                       

                       Computation: 42431 steps/s (collection: 2.173s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0082
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 11.5483
                       Mean reward: 3.65
               Mean episode length: 726.68
Episode_Reward/track_lin_vel_xy_exp: 0.1786
Episode_Reward/track_ang_vel_z_exp: 0.2455
       Episode_Reward/lin_vel_z_l2: -0.0205
      Episode_Reward/ang_vel_xy_l2: -0.0733
     Episode_Reward/dof_torques_l2: -0.0024
         Episode_Reward/dof_acc_l2: -0.0322
     Episode_Reward/action_rate_l2: -0.0824
      Episode_Reward/feet_air_time: -0.0126
Episode_Reward/flat_orientation_l2: -0.0193
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.7027
Metrics/base_velocity/error_vel_xy: 1.0018
Metrics/base_velocity/error_vel_yaw: 0.5005
      Episode_Termination/time_out: 0.5258
  Episode_Termination/base_contact: 0.4742
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 2.32s
                      Time elapsed: 00:03:34
                               ETA: 00:15:17

################################################################################
                      [1m Learning iteration 95/500 [0m                       

                       Computation: 42499 steps/s (collection: 2.168s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0095
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 11.5631
                       Mean reward: 3.55
               Mean episode length: 667.57
Episode_Reward/track_lin_vel_xy_exp: 0.1810
Episode_Reward/track_ang_vel_z_exp: 0.2355
       Episode_Reward/lin_vel_z_l2: -0.0202
      Episode_Reward/ang_vel_xy_l2: -0.0719
     Episode_Reward/dof_torques_l2: -0.0022
         Episode_Reward/dof_acc_l2: -0.0325
     Episode_Reward/action_rate_l2: -0.0789
      Episode_Reward/feet_air_time: -0.0129
Episode_Reward/flat_orientation_l2: -0.0198
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.6921
Metrics/base_velocity/error_vel_xy: 0.9402
Metrics/base_velocity/error_vel_yaw: 0.4851
      Episode_Termination/time_out: 0.5332
  Episode_Termination/base_contact: 0.4668
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 2.31s
                      Time elapsed: 00:03:37
                               ETA: 00:15:15

################################################################################
                      [1m Learning iteration 96/500 [0m                       

                       Computation: 42516 steps/s (collection: 2.169s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0076
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 11.5489
                       Mean reward: 3.90
               Mean episode length: 710.82
Episode_Reward/track_lin_vel_xy_exp: 0.1860
Episode_Reward/track_ang_vel_z_exp: 0.2463
       Episode_Reward/lin_vel_z_l2: -0.0201
      Episode_Reward/ang_vel_xy_l2: -0.0735
     Episode_Reward/dof_torques_l2: -0.0023
         Episode_Reward/dof_acc_l2: -0.0340
     Episode_Reward/action_rate_l2: -0.0816
      Episode_Reward/feet_air_time: -0.0130
Episode_Reward/flat_orientation_l2: -0.0198
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.6789
Metrics/base_velocity/error_vel_xy: 0.9864
Metrics/base_velocity/error_vel_yaw: 0.4795
      Episode_Termination/time_out: 0.5341
  Episode_Termination/base_contact: 0.4659
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 2.31s
                      Time elapsed: 00:03:39
                               ETA: 00:15:13

################################################################################
                      [1m Learning iteration 97/500 [0m                       

                       Computation: 42960 steps/s (collection: 2.145s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0063
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 11.5502
                       Mean reward: 3.72
               Mean episode length: 728.63
Episode_Reward/track_lin_vel_xy_exp: 0.1759
Episode_Reward/track_ang_vel_z_exp: 0.2471
       Episode_Reward/lin_vel_z_l2: -0.0201
      Episode_Reward/ang_vel_xy_l2: -0.0713
     Episode_Reward/dof_torques_l2: -0.0023
         Episode_Reward/dof_acc_l2: -0.0323
     Episode_Reward/action_rate_l2: -0.0803
      Episode_Reward/feet_air_time: -0.0128
Episode_Reward/flat_orientation_l2: -0.0184
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.6653
Metrics/base_velocity/error_vel_xy: 0.9856
Metrics/base_velocity/error_vel_yaw: 0.4621
      Episode_Termination/time_out: 0.5382
  Episode_Termination/base_contact: 0.4618
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 2.29s
                      Time elapsed: 00:03:41
                               ETA: 00:15:11

################################################################################
                      [1m Learning iteration 98/500 [0m                       

                       Computation: 42665 steps/s (collection: 2.160s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0072
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 11.5534
                       Mean reward: 3.54
               Mean episode length: 650.57
Episode_Reward/track_lin_vel_xy_exp: 0.1771
Episode_Reward/track_ang_vel_z_exp: 0.2307
       Episode_Reward/lin_vel_z_l2: -0.0195
      Episode_Reward/ang_vel_xy_l2: -0.0667
     Episode_Reward/dof_torques_l2: -0.0021
         Episode_Reward/dof_acc_l2: -0.0305
     Episode_Reward/action_rate_l2: -0.0744
      Episode_Reward/feet_air_time: -0.0117
Episode_Reward/flat_orientation_l2: -0.0176
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.6538
Metrics/base_velocity/error_vel_xy: 0.8846
Metrics/base_velocity/error_vel_yaw: 0.4136
      Episode_Termination/time_out: 0.5433
  Episode_Termination/base_contact: 0.4567
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 2.30s
                      Time elapsed: 00:03:44
                               ETA: 00:15:09

################################################################################
                      [1m Learning iteration 99/500 [0m                       

                       Computation: 42464 steps/s (collection: 2.171s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0058
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 11.5285
                       Mean reward: 4.25
               Mean episode length: 735.86
Episode_Reward/track_lin_vel_xy_exp: 0.1814
Episode_Reward/track_ang_vel_z_exp: 0.2410
       Episode_Reward/lin_vel_z_l2: -0.0201
      Episode_Reward/ang_vel_xy_l2: -0.0690
     Episode_Reward/dof_torques_l2: -0.0022
         Episode_Reward/dof_acc_l2: -0.0318
     Episode_Reward/action_rate_l2: -0.0778
      Episode_Reward/feet_air_time: -0.0121
Episode_Reward/flat_orientation_l2: -0.0172
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.6403
Metrics/base_velocity/error_vel_xy: 0.9296
Metrics/base_velocity/error_vel_yaw: 0.4488
      Episode_Termination/time_out: 0.5486
  Episode_Termination/base_contact: 0.4514
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 2.31s
                      Time elapsed: 00:03:46
                               ETA: 00:15:07

################################################################################
                      [1m Learning iteration 100/500 [0m                      

                       Computation: 42342 steps/s (collection: 2.177s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0068
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 11.5075
                       Mean reward: 4.71
               Mean episode length: 725.24
Episode_Reward/track_lin_vel_xy_exp: 0.2094
Episode_Reward/track_ang_vel_z_exp: 0.2591
       Episode_Reward/lin_vel_z_l2: -0.0209
      Episode_Reward/ang_vel_xy_l2: -0.0725
     Episode_Reward/dof_torques_l2: -0.0023
         Episode_Reward/dof_acc_l2: -0.0339
     Episode_Reward/action_rate_l2: -0.0824
      Episode_Reward/feet_air_time: -0.0132
Episode_Reward/flat_orientation_l2: -0.0200
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.6252
Metrics/base_velocity/error_vel_xy: 0.9512
Metrics/base_velocity/error_vel_yaw: 0.4589
      Episode_Termination/time_out: 0.5567
  Episode_Termination/base_contact: 0.4433
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 2.32s
                      Time elapsed: 00:03:48
                               ETA: 00:15:05

################################################################################
                      [1m Learning iteration 101/500 [0m                      

                       Computation: 42532 steps/s (collection: 2.169s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0067
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 11.5088
                       Mean reward: 3.08
               Mean episode length: 631.01
Episode_Reward/track_lin_vel_xy_exp: 0.1492
Episode_Reward/track_ang_vel_z_exp: 0.2207
       Episode_Reward/lin_vel_z_l2: -0.0186
      Episode_Reward/ang_vel_xy_l2: -0.0617
     Episode_Reward/dof_torques_l2: -0.0021
         Episode_Reward/dof_acc_l2: -0.0283
     Episode_Reward/action_rate_l2: -0.0701
      Episode_Reward/feet_air_time: -0.0108
Episode_Reward/flat_orientation_l2: -0.0186
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.6136
Metrics/base_velocity/error_vel_xy: 0.8762
Metrics/base_velocity/error_vel_yaw: 0.3909
      Episode_Termination/time_out: 0.5584
  Episode_Termination/base_contact: 0.4416
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 2.31s
                      Time elapsed: 00:03:50
                               ETA: 00:15:03

################################################################################
                      [1m Learning iteration 102/500 [0m                      

                       Computation: 42434 steps/s (collection: 2.173s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0070
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 11.4845
                       Mean reward: 4.03
               Mean episode length: 730.51
Episode_Reward/track_lin_vel_xy_exp: 0.1699
Episode_Reward/track_ang_vel_z_exp: 0.2324
       Episode_Reward/lin_vel_z_l2: -0.0196
      Episode_Reward/ang_vel_xy_l2: -0.0657
     Episode_Reward/dof_torques_l2: -0.0021
         Episode_Reward/dof_acc_l2: -0.0315
     Episode_Reward/action_rate_l2: -0.0740
      Episode_Reward/feet_air_time: -0.0117
Episode_Reward/flat_orientation_l2: -0.0185
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.6024
Metrics/base_velocity/error_vel_xy: 0.9061
Metrics/base_velocity/error_vel_yaw: 0.4221
      Episode_Termination/time_out: 0.5582
  Episode_Termination/base_contact: 0.4418
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 2.32s
                      Time elapsed: 00:03:53
                               ETA: 00:15:01

################################################################################
                      [1m Learning iteration 103/500 [0m                      

                       Computation: 42422 steps/s (collection: 2.174s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0065
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 11.4903
                       Mean reward: 4.10
               Mean episode length: 631.40
Episode_Reward/track_lin_vel_xy_exp: 0.1761
Episode_Reward/track_ang_vel_z_exp: 0.2172
       Episode_Reward/lin_vel_z_l2: -0.0181
      Episode_Reward/ang_vel_xy_l2: -0.0600
     Episode_Reward/dof_torques_l2: -0.0019
         Episode_Reward/dof_acc_l2: -0.0290
     Episode_Reward/action_rate_l2: -0.0680
      Episode_Reward/feet_air_time: -0.0110
Episode_Reward/flat_orientation_l2: -0.0173
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.5917
Metrics/base_velocity/error_vel_xy: 0.7883
Metrics/base_velocity/error_vel_yaw: 0.3662
      Episode_Termination/time_out: 0.5591
  Episode_Termination/base_contact: 0.4409
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 2.32s
                      Time elapsed: 00:03:55
                               ETA: 00:14:59

################################################################################
                      [1m Learning iteration 104/500 [0m                      

                       Computation: 42395 steps/s (collection: 2.175s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0068
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 11.4733
                       Mean reward: 3.71
               Mean episode length: 672.36
Episode_Reward/track_lin_vel_xy_exp: 0.1875
Episode_Reward/track_ang_vel_z_exp: 0.2520
       Episode_Reward/lin_vel_z_l2: -0.0201
      Episode_Reward/ang_vel_xy_l2: -0.0700
     Episode_Reward/dof_torques_l2: -0.0023
         Episode_Reward/dof_acc_l2: -0.0339
     Episode_Reward/action_rate_l2: -0.0790
      Episode_Reward/feet_air_time: -0.0125
Episode_Reward/flat_orientation_l2: -0.0196
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.5809
Metrics/base_velocity/error_vel_xy: 0.9584
Metrics/base_velocity/error_vel_yaw: 0.4334
      Episode_Termination/time_out: 0.5584
  Episode_Termination/base_contact: 0.4416
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 2.32s
                      Time elapsed: 00:03:57
                               ETA: 00:14:57

################################################################################
                      [1m Learning iteration 105/500 [0m                      

                       Computation: 42329 steps/s (collection: 2.176s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0066
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 11.4493
                       Mean reward: 4.41
               Mean episode length: 756.95
Episode_Reward/track_lin_vel_xy_exp: 0.2031
Episode_Reward/track_ang_vel_z_exp: 0.2651
       Episode_Reward/lin_vel_z_l2: -0.0206
      Episode_Reward/ang_vel_xy_l2: -0.0725
     Episode_Reward/dof_torques_l2: -0.0025
         Episode_Reward/dof_acc_l2: -0.0342
     Episode_Reward/action_rate_l2: -0.0837
      Episode_Reward/feet_air_time: -0.0130
Episode_Reward/flat_orientation_l2: -0.0196
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.5686
Metrics/base_velocity/error_vel_xy: 1.0095
Metrics/base_velocity/error_vel_yaw: 0.4783
      Episode_Termination/time_out: 0.5604
  Episode_Termination/base_contact: 0.4396
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 2.32s
                      Time elapsed: 00:04:00
                               ETA: 00:14:55

################################################################################
                      [1m Learning iteration 106/500 [0m                      

                       Computation: 41824 steps/s (collection: 2.206s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0080
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 11.4474
                       Mean reward: 5.11
               Mean episode length: 801.91
Episode_Reward/track_lin_vel_xy_exp: 0.2138
Episode_Reward/track_ang_vel_z_exp: 0.2705
       Episode_Reward/lin_vel_z_l2: -0.0210
      Episode_Reward/ang_vel_xy_l2: -0.0741
     Episode_Reward/dof_torques_l2: -0.0024
         Episode_Reward/dof_acc_l2: -0.0361
     Episode_Reward/action_rate_l2: -0.0850
      Episode_Reward/feet_air_time: -0.0133
Episode_Reward/flat_orientation_l2: -0.0196
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.5559
Metrics/base_velocity/error_vel_xy: 1.0013
Metrics/base_velocity/error_vel_yaw: 0.4813
      Episode_Termination/time_out: 0.5619
  Episode_Termination/base_contact: 0.4381
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 2.35s
                      Time elapsed: 00:04:02
                               ETA: 00:14:53

################################################################################
                      [1m Learning iteration 107/500 [0m                      

                       Computation: 41998 steps/s (collection: 2.197s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0083
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 11.4454
                       Mean reward: 5.52
               Mean episode length: 831.90
Episode_Reward/track_lin_vel_xy_exp: 0.2385
Episode_Reward/track_ang_vel_z_exp: 0.2848
       Episode_Reward/lin_vel_z_l2: -0.0219
      Episode_Reward/ang_vel_xy_l2: -0.0779
     Episode_Reward/dof_torques_l2: -0.0026
         Episode_Reward/dof_acc_l2: -0.0378
     Episode_Reward/action_rate_l2: -0.0890
      Episode_Reward/feet_air_time: -0.0144
Episode_Reward/flat_orientation_l2: -0.0202
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.5441
Metrics/base_velocity/error_vel_xy: 1.0283
Metrics/base_velocity/error_vel_yaw: 0.4981
      Episode_Termination/time_out: 0.5673
  Episode_Termination/base_contact: 0.4327
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 2.34s
                      Time elapsed: 00:04:04
                               ETA: 00:14:51

################################################################################
                      [1m Learning iteration 108/500 [0m                      

                       Computation: 42153 steps/s (collection: 2.188s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0078
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 11.4554
                       Mean reward: 4.52
               Mean episode length: 758.02
Episode_Reward/track_lin_vel_xy_exp: 0.1886
Episode_Reward/track_ang_vel_z_exp: 0.2641
       Episode_Reward/lin_vel_z_l2: -0.0201
      Episode_Reward/ang_vel_xy_l2: -0.0695
     Episode_Reward/dof_torques_l2: -0.0024
         Episode_Reward/dof_acc_l2: -0.0329
     Episode_Reward/action_rate_l2: -0.0810
      Episode_Reward/feet_air_time: -0.0129
Episode_Reward/flat_orientation_l2: -0.0171
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.5331
Metrics/base_velocity/error_vel_xy: 0.9768
Metrics/base_velocity/error_vel_yaw: 0.4254
      Episode_Termination/time_out: 0.5722
  Episode_Termination/base_contact: 0.4278
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 2.33s
                      Time elapsed: 00:04:07
                               ETA: 00:14:49

################################################################################
                      [1m Learning iteration 109/500 [0m                      

                       Computation: 41624 steps/s (collection: 2.216s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0116
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 11.4609
                       Mean reward: 5.60
               Mean episode length: 765.90
Episode_Reward/track_lin_vel_xy_exp: 0.2413
Episode_Reward/track_ang_vel_z_exp: 0.2776
       Episode_Reward/lin_vel_z_l2: -0.0223
      Episode_Reward/ang_vel_xy_l2: -0.0756
     Episode_Reward/dof_torques_l2: -0.0025
         Episode_Reward/dof_acc_l2: -0.0360
     Episode_Reward/action_rate_l2: -0.0860
      Episode_Reward/feet_air_time: -0.0131
Episode_Reward/flat_orientation_l2: -0.0231
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.5228
Metrics/base_velocity/error_vel_xy: 0.9950
Metrics/base_velocity/error_vel_yaw: 0.4746
      Episode_Termination/time_out: 0.5748
  Episode_Termination/base_contact: 0.4252
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 2.36s
                      Time elapsed: 00:04:09
                               ETA: 00:14:47

################################################################################
                      [1m Learning iteration 110/500 [0m                      

                       Computation: 41881 steps/s (collection: 2.202s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0092
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 11.4805
                       Mean reward: 5.18
               Mean episode length: 853.39
Episode_Reward/track_lin_vel_xy_exp: 0.2484
Episode_Reward/track_ang_vel_z_exp: 0.3083
       Episode_Reward/lin_vel_z_l2: -0.0231
      Episode_Reward/ang_vel_xy_l2: -0.0825
     Episode_Reward/dof_torques_l2: -0.0027
         Episode_Reward/dof_acc_l2: -0.0418
     Episode_Reward/action_rate_l2: -0.0953
      Episode_Reward/feet_air_time: -0.0157
Episode_Reward/flat_orientation_l2: -0.0215
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.5100
Metrics/base_velocity/error_vel_xy: 1.1052
Metrics/base_velocity/error_vel_yaw: 0.5120
      Episode_Termination/time_out: 0.5781
  Episode_Termination/base_contact: 0.4219
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 2.35s
                      Time elapsed: 00:04:11
                               ETA: 00:14:45

################################################################################
                      [1m Learning iteration 111/500 [0m                      

                       Computation: 41475 steps/s (collection: 2.227s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0080
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 11.4932
                       Mean reward: 5.15
               Mean episode length: 817.30
Episode_Reward/track_lin_vel_xy_exp: 0.2216
Episode_Reward/track_ang_vel_z_exp: 0.2826
       Episode_Reward/lin_vel_z_l2: -0.0222
      Episode_Reward/ang_vel_xy_l2: -0.0753
     Episode_Reward/dof_torques_l2: -0.0025
         Episode_Reward/dof_acc_l2: -0.0384
     Episode_Reward/action_rate_l2: -0.0873
      Episode_Reward/feet_air_time: -0.0141
Episode_Reward/flat_orientation_l2: -0.0201
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4969
Metrics/base_velocity/error_vel_xy: 1.0265
Metrics/base_velocity/error_vel_yaw: 0.4742
      Episode_Termination/time_out: 0.5805
  Episode_Termination/base_contact: 0.4195
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 2.37s
                      Time elapsed: 00:04:14
                               ETA: 00:14:43

################################################################################
                      [1m Learning iteration 112/500 [0m                      

                       Computation: 41610 steps/s (collection: 2.218s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0112
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 11.5049
                       Mean reward: 5.57
               Mean episode length: 837.94
Episode_Reward/track_lin_vel_xy_exp: 0.2537
Episode_Reward/track_ang_vel_z_exp: 0.3007
       Episode_Reward/lin_vel_z_l2: -0.0219
      Episode_Reward/ang_vel_xy_l2: -0.0782
     Episode_Reward/dof_torques_l2: -0.0025
         Episode_Reward/dof_acc_l2: -0.0389
     Episode_Reward/action_rate_l2: -0.0905
      Episode_Reward/feet_air_time: -0.0150
Episode_Reward/flat_orientation_l2: -0.0190
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4859
Metrics/base_velocity/error_vel_xy: 1.0298
Metrics/base_velocity/error_vel_yaw: 0.4476
      Episode_Termination/time_out: 0.5846
  Episode_Termination/base_contact: 0.4154
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 2.36s
                      Time elapsed: 00:04:16
                               ETA: 00:14:41

################################################################################
                      [1m Learning iteration 113/500 [0m                      

                       Computation: 41475 steps/s (collection: 2.226s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0095
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 11.5112
                       Mean reward: 5.19
               Mean episode length: 794.52
Episode_Reward/track_lin_vel_xy_exp: 0.2178
Episode_Reward/track_ang_vel_z_exp: 0.2922
       Episode_Reward/lin_vel_z_l2: -0.0211
      Episode_Reward/ang_vel_xy_l2: -0.0750
     Episode_Reward/dof_torques_l2: -0.0025
         Episode_Reward/dof_acc_l2: -0.0371
     Episode_Reward/action_rate_l2: -0.0875
      Episode_Reward/feet_air_time: -0.0141
Episode_Reward/flat_orientation_l2: -0.0185
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4738
Metrics/base_velocity/error_vel_xy: 1.0479
Metrics/base_velocity/error_vel_yaw: 0.4359
      Episode_Termination/time_out: 0.5870
  Episode_Termination/base_contact: 0.4130
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 2.37s
                      Time elapsed: 00:04:19
                               ETA: 00:14:39

################################################################################
                      [1m Learning iteration 114/500 [0m                      

                       Computation: 41313 steps/s (collection: 2.235s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0125
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 11.5153
                       Mean reward: 5.12
               Mean episode length: 724.18
Episode_Reward/track_lin_vel_xy_exp: 0.2266
Episode_Reward/track_ang_vel_z_exp: 0.2646
       Episode_Reward/lin_vel_z_l2: -0.0201
      Episode_Reward/ang_vel_xy_l2: -0.0686
     Episode_Reward/dof_torques_l2: -0.0023
         Episode_Reward/dof_acc_l2: -0.0335
     Episode_Reward/action_rate_l2: -0.0789
      Episode_Reward/feet_air_time: -0.0124
Episode_Reward/flat_orientation_l2: -0.0192
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4640
Metrics/base_velocity/error_vel_xy: 0.9005
Metrics/base_velocity/error_vel_yaw: 0.3979
      Episode_Termination/time_out: 0.5880
  Episode_Termination/base_contact: 0.4120
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 2.38s
                      Time elapsed: 00:04:21
                               ETA: 00:14:37

################################################################################
                      [1m Learning iteration 115/500 [0m                      

                       Computation: 41414 steps/s (collection: 2.229s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0090
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 11.5331
                       Mean reward: 4.93
               Mean episode length: 773.22
Episode_Reward/track_lin_vel_xy_exp: 0.2181
Episode_Reward/track_ang_vel_z_exp: 0.2807
       Episode_Reward/lin_vel_z_l2: -0.0210
      Episode_Reward/ang_vel_xy_l2: -0.0722
     Episode_Reward/dof_torques_l2: -0.0025
         Episode_Reward/dof_acc_l2: -0.0370
     Episode_Reward/action_rate_l2: -0.0841
      Episode_Reward/feet_air_time: -0.0138
Episode_Reward/flat_orientation_l2: -0.0186
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4529
Metrics/base_velocity/error_vel_xy: 1.0026
Metrics/base_velocity/error_vel_yaw: 0.4331
      Episode_Termination/time_out: 0.5905
  Episode_Termination/base_contact: 0.4095
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 2.37s
                      Time elapsed: 00:04:23
                               ETA: 00:14:35

################################################################################
                      [1m Learning iteration 116/500 [0m                      

                       Computation: 41325 steps/s (collection: 2.234s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0080
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 11.5438
                       Mean reward: 6.10
               Mean episode length: 834.28
Episode_Reward/track_lin_vel_xy_exp: 0.2592
Episode_Reward/track_ang_vel_z_exp: 0.3024
       Episode_Reward/lin_vel_z_l2: -0.0228
      Episode_Reward/ang_vel_xy_l2: -0.0785
     Episode_Reward/dof_torques_l2: -0.0027
         Episode_Reward/dof_acc_l2: -0.0414
     Episode_Reward/action_rate_l2: -0.0918
      Episode_Reward/feet_air_time: -0.0146
Episode_Reward/flat_orientation_l2: -0.0211
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4429
Metrics/base_velocity/error_vel_xy: 1.0463
Metrics/base_velocity/error_vel_yaw: 0.4887
      Episode_Termination/time_out: 0.5935
  Episode_Termination/base_contact: 0.4065
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 2.38s
                      Time elapsed: 00:04:26
                               ETA: 00:14:33

################################################################################
                      [1m Learning iteration 117/500 [0m                      

                       Computation: 41146 steps/s (collection: 2.245s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0081
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 11.5368
                       Mean reward: 4.89
               Mean episode length: 721.46
Episode_Reward/track_lin_vel_xy_exp: 0.2351
Episode_Reward/track_ang_vel_z_exp: 0.2842
       Episode_Reward/lin_vel_z_l2: -0.0218
      Episode_Reward/ang_vel_xy_l2: -0.0726
     Episode_Reward/dof_torques_l2: -0.0024
         Episode_Reward/dof_acc_l2: -0.0397
     Episode_Reward/action_rate_l2: -0.0855
      Episode_Reward/feet_air_time: -0.0144
Episode_Reward/flat_orientation_l2: -0.0179
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4343
Metrics/base_velocity/error_vel_xy: 0.9697
Metrics/base_velocity/error_vel_yaw: 0.4313
      Episode_Termination/time_out: 0.5988
  Episode_Termination/base_contact: 0.4012
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 2.39s
                      Time elapsed: 00:04:28
                               ETA: 00:14:31

################################################################################
                      [1m Learning iteration 118/500 [0m                      

                       Computation: 41189 steps/s (collection: 2.238s, learning 0.148s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0068
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 11.5218
                       Mean reward: 5.09
               Mean episode length: 800.97
Episode_Reward/track_lin_vel_xy_exp: 0.2322
Episode_Reward/track_ang_vel_z_exp: 0.2817
       Episode_Reward/lin_vel_z_l2: -0.0219
      Episode_Reward/ang_vel_xy_l2: -0.0738
     Episode_Reward/dof_torques_l2: -0.0025
         Episode_Reward/dof_acc_l2: -0.0410
     Episode_Reward/action_rate_l2: -0.0854
      Episode_Reward/feet_air_time: -0.0144
Episode_Reward/flat_orientation_l2: -0.0178
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4251
Metrics/base_velocity/error_vel_xy: 0.9841
Metrics/base_velocity/error_vel_yaw: 0.4521
      Episode_Termination/time_out: 0.6028
  Episode_Termination/base_contact: 0.3972
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 2.39s
                      Time elapsed: 00:04:30
                               ETA: 00:14:29

################################################################################
                      [1m Learning iteration 119/500 [0m                      

                       Computation: 41214 steps/s (collection: 2.235s, learning 0.150s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0075
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 11.5111
                       Mean reward: 6.34
               Mean episode length: 834.02
Episode_Reward/track_lin_vel_xy_exp: 0.2754
Episode_Reward/track_ang_vel_z_exp: 0.3015
       Episode_Reward/lin_vel_z_l2: -0.0218
      Episode_Reward/ang_vel_xy_l2: -0.0760
     Episode_Reward/dof_torques_l2: -0.0026
         Episode_Reward/dof_acc_l2: -0.0396
     Episode_Reward/action_rate_l2: -0.0889
      Episode_Reward/feet_air_time: -0.0148
Episode_Reward/flat_orientation_l2: -0.0182
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4166
Metrics/base_velocity/error_vel_xy: 0.9639
Metrics/base_velocity/error_vel_yaw: 0.4342
      Episode_Termination/time_out: 0.6049
  Episode_Termination/base_contact: 0.3951
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 2.39s
                      Time elapsed: 00:04:33
                               ETA: 00:14:27

################################################################################
                      [1m Learning iteration 120/500 [0m                      

                       Computation: 41512 steps/s (collection: 2.223s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0076
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 11.5136
                       Mean reward: 5.58
               Mean episode length: 862.61
Episode_Reward/track_lin_vel_xy_exp: 0.2473
Episode_Reward/track_ang_vel_z_exp: 0.3193
       Episode_Reward/lin_vel_z_l2: -0.0224
      Episode_Reward/ang_vel_xy_l2: -0.0803
     Episode_Reward/dof_torques_l2: -0.0028
         Episode_Reward/dof_acc_l2: -0.0429
     Episode_Reward/action_rate_l2: -0.0946
      Episode_Reward/feet_air_time: -0.0155
Episode_Reward/flat_orientation_l2: -0.0186
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4100
Metrics/base_velocity/error_vel_xy: 1.1197
Metrics/base_velocity/error_vel_yaw: 0.4699
      Episode_Termination/time_out: 0.6107
  Episode_Termination/base_contact: 0.3893
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 2.37s
                      Time elapsed: 00:04:35
                               ETA: 00:14:25

################################################################################
                      [1m Learning iteration 121/500 [0m                      

                       Computation: 41595 steps/s (collection: 2.218s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0086
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 11.5079
                       Mean reward: 5.36
               Mean episode length: 802.11
Episode_Reward/track_lin_vel_xy_exp: 0.2228
Episode_Reward/track_ang_vel_z_exp: 0.2872
       Episode_Reward/lin_vel_z_l2: -0.0218
      Episode_Reward/ang_vel_xy_l2: -0.0731
     Episode_Reward/dof_torques_l2: -0.0025
         Episode_Reward/dof_acc_l2: -0.0391
     Episode_Reward/action_rate_l2: -0.0853
      Episode_Reward/feet_air_time: -0.0140
Episode_Reward/flat_orientation_l2: -0.0178
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4017
Metrics/base_velocity/error_vel_xy: 1.0065
Metrics/base_velocity/error_vel_yaw: 0.4268
      Episode_Termination/time_out: 0.6122
  Episode_Termination/base_contact: 0.3878
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 2.36s
                      Time elapsed: 00:04:38
                               ETA: 00:14:23

################################################################################
                      [1m Learning iteration 122/500 [0m                      

                       Computation: 41392 steps/s (collection: 2.228s, learning 0.147s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0118
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 11.5141
                       Mean reward: 4.31
               Mean episode length: 756.56
Episode_Reward/track_lin_vel_xy_exp: 0.1950
Episode_Reward/track_ang_vel_z_exp: 0.2847
       Episode_Reward/lin_vel_z_l2: -0.0220
      Episode_Reward/ang_vel_xy_l2: -0.0722
     Episode_Reward/dof_torques_l2: -0.0025
         Episode_Reward/dof_acc_l2: -0.0402
     Episode_Reward/action_rate_l2: -0.0848
      Episode_Reward/feet_air_time: -0.0142
Episode_Reward/flat_orientation_l2: -0.0196
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3952
Metrics/base_velocity/error_vel_xy: 1.0505
Metrics/base_velocity/error_vel_yaw: 0.4222
      Episode_Termination/time_out: 0.6161
  Episode_Termination/base_contact: 0.3839
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 2.37s
                      Time elapsed: 00:04:40
                               ETA: 00:14:21

################################################################################
                      [1m Learning iteration 123/500 [0m                      

                       Computation: 41623 steps/s (collection: 2.216s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0075
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 11.5208
                       Mean reward: 6.05
               Mean episode length: 810.20
Episode_Reward/track_lin_vel_xy_exp: 0.2758
Episode_Reward/track_ang_vel_z_exp: 0.3121
       Episode_Reward/lin_vel_z_l2: -0.0233
      Episode_Reward/ang_vel_xy_l2: -0.0787
     Episode_Reward/dof_torques_l2: -0.0027
         Episode_Reward/dof_acc_l2: -0.0453
     Episode_Reward/action_rate_l2: -0.0916
      Episode_Reward/feet_air_time: -0.0146
Episode_Reward/flat_orientation_l2: -0.0223
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3896
Metrics/base_velocity/error_vel_xy: 1.0144
Metrics/base_velocity/error_vel_yaw: 0.4381
      Episode_Termination/time_out: 0.6199
  Episode_Termination/base_contact: 0.3801
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 2.36s
                      Time elapsed: 00:04:42
                               ETA: 00:14:19

################################################################################
                      [1m Learning iteration 124/500 [0m                      

                       Computation: 41354 steps/s (collection: 2.233s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0068
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 11.5006
                       Mean reward: 5.25
               Mean episode length: 787.53
Episode_Reward/track_lin_vel_xy_exp: 0.2560
Episode_Reward/track_ang_vel_z_exp: 0.3044
       Episode_Reward/lin_vel_z_l2: -0.0227
      Episode_Reward/ang_vel_xy_l2: -0.0775
     Episode_Reward/dof_torques_l2: -0.0027
         Episode_Reward/dof_acc_l2: -0.0439
     Episode_Reward/action_rate_l2: -0.0911
      Episode_Reward/feet_air_time: -0.0152
Episode_Reward/flat_orientation_l2: -0.0193
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3832
Metrics/base_velocity/error_vel_xy: 1.0264
Metrics/base_velocity/error_vel_yaw: 0.4587
      Episode_Termination/time_out: 0.6244
  Episode_Termination/base_contact: 0.3756
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 2.38s
                      Time elapsed: 00:04:45
                               ETA: 00:14:17

################################################################################
                      [1m Learning iteration 125/500 [0m                      

                       Computation: 41452 steps/s (collection: 2.227s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0068
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 11.4860
                       Mean reward: 5.75
               Mean episode length: 831.99
Episode_Reward/track_lin_vel_xy_exp: 0.2619
Episode_Reward/track_ang_vel_z_exp: 0.2884
       Episode_Reward/lin_vel_z_l2: -0.0217
      Episode_Reward/ang_vel_xy_l2: -0.0729
     Episode_Reward/dof_torques_l2: -0.0026
         Episode_Reward/dof_acc_l2: -0.0400
     Episode_Reward/action_rate_l2: -0.0864
      Episode_Reward/feet_air_time: -0.0139
Episode_Reward/flat_orientation_l2: -0.0184
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3778
Metrics/base_velocity/error_vel_xy: 0.9795
Metrics/base_velocity/error_vel_yaw: 0.4554
      Episode_Termination/time_out: 0.6265
  Episode_Termination/base_contact: 0.3735
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 2.37s
                      Time elapsed: 00:04:47
                               ETA: 00:14:15

################################################################################
                      [1m Learning iteration 126/500 [0m                      

                       Computation: 41444 steps/s (collection: 2.228s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0093
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 11.4734
                       Mean reward: 5.86
               Mean episode length: 794.46
Episode_Reward/track_lin_vel_xy_exp: 0.2789
Episode_Reward/track_ang_vel_z_exp: 0.2869
       Episode_Reward/lin_vel_z_l2: -0.0234
      Episode_Reward/ang_vel_xy_l2: -0.0732
     Episode_Reward/dof_torques_l2: -0.0026
         Episode_Reward/dof_acc_l2: -0.0446
     Episode_Reward/action_rate_l2: -0.0863
      Episode_Reward/feet_air_time: -0.0134
Episode_Reward/flat_orientation_l2: -0.0225
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3750
Metrics/base_velocity/error_vel_xy: 0.9199
Metrics/base_velocity/error_vel_yaw: 0.4395
      Episode_Termination/time_out: 0.6316
  Episode_Termination/base_contact: 0.3684
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 2.37s
                      Time elapsed: 00:04:49
                               ETA: 00:14:13

################################################################################
                      [1m Learning iteration 127/500 [0m                      

                       Computation: 41301 steps/s (collection: 2.237s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0091
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 11.4818
                       Mean reward: 6.11
               Mean episode length: 838.08
Episode_Reward/track_lin_vel_xy_exp: 0.2664
Episode_Reward/track_ang_vel_z_exp: 0.3150
       Episode_Reward/lin_vel_z_l2: -0.0224
      Episode_Reward/ang_vel_xy_l2: -0.0790
     Episode_Reward/dof_torques_l2: -0.0028
         Episode_Reward/dof_acc_l2: -0.0424
     Episode_Reward/action_rate_l2: -0.0931
      Episode_Reward/feet_air_time: -0.0149
Episode_Reward/flat_orientation_l2: -0.0214
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3696
Metrics/base_velocity/error_vel_xy: 1.0794
Metrics/base_velocity/error_vel_yaw: 0.4739
      Episode_Termination/time_out: 0.6359
  Episode_Termination/base_contact: 0.3641
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 2.38s
                      Time elapsed: 00:04:52
                               ETA: 00:14:11

################################################################################
                      [1m Learning iteration 128/500 [0m                      

                       Computation: 41336 steps/s (collection: 2.228s, learning 0.150s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0088
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 11.4792
                       Mean reward: 5.36
               Mean episode length: 829.16
Episode_Reward/track_lin_vel_xy_exp: 0.2445
Episode_Reward/track_ang_vel_z_exp: 0.3050
       Episode_Reward/lin_vel_z_l2: -0.0229
      Episode_Reward/ang_vel_xy_l2: -0.0777
     Episode_Reward/dof_torques_l2: -0.0027
         Episode_Reward/dof_acc_l2: -0.0462
     Episode_Reward/action_rate_l2: -0.0915
      Episode_Reward/feet_air_time: -0.0154
Episode_Reward/flat_orientation_l2: -0.0212
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3651
Metrics/base_velocity/error_vel_xy: 1.0575
Metrics/base_velocity/error_vel_yaw: 0.4540
      Episode_Termination/time_out: 0.6409
  Episode_Termination/base_contact: 0.3591
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 2.38s
                      Time elapsed: 00:04:54
                               ETA: 00:14:09

################################################################################
                      [1m Learning iteration 129/500 [0m                      

                       Computation: 41445 steps/s (collection: 2.227s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0107
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 11.4940
                       Mean reward: 5.70
               Mean episode length: 817.20
Episode_Reward/track_lin_vel_xy_exp: 0.2517
Episode_Reward/track_ang_vel_z_exp: 0.3061
       Episode_Reward/lin_vel_z_l2: -0.0229
      Episode_Reward/ang_vel_xy_l2: -0.0770
     Episode_Reward/dof_torques_l2: -0.0026
         Episode_Reward/dof_acc_l2: -0.0473
     Episode_Reward/action_rate_l2: -0.0905
      Episode_Reward/feet_air_time: -0.0154
Episode_Reward/flat_orientation_l2: -0.0207
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3611
Metrics/base_velocity/error_vel_xy: 1.0286
Metrics/base_velocity/error_vel_yaw: 0.4342
      Episode_Termination/time_out: 0.6436
  Episode_Termination/base_contact: 0.3564
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 2.37s
                      Time elapsed: 00:04:57
                               ETA: 00:14:07

################################################################################
                      [1m Learning iteration 130/500 [0m                      

                       Computation: 41252 steps/s (collection: 2.239s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0172
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 11.5104
                       Mean reward: 6.22
               Mean episode length: 827.34
Episode_Reward/track_lin_vel_xy_exp: 0.2925
Episode_Reward/track_ang_vel_z_exp: 0.3142
       Episode_Reward/lin_vel_z_l2: -0.0228
      Episode_Reward/ang_vel_xy_l2: -0.0781
     Episode_Reward/dof_torques_l2: -0.0027
         Episode_Reward/dof_acc_l2: -0.0465
     Episode_Reward/action_rate_l2: -0.0922
      Episode_Reward/feet_air_time: -0.0152
Episode_Reward/flat_orientation_l2: -0.0209
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3561
Metrics/base_velocity/error_vel_xy: 0.9928
Metrics/base_velocity/error_vel_yaw: 0.4321
      Episode_Termination/time_out: 0.6482
  Episode_Termination/base_contact: 0.3518
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 2.38s
                      Time elapsed: 00:04:59
                               ETA: 00:14:05

################################################################################
                      [1m Learning iteration 131/500 [0m                      

                       Computation: 40936 steps/s (collection: 2.258s, learning 0.143s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0150
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 11.5405
                       Mean reward: 5.17
               Mean episode length: 793.03
Episode_Reward/track_lin_vel_xy_exp: 0.2595
Episode_Reward/track_ang_vel_z_exp: 0.2948
       Episode_Reward/lin_vel_z_l2: -0.0234
      Episode_Reward/ang_vel_xy_l2: -0.0763
     Episode_Reward/dof_torques_l2: -0.0025
         Episode_Reward/dof_acc_l2: -0.0477
     Episode_Reward/action_rate_l2: -0.0884
      Episode_Reward/feet_air_time: -0.0153
Episode_Reward/flat_orientation_l2: -0.0242
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3513
Metrics/base_velocity/error_vel_xy: 0.9865
Metrics/base_velocity/error_vel_yaw: 0.4405
      Episode_Termination/time_out: 0.6493
  Episode_Termination/base_contact: 0.3507
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 2.40s
                      Time elapsed: 00:05:01
                               ETA: 00:14:03

################################################################################
                      [1m Learning iteration 132/500 [0m                      

                       Computation: 40828 steps/s (collection: 2.263s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0100
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 11.5594
                       Mean reward: 5.30
               Mean episode length: 821.85
Episode_Reward/track_lin_vel_xy_exp: 0.2905
Episode_Reward/track_ang_vel_z_exp: 0.3154
       Episode_Reward/lin_vel_z_l2: -0.0234
      Episode_Reward/ang_vel_xy_l2: -0.0812
     Episode_Reward/dof_torques_l2: -0.0029
         Episode_Reward/dof_acc_l2: -0.0479
     Episode_Reward/action_rate_l2: -0.0960
      Episode_Reward/feet_air_time: -0.0153
Episode_Reward/flat_orientation_l2: -0.0446
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3466
Metrics/base_velocity/error_vel_xy: 1.0527
Metrics/base_velocity/error_vel_yaw: 0.5194
      Episode_Termination/time_out: 0.6525
  Episode_Termination/base_contact: 0.3475
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 2.41s
                      Time elapsed: 00:05:04
                               ETA: 00:14:01

################################################################################
                      [1m Learning iteration 133/500 [0m                      

                       Computation: 40985 steps/s (collection: 2.251s, learning 0.148s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0091
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 11.5679
                       Mean reward: 6.20
               Mean episode length: 785.71
Episode_Reward/track_lin_vel_xy_exp: 0.2726
Episode_Reward/track_ang_vel_z_exp: 0.2900
       Episode_Reward/lin_vel_z_l2: -0.0222
      Episode_Reward/ang_vel_xy_l2: -0.0728
     Episode_Reward/dof_torques_l2: -0.0026
         Episode_Reward/dof_acc_l2: -0.0448
     Episode_Reward/action_rate_l2: -0.0854
      Episode_Reward/feet_air_time: -0.0133
Episode_Reward/flat_orientation_l2: -0.0230
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3427
Metrics/base_velocity/error_vel_xy: 0.9054
Metrics/base_velocity/error_vel_yaw: 0.4054
      Episode_Termination/time_out: 0.6557
  Episode_Termination/base_contact: 0.3443
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 2.40s
                      Time elapsed: 00:05:06
                               ETA: 00:13:59

################################################################################
                      [1m Learning iteration 134/500 [0m                      

                       Computation: 40767 steps/s (collection: 2.266s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0076
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 11.5578
                       Mean reward: 5.36
               Mean episode length: 817.07
Episode_Reward/track_lin_vel_xy_exp: 0.2462
Episode_Reward/track_ang_vel_z_exp: 0.3066
       Episode_Reward/lin_vel_z_l2: -0.0238
      Episode_Reward/ang_vel_xy_l2: -0.0777
     Episode_Reward/dof_torques_l2: -0.0027
         Episode_Reward/dof_acc_l2: -0.0518
     Episode_Reward/action_rate_l2: -0.0922
      Episode_Reward/feet_air_time: -0.0160
Episode_Reward/flat_orientation_l2: -0.0208
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3397
Metrics/base_velocity/error_vel_xy: 1.0501
Metrics/base_velocity/error_vel_yaw: 0.4461
      Episode_Termination/time_out: 0.6595
  Episode_Termination/base_contact: 0.3405
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 2.41s
                      Time elapsed: 00:05:09
                               ETA: 00:13:57

################################################################################
                      [1m Learning iteration 135/500 [0m                      

                       Computation: 41007 steps/s (collection: 2.253s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0126
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 11.5523
                       Mean reward: 6.75
               Mean episode length: 875.40
Episode_Reward/track_lin_vel_xy_exp: 0.2581
Episode_Reward/track_ang_vel_z_exp: 0.3064
       Episode_Reward/lin_vel_z_l2: -0.0228
      Episode_Reward/ang_vel_xy_l2: -0.0768
     Episode_Reward/dof_torques_l2: -0.0026
         Episode_Reward/dof_acc_l2: -0.0503
     Episode_Reward/action_rate_l2: -0.0908
      Episode_Reward/feet_air_time: -0.0157
Episode_Reward/flat_orientation_l2: -0.0184
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3392
Metrics/base_velocity/error_vel_xy: 1.0077
Metrics/base_velocity/error_vel_yaw: 0.4224
      Episode_Termination/time_out: 0.6627
  Episode_Termination/base_contact: 0.3373
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 2.40s
                      Time elapsed: 00:05:11
                               ETA: 00:13:55

################################################################################
                      [1m Learning iteration 136/500 [0m                      

                       Computation: 40680 steps/s (collection: 2.271s, learning 0.146s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0090
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 11.5624
                       Mean reward: 6.20
               Mean episode length: 854.93
Episode_Reward/track_lin_vel_xy_exp: 0.2658
Episode_Reward/track_ang_vel_z_exp: 0.3182
       Episode_Reward/lin_vel_z_l2: -0.0236
      Episode_Reward/ang_vel_xy_l2: -0.0797
     Episode_Reward/dof_torques_l2: -0.0028
         Episode_Reward/dof_acc_l2: -0.0494
     Episode_Reward/action_rate_l2: -0.0939
      Episode_Reward/feet_air_time: -0.0153
Episode_Reward/flat_orientation_l2: -0.0203
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3380
Metrics/base_velocity/error_vel_xy: 1.0584
Metrics/base_velocity/error_vel_yaw: 0.4426
      Episode_Termination/time_out: 0.6695
  Episode_Termination/base_contact: 0.3305
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 2.42s
                      Time elapsed: 00:05:13
                               ETA: 00:13:53

################################################################################
                      [1m Learning iteration 137/500 [0m                      

                       Computation: 40840 steps/s (collection: 2.262s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0115
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 11.5668
                       Mean reward: 5.49
               Mean episode length: 849.67
Episode_Reward/track_lin_vel_xy_exp: 0.2656
Episode_Reward/track_ang_vel_z_exp: 0.3202
       Episode_Reward/lin_vel_z_l2: -0.0234
      Episode_Reward/ang_vel_xy_l2: -0.0789
     Episode_Reward/dof_torques_l2: -0.0028
         Episode_Reward/dof_acc_l2: -0.0504
     Episode_Reward/action_rate_l2: -0.0941
      Episode_Reward/feet_air_time: -0.0160
Episode_Reward/flat_orientation_l2: -0.0466
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3360
Metrics/base_velocity/error_vel_xy: 1.0770
Metrics/base_velocity/error_vel_yaw: 0.4360
      Episode_Termination/time_out: 0.6739
  Episode_Termination/base_contact: 0.3261
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 2.41s
                      Time elapsed: 00:05:16
                               ETA: 00:13:52

################################################################################
                      [1m Learning iteration 138/500 [0m                      

                       Computation: 40770 steps/s (collection: 2.263s, learning 0.148s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0098
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 11.5884
                       Mean reward: 6.24
               Mean episode length: 868.24
Episode_Reward/track_lin_vel_xy_exp: 0.2777
Episode_Reward/track_ang_vel_z_exp: 0.3261
       Episode_Reward/lin_vel_z_l2: -0.0241
      Episode_Reward/ang_vel_xy_l2: -0.0821
     Episode_Reward/dof_torques_l2: -0.0028
         Episode_Reward/dof_acc_l2: -0.0527
     Episode_Reward/action_rate_l2: -0.0969
      Episode_Reward/feet_air_time: -0.0159
Episode_Reward/flat_orientation_l2: -0.0205
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3329
Metrics/base_velocity/error_vel_xy: 1.1071
Metrics/base_velocity/error_vel_yaw: 0.4649
      Episode_Termination/time_out: 0.6797
  Episode_Termination/base_contact: 0.3203
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 2.41s
                      Time elapsed: 00:05:18
                               ETA: 00:13:50

################################################################################
                      [1m Learning iteration 139/500 [0m                      

                       Computation: 40545 steps/s (collection: 2.280s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0079
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 11.5930
                       Mean reward: 6.06
               Mean episode length: 846.81
Episode_Reward/track_lin_vel_xy_exp: 0.2868
Episode_Reward/track_ang_vel_z_exp: 0.3168
       Episode_Reward/lin_vel_z_l2: -0.0247
      Episode_Reward/ang_vel_xy_l2: -0.0813
     Episode_Reward/dof_torques_l2: -0.0029
         Episode_Reward/dof_acc_l2: -0.0525
     Episode_Reward/action_rate_l2: -0.0949
      Episode_Reward/feet_air_time: -0.0161
Episode_Reward/flat_orientation_l2: -0.0205
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3307
Metrics/base_velocity/error_vel_xy: 1.0299
Metrics/base_velocity/error_vel_yaw: 0.4643
      Episode_Termination/time_out: 0.6819
  Episode_Termination/base_contact: 0.3181
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 2.42s
                      Time elapsed: 00:05:21
                               ETA: 00:13:48

################################################################################
                      [1m Learning iteration 140/500 [0m                      

                       Computation: 40955 steps/s (collection: 2.254s, learning 0.146s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0089
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 11.5867
                       Mean reward: 6.42
               Mean episode length: 835.33
Episode_Reward/track_lin_vel_xy_exp: 0.2782
Episode_Reward/track_ang_vel_z_exp: 0.3174
       Episode_Reward/lin_vel_z_l2: -0.0238
      Episode_Reward/ang_vel_xy_l2: -0.0803
     Episode_Reward/dof_torques_l2: -0.0027
         Episode_Reward/dof_acc_l2: -0.0542
     Episode_Reward/action_rate_l2: -0.0937
      Episode_Reward/feet_air_time: -0.0163
Episode_Reward/flat_orientation_l2: -0.0194
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3301
Metrics/base_velocity/error_vel_xy: 1.0290
Metrics/base_velocity/error_vel_yaw: 0.4301
      Episode_Termination/time_out: 0.6854
  Episode_Termination/base_contact: 0.3146
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 2.40s
                      Time elapsed: 00:05:23
                               ETA: 00:13:46

################################################################################
                      [1m Learning iteration 141/500 [0m                      

                       Computation: 40501 steps/s (collection: 2.282s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0120
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 11.5914
                       Mean reward: 6.23
               Mean episode length: 902.69
Episode_Reward/track_lin_vel_xy_exp: 0.2741
Episode_Reward/track_ang_vel_z_exp: 0.3296
       Episode_Reward/lin_vel_z_l2: -0.0248
      Episode_Reward/ang_vel_xy_l2: -0.0848
     Episode_Reward/dof_torques_l2: -0.0030
         Episode_Reward/dof_acc_l2: -0.0598
     Episode_Reward/action_rate_l2: -0.0995
      Episode_Reward/feet_air_time: -0.0174
Episode_Reward/flat_orientation_l2: -0.0193
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3302
Metrics/base_velocity/error_vel_xy: 1.1083
Metrics/base_velocity/error_vel_yaw: 0.4783
      Episode_Termination/time_out: 0.6918
  Episode_Termination/base_contact: 0.3082
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 2.43s
                      Time elapsed: 00:05:25
                               ETA: 00:13:44

################################################################################
                      [1m Learning iteration 142/500 [0m                      

                       Computation: 40380 steps/s (collection: 2.290s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0117
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 11.6068
                       Mean reward: 5.33
               Mean episode length: 874.10
Episode_Reward/track_lin_vel_xy_exp: 0.2798
Episode_Reward/track_ang_vel_z_exp: 0.3147
       Episode_Reward/lin_vel_z_l2: -0.0239
      Episode_Reward/ang_vel_xy_l2: -0.0797
     Episode_Reward/dof_torques_l2: -0.0028
         Episode_Reward/dof_acc_l2: -0.0561
     Episode_Reward/action_rate_l2: -0.0940
      Episode_Reward/feet_air_time: -0.0160
Episode_Reward/flat_orientation_l2: -0.0626
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3322
Metrics/base_velocity/error_vel_xy: 1.0261
Metrics/base_velocity/error_vel_yaw: 0.4463
      Episode_Termination/time_out: 0.6983
  Episode_Termination/base_contact: 0.3017
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 2.43s
                      Time elapsed: 00:05:28
                               ETA: 00:13:42

################################################################################
                      [1m Learning iteration 143/500 [0m                      

                       Computation: 40448 steps/s (collection: 2.287s, learning 0.143s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0102
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 11.6291
                       Mean reward: 6.14
               Mean episode length: 812.00
Episode_Reward/track_lin_vel_xy_exp: 0.2730
Episode_Reward/track_ang_vel_z_exp: 0.2982
       Episode_Reward/lin_vel_z_l2: -0.0231
      Episode_Reward/ang_vel_xy_l2: -0.0751
     Episode_Reward/dof_torques_l2: -0.0026
         Episode_Reward/dof_acc_l2: -0.0525
     Episode_Reward/action_rate_l2: -0.0884
      Episode_Reward/feet_air_time: -0.0153
Episode_Reward/flat_orientation_l2: -0.0209
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3331
Metrics/base_velocity/error_vel_xy: 0.9400
Metrics/base_velocity/error_vel_yaw: 0.4120
      Episode_Termination/time_out: 0.7037
  Episode_Termination/base_contact: 0.2963
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 2.43s
                      Time elapsed: 00:05:30
                               ETA: 00:13:40

################################################################################
                      [1m Learning iteration 144/500 [0m                      

                       Computation: 40444 steps/s (collection: 2.285s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0110
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 11.6486
                       Mean reward: 6.39
               Mean episode length: 905.79
Episode_Reward/track_lin_vel_xy_exp: 0.3122
Episode_Reward/track_ang_vel_z_exp: 0.3394
       Episode_Reward/lin_vel_z_l2: -0.0264
      Episode_Reward/ang_vel_xy_l2: -0.0862
     Episode_Reward/dof_torques_l2: -0.0030
         Episode_Reward/dof_acc_l2: -0.0617
     Episode_Reward/action_rate_l2: -0.1017
      Episode_Reward/feet_air_time: -0.0172
Episode_Reward/flat_orientation_l2: -0.0224
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3338
Metrics/base_velocity/error_vel_xy: 1.0838
Metrics/base_velocity/error_vel_yaw: 0.4681
      Episode_Termination/time_out: 0.7082
  Episode_Termination/base_contact: 0.2918
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 2.43s
                      Time elapsed: 00:05:33
                               ETA: 00:13:38

################################################################################
                      [1m Learning iteration 145/500 [0m                      

                       Computation: 40450 steps/s (collection: 2.286s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0082
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 11.6437
                       Mean reward: 6.03
               Mean episode length: 811.79
Episode_Reward/track_lin_vel_xy_exp: 0.2727
Episode_Reward/track_ang_vel_z_exp: 0.3013
       Episode_Reward/lin_vel_z_l2: -0.0238
      Episode_Reward/ang_vel_xy_l2: -0.0766
     Episode_Reward/dof_torques_l2: -0.0028
         Episode_Reward/dof_acc_l2: -0.0545
     Episode_Reward/action_rate_l2: -0.0910
      Episode_Reward/feet_air_time: -0.0154
Episode_Reward/flat_orientation_l2: -0.0202
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3355
Metrics/base_velocity/error_vel_xy: 0.9811
Metrics/base_velocity/error_vel_yaw: 0.4415
      Episode_Termination/time_out: 0.7136
  Episode_Termination/base_contact: 0.2864
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 2.43s
                      Time elapsed: 00:05:35
                               ETA: 00:13:36

################################################################################
                      [1m Learning iteration 146/500 [0m                      

                       Computation: 40294 steps/s (collection: 2.294s, learning 0.146s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0077
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 11.6262
                       Mean reward: 6.58
               Mean episode length: 845.93
Episode_Reward/track_lin_vel_xy_exp: 0.3153
Episode_Reward/track_ang_vel_z_exp: 0.3207
       Episode_Reward/lin_vel_z_l2: -0.0238
      Episode_Reward/ang_vel_xy_l2: -0.0810
     Episode_Reward/dof_torques_l2: -0.0028
         Episode_Reward/dof_acc_l2: -0.0567
     Episode_Reward/action_rate_l2: -0.0953
      Episode_Reward/feet_air_time: -0.0159
Episode_Reward/flat_orientation_l2: -0.0182
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3351
Metrics/base_velocity/error_vel_xy: 0.9698
Metrics/base_velocity/error_vel_yaw: 0.4433
      Episode_Termination/time_out: 0.7191
  Episode_Termination/base_contact: 0.2809
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 2.44s
                      Time elapsed: 00:05:38
                               ETA: 00:13:34

################################################################################
                      [1m Learning iteration 147/500 [0m                      

                       Computation: 40370 steps/s (collection: 2.291s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0082
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 11.6046
                       Mean reward: 6.52
               Mean episode length: 883.95
Episode_Reward/track_lin_vel_xy_exp: 0.2815
Episode_Reward/track_ang_vel_z_exp: 0.3314
       Episode_Reward/lin_vel_z_l2: -0.0247
      Episode_Reward/ang_vel_xy_l2: -0.0819
     Episode_Reward/dof_torques_l2: -0.0029
         Episode_Reward/dof_acc_l2: -0.0555
     Episode_Reward/action_rate_l2: -0.0977
      Episode_Reward/feet_air_time: -0.0164
Episode_Reward/flat_orientation_l2: -0.0223
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3321
Metrics/base_velocity/error_vel_xy: 1.0770
Metrics/base_velocity/error_vel_yaw: 0.4320
      Episode_Termination/time_out: 0.7230
  Episode_Termination/base_contact: 0.2770
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 2.44s
                      Time elapsed: 00:05:40
                               ETA: 00:13:32

################################################################################
                      [1m Learning iteration 148/500 [0m                      

                       Computation: 40109 steps/s (collection: 2.305s, learning 0.146s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0089
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 11.5986
                       Mean reward: 5.60
               Mean episode length: 863.36
Episode_Reward/track_lin_vel_xy_exp: 0.3035
Episode_Reward/track_ang_vel_z_exp: 0.3159
       Episode_Reward/lin_vel_z_l2: -0.0246
      Episode_Reward/ang_vel_xy_l2: -0.0811
     Episode_Reward/dof_torques_l2: -0.0028
         Episode_Reward/dof_acc_l2: -0.0565
     Episode_Reward/action_rate_l2: -0.0952
      Episode_Reward/feet_air_time: -0.0160
Episode_Reward/flat_orientation_l2: -0.0480
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3305
Metrics/base_velocity/error_vel_xy: 1.0087
Metrics/base_velocity/error_vel_yaw: 0.4543
      Episode_Termination/time_out: 0.7265
  Episode_Termination/base_contact: 0.2735
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 2.45s
                      Time elapsed: 00:05:43
                               ETA: 00:13:30

################################################################################
                      [1m Learning iteration 149/500 [0m                      

                       Computation: 40377 steps/s (collection: 2.291s, learning 0.143s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0111
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 11.5969
                       Mean reward: 6.44
               Mean episode length: 903.06
Episode_Reward/track_lin_vel_xy_exp: 0.3094
Episode_Reward/track_ang_vel_z_exp: 0.3326
       Episode_Reward/lin_vel_z_l2: -0.0265
      Episode_Reward/ang_vel_xy_l2: -0.0873
     Episode_Reward/dof_torques_l2: -0.0030
         Episode_Reward/dof_acc_l2: -0.0664
     Episode_Reward/action_rate_l2: -0.1025
      Episode_Reward/feet_air_time: -0.0180
Episode_Reward/flat_orientation_l2: -0.0230
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3305
Metrics/base_velocity/error_vel_xy: 1.0752
Metrics/base_velocity/error_vel_yaw: 0.4914
      Episode_Termination/time_out: 0.7286
  Episode_Termination/base_contact: 0.2714
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 2.43s
                      Time elapsed: 00:05:45
                               ETA: 00:13:28

################################################################################
                      [1m Learning iteration 150/500 [0m                      

                       Computation: 40252 steps/s (collection: 2.298s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0078
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 11.5908
                       Mean reward: 5.36
               Mean episode length: 899.22
Episode_Reward/track_lin_vel_xy_exp: 0.3169
Episode_Reward/track_ang_vel_z_exp: 0.3383
       Episode_Reward/lin_vel_z_l2: -0.0259
      Episode_Reward/ang_vel_xy_l2: -0.0863
     Episode_Reward/dof_torques_l2: -0.0030
         Episode_Reward/dof_acc_l2: -0.0642
     Episode_Reward/action_rate_l2: -0.1030
      Episode_Reward/feet_air_time: -0.0172
Episode_Reward/flat_orientation_l2: -0.0849
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3329
Metrics/base_velocity/error_vel_xy: 1.0824
Metrics/base_velocity/error_vel_yaw: 0.4824
      Episode_Termination/time_out: 0.7324
  Episode_Termination/base_contact: 0.2676
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 2.44s
                      Time elapsed: 00:05:47
                               ETA: 00:13:26

################################################################################
                      [1m Learning iteration 151/500 [0m                      

                       Computation: 40184 steps/s (collection: 2.301s, learning 0.146s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0092
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 11.5892
                       Mean reward: 6.23
               Mean episode length: 945.18
Episode_Reward/track_lin_vel_xy_exp: 0.3345
Episode_Reward/track_ang_vel_z_exp: 0.3454
       Episode_Reward/lin_vel_z_l2: -0.0257
      Episode_Reward/ang_vel_xy_l2: -0.0870
     Episode_Reward/dof_torques_l2: -0.0031
         Episode_Reward/dof_acc_l2: -0.0645
     Episode_Reward/action_rate_l2: -0.1039
      Episode_Reward/feet_air_time: -0.0176
Episode_Reward/flat_orientation_l2: -0.0673
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3338
Metrics/base_velocity/error_vel_xy: 1.0657
Metrics/base_velocity/error_vel_yaw: 0.4839
      Episode_Termination/time_out: 0.7374
  Episode_Termination/base_contact: 0.2626
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 2.45s
                      Time elapsed: 00:05:50
                               ETA: 00:13:24

################################################################################
                      [1m Learning iteration 152/500 [0m                      

                       Computation: 40282 steps/s (collection: 2.295s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0101
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 11.5711
                       Mean reward: 6.82
               Mean episode length: 957.89
Episode_Reward/track_lin_vel_xy_exp: 0.3480
Episode_Reward/track_ang_vel_z_exp: 0.3568
       Episode_Reward/lin_vel_z_l2: -0.0253
      Episode_Reward/ang_vel_xy_l2: -0.0909
     Episode_Reward/dof_torques_l2: -0.0031
         Episode_Reward/dof_acc_l2: -0.0615
     Episode_Reward/action_rate_l2: -0.1067
      Episode_Reward/feet_air_time: -0.0176
Episode_Reward/flat_orientation_l2: -0.0841
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3349
Metrics/base_velocity/error_vel_xy: 1.1021
Metrics/base_velocity/error_vel_yaw: 0.4968
      Episode_Termination/time_out: 0.7423
  Episode_Termination/base_contact: 0.2577
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 2.44s
                      Time elapsed: 00:05:52
                               ETA: 00:13:22

################################################################################
                      [1m Learning iteration 153/500 [0m                      

                       Computation: 40359 steps/s (collection: 2.292s, learning 0.143s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0109
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 11.5602
                       Mean reward: 6.86
               Mean episode length: 894.12
Episode_Reward/track_lin_vel_xy_exp: 0.3202
Episode_Reward/track_ang_vel_z_exp: 0.3353
       Episode_Reward/lin_vel_z_l2: -0.0259
      Episode_Reward/ang_vel_xy_l2: -0.0879
     Episode_Reward/dof_torques_l2: -0.0030
         Episode_Reward/dof_acc_l2: -0.0650
     Episode_Reward/action_rate_l2: -0.1022
      Episode_Reward/feet_air_time: -0.0170
Episode_Reward/flat_orientation_l2: -0.0209
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3374
Metrics/base_velocity/error_vel_xy: 1.0571
Metrics/base_velocity/error_vel_yaw: 0.4784
      Episode_Termination/time_out: 0.7454
  Episode_Termination/base_contact: 0.2546
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 2.44s
                      Time elapsed: 00:05:55
                               ETA: 00:13:20

################################################################################
                      [1m Learning iteration 154/500 [0m                      

                       Computation: 39860 steps/s (collection: 2.323s, learning 0.143s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0161
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 11.5787
                       Mean reward: 6.93
               Mean episode length: 890.61
Episode_Reward/track_lin_vel_xy_exp: 0.3267
Episode_Reward/track_ang_vel_z_exp: 0.3362
       Episode_Reward/lin_vel_z_l2: -0.0276
      Episode_Reward/ang_vel_xy_l2: -0.0886
     Episode_Reward/dof_torques_l2: -0.0030
         Episode_Reward/dof_acc_l2: -0.0708
     Episode_Reward/action_rate_l2: -0.1029
      Episode_Reward/feet_air_time: -0.0181
Episode_Reward/flat_orientation_l2: -0.0216
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3406
Metrics/base_velocity/error_vel_xy: 1.0478
Metrics/base_velocity/error_vel_yaw: 0.4730
      Episode_Termination/time_out: 0.7469
  Episode_Termination/base_contact: 0.2531
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 2.47s
                      Time elapsed: 00:05:57
                               ETA: 00:13:18

################################################################################
                      [1m Learning iteration 155/500 [0m                      

                       Computation: 40075 steps/s (collection: 2.310s, learning 0.143s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0125
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 11.6120
                       Mean reward: 6.86
               Mean episode length: 945.06
Episode_Reward/track_lin_vel_xy_exp: 0.3145
Episode_Reward/track_ang_vel_z_exp: 0.3426
       Episode_Reward/lin_vel_z_l2: -0.0265
      Episode_Reward/ang_vel_xy_l2: -0.0886
     Episode_Reward/dof_torques_l2: -0.0032
         Episode_Reward/dof_acc_l2: -0.0659
     Episode_Reward/action_rate_l2: -0.1043
      Episode_Reward/feet_air_time: -0.0179
Episode_Reward/flat_orientation_l2: -0.0221
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3437
Metrics/base_velocity/error_vel_xy: 1.1144
Metrics/base_velocity/error_vel_yaw: 0.4952
      Episode_Termination/time_out: 0.7505
  Episode_Termination/base_contact: 0.2495
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 2.45s
                      Time elapsed: 00:06:00
                               ETA: 00:13:16

################################################################################
                      [1m Learning iteration 156/500 [0m                      

                       Computation: 39905 steps/s (collection: 2.321s, learning 0.143s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0131
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 11.6391
                       Mean reward: 6.17
               Mean episode length: 893.70
Episode_Reward/track_lin_vel_xy_exp: 0.3153
Episode_Reward/track_ang_vel_z_exp: 0.3329
       Episode_Reward/lin_vel_z_l2: -0.0261
      Episode_Reward/ang_vel_xy_l2: -0.0860
     Episode_Reward/dof_torques_l2: -0.0030
         Episode_Reward/dof_acc_l2: -0.0639
     Episode_Reward/action_rate_l2: -0.1004
      Episode_Reward/feet_air_time: -0.0171
Episode_Reward/flat_orientation_l2: -0.0221
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3457
Metrics/base_velocity/error_vel_xy: 1.0435
Metrics/base_velocity/error_vel_yaw: 0.4505
      Episode_Termination/time_out: 0.7551
  Episode_Termination/base_contact: 0.2449
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 2.46s
                      Time elapsed: 00:06:02
                               ETA: 00:13:14

################################################################################
                      [1m Learning iteration 157/500 [0m                      

                       Computation: 39971 steps/s (collection: 2.317s, learning 0.143s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0094
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 11.6573
                       Mean reward: 6.90
               Mean episode length: 903.90
Episode_Reward/track_lin_vel_xy_exp: 0.3344
Episode_Reward/track_ang_vel_z_exp: 0.3360
       Episode_Reward/lin_vel_z_l2: -0.0247
      Episode_Reward/ang_vel_xy_l2: -0.0866
     Episode_Reward/dof_torques_l2: -0.0030
         Episode_Reward/dof_acc_l2: -0.0642
     Episode_Reward/action_rate_l2: -0.1008
      Episode_Reward/feet_air_time: -0.0171
Episode_Reward/flat_orientation_l2: -0.0219
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3493
Metrics/base_velocity/error_vel_xy: 1.0406
Metrics/base_velocity/error_vel_yaw: 0.4608
      Episode_Termination/time_out: 0.7597
  Episode_Termination/base_contact: 0.2403
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 2.46s
                      Time elapsed: 00:06:05
                               ETA: 00:13:12

################################################################################
                      [1m Learning iteration 158/500 [0m                      

                       Computation: 40015 steps/s (collection: 2.312s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0093
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 11.6345
                       Mean reward: 7.46
               Mean episode length: 922.74
Episode_Reward/track_lin_vel_xy_exp: 0.3371
Episode_Reward/track_ang_vel_z_exp: 0.3409
       Episode_Reward/lin_vel_z_l2: -0.0261
      Episode_Reward/ang_vel_xy_l2: -0.0896
     Episode_Reward/dof_torques_l2: -0.0031
         Episode_Reward/dof_acc_l2: -0.0664
     Episode_Reward/action_rate_l2: -0.1042
      Episode_Reward/feet_air_time: -0.0179
Episode_Reward/flat_orientation_l2: -0.0243
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3514
Metrics/base_velocity/error_vel_xy: 1.0647
Metrics/base_velocity/error_vel_yaw: 0.4857
      Episode_Termination/time_out: 0.7631
  Episode_Termination/base_contact: 0.2369
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 2.46s
                      Time elapsed: 00:06:07
                               ETA: 00:13:10

################################################################################
                      [1m Learning iteration 159/500 [0m                      

                       Computation: 40287 steps/s (collection: 2.295s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0092
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 11.6069
                       Mean reward: 7.29
               Mean episode length: 925.93
Episode_Reward/track_lin_vel_xy_exp: 0.3553
Episode_Reward/track_ang_vel_z_exp: 0.3326
       Episode_Reward/lin_vel_z_l2: -0.0248
      Episode_Reward/ang_vel_xy_l2: -0.0880
     Episode_Reward/dof_torques_l2: -0.0030
         Episode_Reward/dof_acc_l2: -0.0635
     Episode_Reward/action_rate_l2: -0.1019
      Episode_Reward/feet_air_time: -0.0174
Episode_Reward/flat_orientation_l2: -0.0264
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3571
Metrics/base_velocity/error_vel_xy: 0.9943
Metrics/base_velocity/error_vel_yaw: 0.4845
      Episode_Termination/time_out: 0.7680
  Episode_Termination/base_contact: 0.2320
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 2.44s
                      Time elapsed: 00:06:09
                               ETA: 00:13:08

################################################################################
                      [1m Learning iteration 160/500 [0m                      

                       Computation: 39749 steps/s (collection: 2.329s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0074
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 11.5939
                       Mean reward: 7.21
               Mean episode length: 911.19
Episode_Reward/track_lin_vel_xy_exp: 0.3453
Episode_Reward/track_ang_vel_z_exp: 0.3352
       Episode_Reward/lin_vel_z_l2: -0.0248
      Episode_Reward/ang_vel_xy_l2: -0.0873
     Episode_Reward/dof_torques_l2: -0.0031
         Episode_Reward/dof_acc_l2: -0.0626
     Episode_Reward/action_rate_l2: -0.1017
      Episode_Reward/feet_air_time: -0.0170
Episode_Reward/flat_orientation_l2: -0.0233
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3610
Metrics/base_velocity/error_vel_xy: 1.0149
Metrics/base_velocity/error_vel_yaw: 0.4734
      Episode_Termination/time_out: 0.7728
  Episode_Termination/base_contact: 0.2272
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 2.47s
                      Time elapsed: 00:06:12
                               ETA: 00:13:06

################################################################################
                      [1m Learning iteration 161/500 [0m                      

                       Computation: 40067 steps/s (collection: 2.309s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0079
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 11.5893
                       Mean reward: 5.60
               Mean episode length: 867.15
Episode_Reward/track_lin_vel_xy_exp: 0.3179
Episode_Reward/track_ang_vel_z_exp: 0.3318
       Episode_Reward/lin_vel_z_l2: -0.0263
      Episode_Reward/ang_vel_xy_l2: -0.0879
     Episode_Reward/dof_torques_l2: -0.0030
         Episode_Reward/dof_acc_l2: -0.0708
     Episode_Reward/action_rate_l2: -0.1025
      Episode_Reward/feet_air_time: -0.0173
Episode_Reward/flat_orientation_l2: -0.0477
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3653
Metrics/base_velocity/error_vel_xy: 1.0477
Metrics/base_velocity/error_vel_yaw: 0.4692
      Episode_Termination/time_out: 0.7758
  Episode_Termination/base_contact: 0.2242
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 2.45s
                      Time elapsed: 00:06:14
                               ETA: 00:13:04

################################################################################
                      [1m Learning iteration 162/500 [0m                      

                       Computation: 40184 steps/s (collection: 2.302s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0092
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 11.5865
                       Mean reward: 7.02
               Mean episode length: 902.83
Episode_Reward/track_lin_vel_xy_exp: 0.3361
Episode_Reward/track_ang_vel_z_exp: 0.3462
       Episode_Reward/lin_vel_z_l2: -0.0260
      Episode_Reward/ang_vel_xy_l2: -0.0894
     Episode_Reward/dof_torques_l2: -0.0031
         Episode_Reward/dof_acc_l2: -0.0674
     Episode_Reward/action_rate_l2: -0.1048
      Episode_Reward/feet_air_time: -0.0179
Episode_Reward/flat_orientation_l2: -0.0237
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3690
Metrics/base_velocity/error_vel_xy: 1.0761
Metrics/base_velocity/error_vel_yaw: 0.4720
      Episode_Termination/time_out: 0.7785
  Episode_Termination/base_contact: 0.2215
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 2.45s
                      Time elapsed: 00:06:17
                               ETA: 00:13:02

################################################################################
                      [1m Learning iteration 163/500 [0m                      

                       Computation: 40296 steps/s (collection: 2.296s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0102
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 11.5769
                       Mean reward: 5.81
               Mean episode length: 879.25
Episode_Reward/track_lin_vel_xy_exp: 0.2734
Episode_Reward/track_ang_vel_z_exp: 0.3208
       Episode_Reward/lin_vel_z_l2: -0.0250
      Episode_Reward/ang_vel_xy_l2: -0.0855
     Episode_Reward/dof_torques_l2: -0.0029
         Episode_Reward/dof_acc_l2: -0.0654
     Episode_Reward/action_rate_l2: -0.0985
      Episode_Reward/feet_air_time: -0.0170
Episode_Reward/flat_orientation_l2: -0.0232
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3714
Metrics/base_velocity/error_vel_xy: 1.1308
Metrics/base_velocity/error_vel_yaw: 0.4696
      Episode_Termination/time_out: 0.7821
  Episode_Termination/base_contact: 0.2179
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 2.44s
                      Time elapsed: 00:06:19
                               ETA: 00:13:00

################################################################################
                      [1m Learning iteration 164/500 [0m                      

                       Computation: 40116 steps/s (collection: 2.307s, learning 0.143s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0109
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 11.5799
                       Mean reward: 6.28
               Mean episode length: 888.06
Episode_Reward/track_lin_vel_xy_exp: 0.3379
Episode_Reward/track_ang_vel_z_exp: 0.3357
       Episode_Reward/lin_vel_z_l2: -0.0257
      Episode_Reward/ang_vel_xy_l2: -0.0870
     Episode_Reward/dof_torques_l2: -0.0030
         Episode_Reward/dof_acc_l2: -0.0675
     Episode_Reward/action_rate_l2: -0.1016
      Episode_Reward/feet_air_time: -0.0171
Episode_Reward/flat_orientation_l2: -0.0409
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3769
Metrics/base_velocity/error_vel_xy: 1.0072
Metrics/base_velocity/error_vel_yaw: 0.4483
      Episode_Termination/time_out: 0.7842
  Episode_Termination/base_contact: 0.2158
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 2.45s
                      Time elapsed: 00:06:22
                               ETA: 00:12:58

################################################################################
                      [1m Learning iteration 165/500 [0m                      

                       Computation: 40250 steps/s (collection: 2.298s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0107
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 11.5630
                       Mean reward: 6.95
               Mean episode length: 926.77
Episode_Reward/track_lin_vel_xy_exp: 0.3586
Episode_Reward/track_ang_vel_z_exp: 0.3532
       Episode_Reward/lin_vel_z_l2: -0.0266
      Episode_Reward/ang_vel_xy_l2: -0.0929
     Episode_Reward/dof_torques_l2: -0.0032
         Episode_Reward/dof_acc_l2: -0.0727
     Episode_Reward/action_rate_l2: -0.1075
      Episode_Reward/feet_air_time: -0.0185
Episode_Reward/flat_orientation_l2: -0.0245
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3801
Metrics/base_velocity/error_vel_xy: 1.0578
Metrics/base_velocity/error_vel_yaw: 0.4837
      Episode_Termination/time_out: 0.7856
  Episode_Termination/base_contact: 0.2144
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 2.44s
                      Time elapsed: 00:06:24
                               ETA: 00:12:56

################################################################################
                      [1m Learning iteration 166/500 [0m                      

                       Computation: 40087 steps/s (collection: 2.305s, learning 0.147s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0074
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 11.5398
                       Mean reward: 7.06
               Mean episode length: 957.04
Episode_Reward/track_lin_vel_xy_exp: 0.3414
Episode_Reward/track_ang_vel_z_exp: 0.3560
       Episode_Reward/lin_vel_z_l2: -0.0269
      Episode_Reward/ang_vel_xy_l2: -0.0935
     Episode_Reward/dof_torques_l2: -0.0034
         Episode_Reward/dof_acc_l2: -0.0737
     Episode_Reward/action_rate_l2: -0.1103
      Episode_Reward/feet_air_time: -0.0188
Episode_Reward/flat_orientation_l2: -0.0244
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3843
Metrics/base_velocity/error_vel_xy: 1.1362
Metrics/base_velocity/error_vel_yaw: 0.5127
      Episode_Termination/time_out: 0.7903
  Episode_Termination/base_contact: 0.2097
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 2.45s
                      Time elapsed: 00:06:27
                               ETA: 00:12:54

################################################################################
                      [1m Learning iteration 167/500 [0m                      

                       Computation: 40295 steps/s (collection: 2.292s, learning 0.147s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0083
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 11.5304
                       Mean reward: 6.83
               Mean episode length: 938.74
Episode_Reward/track_lin_vel_xy_exp: 0.2949
Episode_Reward/track_ang_vel_z_exp: 0.3440
       Episode_Reward/lin_vel_z_l2: -0.0265
      Episode_Reward/ang_vel_xy_l2: -0.0913
     Episode_Reward/dof_torques_l2: -0.0032
         Episode_Reward/dof_acc_l2: -0.0682
     Episode_Reward/action_rate_l2: -0.1053
      Episode_Reward/feet_air_time: -0.0177
Episode_Reward/flat_orientation_l2: -0.0222
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3874
Metrics/base_velocity/error_vel_xy: 1.1614
Metrics/base_velocity/error_vel_yaw: 0.4709
      Episode_Termination/time_out: 0.7941
  Episode_Termination/base_contact: 0.2059
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 2.44s
                      Time elapsed: 00:06:29
                               ETA: 00:12:52

################################################################################
                      [1m Learning iteration 168/500 [0m                      

                       Computation: 39783 steps/s (collection: 2.326s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0083
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 11.5151
                       Mean reward: 6.79
               Mean episode length: 919.20
Episode_Reward/track_lin_vel_xy_exp: 0.3419
Episode_Reward/track_ang_vel_z_exp: 0.3439
       Episode_Reward/lin_vel_z_l2: -0.0270
      Episode_Reward/ang_vel_xy_l2: -0.0915
     Episode_Reward/dof_torques_l2: -0.0032
         Episode_Reward/dof_acc_l2: -0.0738
     Episode_Reward/action_rate_l2: -0.1062
      Episode_Reward/feet_air_time: -0.0181
Episode_Reward/flat_orientation_l2: -0.0225
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3910
Metrics/base_velocity/error_vel_xy: 1.0660
Metrics/base_velocity/error_vel_yaw: 0.4852
      Episode_Termination/time_out: 0.7969
  Episode_Termination/base_contact: 0.2031
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 2.47s
                      Time elapsed: 00:06:32
                               ETA: 00:12:50

################################################################################
                      [1m Learning iteration 169/500 [0m                      

                       Computation: 40063 steps/s (collection: 2.307s, learning 0.147s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0111
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 11.5180
                       Mean reward: 6.93
               Mean episode length: 915.32
Episode_Reward/track_lin_vel_xy_exp: 0.3233
Episode_Reward/track_ang_vel_z_exp: 0.3401
       Episode_Reward/lin_vel_z_l2: -0.0241
      Episode_Reward/ang_vel_xy_l2: -0.0891
     Episode_Reward/dof_torques_l2: -0.0032
         Episode_Reward/dof_acc_l2: -0.0629
     Episode_Reward/action_rate_l2: -0.1032
      Episode_Reward/feet_air_time: -0.0165
Episode_Reward/flat_orientation_l2: -0.0233
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3935
Metrics/base_velocity/error_vel_xy: 1.0954
Metrics/base_velocity/error_vel_yaw: 0.4673
      Episode_Termination/time_out: 0.7990
  Episode_Termination/base_contact: 0.2010
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 2.45s
                      Time elapsed: 00:06:34
                               ETA: 00:12:48

################################################################################
                      [1m Learning iteration 170/500 [0m                      

                       Computation: 39848 steps/s (collection: 2.321s, learning 0.146s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0139
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 11.5497
                       Mean reward: 6.06
               Mean episode length: 933.73
Episode_Reward/track_lin_vel_xy_exp: 0.3362
Episode_Reward/track_ang_vel_z_exp: 0.3401
       Episode_Reward/lin_vel_z_l2: -0.0269
      Episode_Reward/ang_vel_xy_l2: -0.0932
     Episode_Reward/dof_torques_l2: -0.0031
         Episode_Reward/dof_acc_l2: -0.0707
     Episode_Reward/action_rate_l2: -0.1050
      Episode_Reward/feet_air_time: -0.0181
Episode_Reward/flat_orientation_l2: -0.0641
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.3969
Metrics/base_velocity/error_vel_xy: 1.0935
Metrics/base_velocity/error_vel_yaw: 0.4932
      Episode_Termination/time_out: 0.8014
  Episode_Termination/base_contact: 0.1986
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 2.47s
                      Time elapsed: 00:06:36
                               ETA: 00:12:46

################################################################################
                      [1m Learning iteration 171/500 [0m                      

                       Computation: 39776 steps/s (collection: 2.321s, learning 0.150s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0122
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 11.5647
                       Mean reward: 6.81
               Mean episode length: 923.90
Episode_Reward/track_lin_vel_xy_exp: 0.3712
Episode_Reward/track_ang_vel_z_exp: 0.3406
       Episode_Reward/lin_vel_z_l2: -0.0264
      Episode_Reward/ang_vel_xy_l2: -0.0931
     Episode_Reward/dof_torques_l2: -0.0031
         Episode_Reward/dof_acc_l2: -0.0745
     Episode_Reward/action_rate_l2: -0.1047
      Episode_Reward/feet_air_time: -0.0177
Episode_Reward/flat_orientation_l2: -0.0411
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4009
Metrics/base_velocity/error_vel_xy: 1.0024
Metrics/base_velocity/error_vel_yaw: 0.4805
      Episode_Termination/time_out: 0.8052
  Episode_Termination/base_contact: 0.1948
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 2.47s
                      Time elapsed: 00:06:39
                               ETA: 00:12:43

################################################################################
                      [1m Learning iteration 172/500 [0m                      

                       Computation: 39767 steps/s (collection: 2.324s, learning 0.148s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0096
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 11.5814
                       Mean reward: 6.59
               Mean episode length: 950.90
Episode_Reward/track_lin_vel_xy_exp: 0.3648
Episode_Reward/track_ang_vel_z_exp: 0.3611
       Episode_Reward/lin_vel_z_l2: -0.0244
      Episode_Reward/ang_vel_xy_l2: -0.0926
     Episode_Reward/dof_torques_l2: -0.0032
         Episode_Reward/dof_acc_l2: -0.0663
     Episode_Reward/action_rate_l2: -0.1074
      Episode_Reward/feet_air_time: -0.0176
Episode_Reward/flat_orientation_l2: -0.0469
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4037
Metrics/base_velocity/error_vel_xy: 1.1047
Metrics/base_velocity/error_vel_yaw: 0.4830
      Episode_Termination/time_out: 0.8085
  Episode_Termination/base_contact: 0.1915
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 2.47s
                      Time elapsed: 00:06:41
                               ETA: 00:12:41

################################################################################
                      [1m Learning iteration 173/500 [0m                      

                       Computation: 39209 steps/s (collection: 2.363s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0137
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 11.6043
                       Mean reward: 7.76
               Mean episode length: 955.70
Episode_Reward/track_lin_vel_xy_exp: 0.3900
Episode_Reward/track_ang_vel_z_exp: 0.3551
       Episode_Reward/lin_vel_z_l2: -0.0263
      Episode_Reward/ang_vel_xy_l2: -0.0937
     Episode_Reward/dof_torques_l2: -0.0033
         Episode_Reward/dof_acc_l2: -0.0737
     Episode_Reward/action_rate_l2: -0.1081
      Episode_Reward/feet_air_time: -0.0182
Episode_Reward/flat_orientation_l2: -0.0290
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4071
Metrics/base_velocity/error_vel_xy: 1.0422
Metrics/base_velocity/error_vel_yaw: 0.4766
      Episode_Termination/time_out: 0.8125
  Episode_Termination/base_contact: 0.1875
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 2.51s
                      Time elapsed: 00:06:44
                               ETA: 00:12:39

################################################################################
                      [1m Learning iteration 174/500 [0m                      

                       Computation: 39662 steps/s (collection: 2.333s, learning 0.146s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0123
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 11.6239
                       Mean reward: 6.44
               Mean episode length: 955.57
Episode_Reward/track_lin_vel_xy_exp: 0.3499
Episode_Reward/track_ang_vel_z_exp: 0.3560
       Episode_Reward/lin_vel_z_l2: -0.0267
      Episode_Reward/ang_vel_xy_l2: -0.0946
     Episode_Reward/dof_torques_l2: -0.0033
         Episode_Reward/dof_acc_l2: -0.0740
     Episode_Reward/action_rate_l2: -0.1098
      Episode_Reward/feet_air_time: -0.0183
Episode_Reward/flat_orientation_l2: -0.0643
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4110
Metrics/base_velocity/error_vel_xy: 1.1265
Metrics/base_velocity/error_vel_yaw: 0.5071
      Episode_Termination/time_out: 0.8164
  Episode_Termination/base_contact: 0.1836
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 2.48s
                      Time elapsed: 00:06:46
                               ETA: 00:12:37

################################################################################
                      [1m Learning iteration 175/500 [0m                      

                       Computation: 39507 steps/s (collection: 2.343s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0149
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 11.6319
                       Mean reward: 7.43
               Mean episode length: 932.95
Episode_Reward/track_lin_vel_xy_exp: 0.3835
Episode_Reward/track_ang_vel_z_exp: 0.3421
       Episode_Reward/lin_vel_z_l2: -0.0279
      Episode_Reward/ang_vel_xy_l2: -0.0930
     Episode_Reward/dof_torques_l2: -0.0032
         Episode_Reward/dof_acc_l2: -0.0792
     Episode_Reward/action_rate_l2: -0.1072
      Episode_Reward/feet_air_time: -0.0179
Episode_Reward/flat_orientation_l2: -0.0253
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4167
Metrics/base_velocity/error_vel_xy: 1.0098
Metrics/base_velocity/error_vel_yaw: 0.4921
      Episode_Termination/time_out: 0.8204
  Episode_Termination/base_contact: 0.1796
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 2.49s
                      Time elapsed: 00:06:49
                               ETA: 00:12:35

################################################################################
                      [1m Learning iteration 176/500 [0m                      

                       Computation: 39639 steps/s (collection: 2.337s, learning 0.143s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0085
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 11.6301
                       Mean reward: 7.09
               Mean episode length: 952.53
Episode_Reward/track_lin_vel_xy_exp: 0.3501
Episode_Reward/track_ang_vel_z_exp: 0.3560
       Episode_Reward/lin_vel_z_l2: -0.0256
      Episode_Reward/ang_vel_xy_l2: -0.0944
     Episode_Reward/dof_torques_l2: -0.0033
         Episode_Reward/dof_acc_l2: -0.0740
     Episode_Reward/action_rate_l2: -0.1095
      Episode_Reward/feet_air_time: -0.0184
Episode_Reward/flat_orientation_l2: -0.0250
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4214
Metrics/base_velocity/error_vel_xy: 1.1375
Metrics/base_velocity/error_vel_yaw: 0.4959
      Episode_Termination/time_out: 0.8236
  Episode_Termination/base_contact: 0.1764
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 2.48s
                      Time elapsed: 00:06:51
                               ETA: 00:12:33

################################################################################
                      [1m Learning iteration 177/500 [0m                      

                       Computation: 39352 steps/s (collection: 2.353s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0111
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 11.6211
                       Mean reward: 7.39
               Mean episode length: 954.37
Episode_Reward/track_lin_vel_xy_exp: 0.3876
Episode_Reward/track_ang_vel_z_exp: 0.3607
       Episode_Reward/lin_vel_z_l2: -0.0260
      Episode_Reward/ang_vel_xy_l2: -0.0962
     Episode_Reward/dof_torques_l2: -0.0033
         Episode_Reward/dof_acc_l2: -0.0774
     Episode_Reward/action_rate_l2: -0.1105
      Episode_Reward/feet_air_time: -0.0186
Episode_Reward/flat_orientation_l2: -0.0225
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4261
Metrics/base_velocity/error_vel_xy: 1.0774
Metrics/base_velocity/error_vel_yaw: 0.4976
      Episode_Termination/time_out: 0.8269
  Episode_Termination/base_contact: 0.1731
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 2.50s
                      Time elapsed: 00:06:54
                               ETA: 00:12:31

################################################################################
                      [1m Learning iteration 178/500 [0m                      

                       Computation: 39218 steps/s (collection: 2.362s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0127
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 11.6310
                       Mean reward: 7.22
               Mean episode length: 927.82
Episode_Reward/track_lin_vel_xy_exp: 0.3923
Episode_Reward/track_ang_vel_z_exp: 0.3476
       Episode_Reward/lin_vel_z_l2: -0.0270
      Episode_Reward/ang_vel_xy_l2: -0.0941
     Episode_Reward/dof_torques_l2: -0.0033
         Episode_Reward/dof_acc_l2: -0.0773
     Episode_Reward/action_rate_l2: -0.1081
      Episode_Reward/feet_air_time: -0.0180
Episode_Reward/flat_orientation_l2: -0.0316
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4320
Metrics/base_velocity/error_vel_xy: 1.0193
Metrics/base_velocity/error_vel_yaw: 0.4944
      Episode_Termination/time_out: 0.8292
  Episode_Termination/base_contact: 0.1708
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 2.51s
                      Time elapsed: 00:06:56
                               ETA: 00:12:29

################################################################################
                      [1m Learning iteration 179/500 [0m                      

                       Computation: 39382 steps/s (collection: 2.351s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0133
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 11.6318
                       Mean reward: 6.85
               Mean episode length: 939.91
Episode_Reward/track_lin_vel_xy_exp: 0.3670
Episode_Reward/track_ang_vel_z_exp: 0.3530
       Episode_Reward/lin_vel_z_l2: -0.0271
      Episode_Reward/ang_vel_xy_l2: -0.0955
     Episode_Reward/dof_torques_l2: -0.0033
         Episode_Reward/dof_acc_l2: -0.0778
     Episode_Reward/action_rate_l2: -0.1095
      Episode_Reward/feet_air_time: -0.0185
Episode_Reward/flat_orientation_l2: -0.0253
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4354
Metrics/base_velocity/error_vel_xy: 1.0689
Metrics/base_velocity/error_vel_yaw: 0.5013
      Episode_Termination/time_out: 0.8330
  Episode_Termination/base_contact: 0.1670
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 2.50s
                      Time elapsed: 00:06:59
                               ETA: 00:12:27

################################################################################
                      [1m Learning iteration 180/500 [0m                      

                       Computation: 39473 steps/s (collection: 2.345s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0156
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 11.6412
                       Mean reward: 7.47
               Mean episode length: 946.87
Episode_Reward/track_lin_vel_xy_exp: 0.3710
Episode_Reward/track_ang_vel_z_exp: 0.3483
       Episode_Reward/lin_vel_z_l2: -0.0282
      Episode_Reward/ang_vel_xy_l2: -0.0962
     Episode_Reward/dof_torques_l2: -0.0033
         Episode_Reward/dof_acc_l2: -0.0813
     Episode_Reward/action_rate_l2: -0.1094
      Episode_Reward/feet_air_time: -0.0181
Episode_Reward/flat_orientation_l2: -0.0262
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4393
Metrics/base_velocity/error_vel_xy: 1.0700
Metrics/base_velocity/error_vel_yaw: 0.4939
      Episode_Termination/time_out: 0.8354
  Episode_Termination/base_contact: 0.1646
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 2.49s
                      Time elapsed: 00:07:01
                               ETA: 00:12:25

################################################################################
                      [1m Learning iteration 181/500 [0m                      

                       Computation: 39607 steps/s (collection: 2.339s, learning 0.143s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0104
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 11.6495
                       Mean reward: 7.97
               Mean episode length: 926.56
Episode_Reward/track_lin_vel_xy_exp: 0.4245
Episode_Reward/track_ang_vel_z_exp: 0.3479
       Episode_Reward/lin_vel_z_l2: -0.0269
      Episode_Reward/ang_vel_xy_l2: -0.0944
     Episode_Reward/dof_torques_l2: -0.0033
         Episode_Reward/dof_acc_l2: -0.0785
     Episode_Reward/action_rate_l2: -0.1090
      Episode_Reward/feet_air_time: -0.0181
Episode_Reward/flat_orientation_l2: -0.0242
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4452
Metrics/base_velocity/error_vel_xy: 0.9354
Metrics/base_velocity/error_vel_yaw: 0.4885
      Episode_Termination/time_out: 0.8381
  Episode_Termination/base_contact: 0.1619
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 2.48s
                      Time elapsed: 00:07:04
                               ETA: 00:12:23

################################################################################
                      [1m Learning iteration 182/500 [0m                      

                       Computation: 39562 steps/s (collection: 2.342s, learning 0.143s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0142
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 11.6633
                       Mean reward: 6.50
               Mean episode length: 938.08
Episode_Reward/track_lin_vel_xy_exp: 0.3387
Episode_Reward/track_ang_vel_z_exp: 0.3556
       Episode_Reward/lin_vel_z_l2: -0.0276
      Episode_Reward/ang_vel_xy_l2: -0.0966
     Episode_Reward/dof_torques_l2: -0.0033
         Episode_Reward/dof_acc_l2: -0.0799
     Episode_Reward/action_rate_l2: -0.1102
      Episode_Reward/feet_air_time: -0.0191
Episode_Reward/flat_orientation_l2: -0.0235
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4482
Metrics/base_velocity/error_vel_xy: 1.1184
Metrics/base_velocity/error_vel_yaw: 0.4898
      Episode_Termination/time_out: 0.8410
  Episode_Termination/base_contact: 0.1590
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 2.48s
                      Time elapsed: 00:07:06
                               ETA: 00:12:21

################################################################################
                      [1m Learning iteration 183/500 [0m                      

                       Computation: 39412 steps/s (collection: 2.350s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0222
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 11.7049
                       Mean reward: 7.05
               Mean episode length: 945.91
Episode_Reward/track_lin_vel_xy_exp: 0.3770
Episode_Reward/track_ang_vel_z_exp: 0.3517
       Episode_Reward/lin_vel_z_l2: -0.0264
      Episode_Reward/ang_vel_xy_l2: -0.0945
     Episode_Reward/dof_torques_l2: -0.0032
         Episode_Reward/dof_acc_l2: -0.0747
     Episode_Reward/action_rate_l2: -0.1081
      Episode_Reward/feet_air_time: -0.0174
Episode_Reward/flat_orientation_l2: -0.0289
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4542
Metrics/base_velocity/error_vel_xy: 1.0517
Metrics/base_velocity/error_vel_yaw: 0.4830
      Episode_Termination/time_out: 0.8440
  Episode_Termination/base_contact: 0.1560
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 2.49s
                      Time elapsed: 00:07:09
                               ETA: 00:12:19

################################################################################
                      [1m Learning iteration 184/500 [0m                      

                       Computation: 39163 steps/s (collection: 2.366s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0115
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 11.7333
                       Mean reward: 7.03
               Mean episode length: 918.81
Episode_Reward/track_lin_vel_xy_exp: 0.3543
Episode_Reward/track_ang_vel_z_exp: 0.3490
       Episode_Reward/lin_vel_z_l2: -0.0267
      Episode_Reward/ang_vel_xy_l2: -0.0955
     Episode_Reward/dof_torques_l2: -0.0032
         Episode_Reward/dof_acc_l2: -0.0738
     Episode_Reward/action_rate_l2: -0.1082
      Episode_Reward/feet_air_time: -0.0181
Episode_Reward/flat_orientation_l2: -0.0265
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4575
Metrics/base_velocity/error_vel_xy: 1.0829
Metrics/base_velocity/error_vel_yaw: 0.4901
      Episode_Termination/time_out: 0.8466
  Episode_Termination/base_contact: 0.1534
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 2.51s
                      Time elapsed: 00:07:11
                               ETA: 00:12:17

################################################################################
                      [1m Learning iteration 185/500 [0m                      

                       Computation: 39351 steps/s (collection: 2.354s, learning 0.144s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0163
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 11.7500
                       Mean reward: 7.31
               Mean episode length: 928.04
Episode_Reward/track_lin_vel_xy_exp: 0.3579
Episode_Reward/track_ang_vel_z_exp: 0.3425
       Episode_Reward/lin_vel_z_l2: -0.0271
      Episode_Reward/ang_vel_xy_l2: -0.0934
     Episode_Reward/dof_torques_l2: -0.0033
         Episode_Reward/dof_acc_l2: -0.0782
     Episode_Reward/action_rate_l2: -0.1075
      Episode_Reward/feet_air_time: -0.0176
Episode_Reward/flat_orientation_l2: -0.0255
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4607
Metrics/base_velocity/error_vel_xy: 1.0521
Metrics/base_velocity/error_vel_yaw: 0.4948
      Episode_Termination/time_out: 0.8497
  Episode_Termination/base_contact: 0.1503
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 2.50s
                      Time elapsed: 00:07:14
                               ETA: 00:12:15

################################################################################
                      [1m Learning iteration 186/500 [0m                      

                       Computation: 39437 steps/s (collection: 2.350s, learning 0.143s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0160
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 11.7802
                       Mean reward: 6.93
               Mean episode length: 921.59
Episode_Reward/track_lin_vel_xy_exp: 0.3777
Episode_Reward/track_ang_vel_z_exp: 0.3346
       Episode_Reward/lin_vel_z_l2: -0.0285
      Episode_Reward/ang_vel_xy_l2: -0.0941
     Episode_Reward/dof_torques_l2: -0.0033
         Episode_Reward/dof_acc_l2: -0.0836
     Episode_Reward/action_rate_l2: -0.1077
      Episode_Reward/feet_air_time: -0.0173
Episode_Reward/flat_orientation_l2: -0.0492
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4657
Metrics/base_velocity/error_vel_xy: 1.0130
Metrics/base_velocity/error_vel_yaw: 0.5117
      Episode_Termination/time_out: 0.8513
  Episode_Termination/base_contact: 0.1487
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 2.49s
                      Time elapsed: 00:07:16
                               ETA: 00:12:13

################################################################################
                      [1m Learning iteration 187/500 [0m                      

                       Computation: 39329 steps/s (collection: 2.355s, learning 0.144s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0139
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 11.7972
                       Mean reward: 7.38
               Mean episode length: 906.25
Episode_Reward/track_lin_vel_xy_exp: 0.3750
Episode_Reward/track_ang_vel_z_exp: 0.3317
       Episode_Reward/lin_vel_z_l2: -0.0268
      Episode_Reward/ang_vel_xy_l2: -0.0906
     Episode_Reward/dof_torques_l2: -0.0031
         Episode_Reward/dof_acc_l2: -0.0772
     Episode_Reward/action_rate_l2: -0.1034
      Episode_Reward/feet_air_time: -0.0174
Episode_Reward/flat_orientation_l2: -0.0253
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4724
Metrics/base_velocity/error_vel_xy: 0.9401
Metrics/base_velocity/error_vel_yaw: 0.4495
      Episode_Termination/time_out: 0.8527
  Episode_Termination/base_contact: 0.1473
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 2.50s
                      Time elapsed: 00:07:19
                               ETA: 00:12:11

################################################################################
                      [1m Learning iteration 188/500 [0m                      

                       Computation: 39357 steps/s (collection: 2.351s, learning 0.147s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0180
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 11.8136
                       Mean reward: 7.17
               Mean episode length: 904.29
Episode_Reward/track_lin_vel_xy_exp: 0.3806
Episode_Reward/track_ang_vel_z_exp: 0.3294
       Episode_Reward/lin_vel_z_l2: -0.0265
      Episode_Reward/ang_vel_xy_l2: -0.0907
     Episode_Reward/dof_torques_l2: -0.0031
         Episode_Reward/dof_acc_l2: -0.0749
     Episode_Reward/action_rate_l2: -0.1039
      Episode_Reward/feet_air_time: -0.0175
Episode_Reward/flat_orientation_l2: -0.0293
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4770
Metrics/base_velocity/error_vel_xy: 0.9368
Metrics/base_velocity/error_vel_yaw: 0.4717
      Episode_Termination/time_out: 0.8549
  Episode_Termination/base_contact: 0.1451
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 2.50s
                      Time elapsed: 00:07:21
                               ETA: 00:12:09

################################################################################
                      [1m Learning iteration 189/500 [0m                      

                       Computation: 39381 steps/s (collection: 2.352s, learning 0.144s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0183
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 11.8331
                       Mean reward: 7.15
               Mean episode length: 932.23
Episode_Reward/track_lin_vel_xy_exp: 0.3563
Episode_Reward/track_ang_vel_z_exp: 0.3400
       Episode_Reward/lin_vel_z_l2: -0.0270
      Episode_Reward/ang_vel_xy_l2: -0.0938
     Episode_Reward/dof_torques_l2: -0.0032
         Episode_Reward/dof_acc_l2: -0.0782
     Episode_Reward/action_rate_l2: -0.1069
      Episode_Reward/feet_air_time: -0.0181
Episode_Reward/flat_orientation_l2: -0.0271
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4803
Metrics/base_velocity/error_vel_xy: 1.0322
Metrics/base_velocity/error_vel_yaw: 0.4794
      Episode_Termination/time_out: 0.8551
  Episode_Termination/base_contact: 0.1449
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 2.50s
                      Time elapsed: 00:07:24
                               ETA: 00:12:07

################################################################################
                      [1m Learning iteration 190/500 [0m                      

                       Computation: 38946 steps/s (collection: 2.375s, learning 0.149s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0148
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 11.8591
                       Mean reward: 8.04
               Mean episode length: 944.88
Episode_Reward/track_lin_vel_xy_exp: 0.4172
Episode_Reward/track_ang_vel_z_exp: 0.3566
       Episode_Reward/lin_vel_z_l2: -0.0279
      Episode_Reward/ang_vel_xy_l2: -0.0980
     Episode_Reward/dof_torques_l2: -0.0033
         Episode_Reward/dof_acc_l2: -0.0814
     Episode_Reward/action_rate_l2: -0.1115
      Episode_Reward/feet_air_time: -0.0185
Episode_Reward/flat_orientation_l2: -0.0257
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4820
Metrics/base_velocity/error_vel_xy: 1.0181
Metrics/base_velocity/error_vel_yaw: 0.4998
      Episode_Termination/time_out: 0.8583
  Episode_Termination/base_contact: 0.1417
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 2.52s
                      Time elapsed: 00:07:26
                               ETA: 00:12:05

################################################################################
                      [1m Learning iteration 191/500 [0m                      

                       Computation: 39393 steps/s (collection: 2.352s, learning 0.144s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0131
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 11.8616
                       Mean reward: 6.57
               Mean episode length: 887.46
Episode_Reward/track_lin_vel_xy_exp: 0.3691
Episode_Reward/track_ang_vel_z_exp: 0.3271
       Episode_Reward/lin_vel_z_l2: -0.0294
      Episode_Reward/ang_vel_xy_l2: -0.0931
     Episode_Reward/dof_torques_l2: -0.0031
         Episode_Reward/dof_acc_l2: -0.0803
     Episode_Reward/action_rate_l2: -0.1047
      Episode_Reward/feet_air_time: -0.0169
Episode_Reward/flat_orientation_l2: -0.0275
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4852
Metrics/base_velocity/error_vel_xy: 0.9661
Metrics/base_velocity/error_vel_yaw: 0.4620
      Episode_Termination/time_out: 0.8593
  Episode_Termination/base_contact: 0.1407
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 2.50s
                      Time elapsed: 00:07:29
                               ETA: 00:12:03

################################################################################
                      [1m Learning iteration 192/500 [0m                      

                       Computation: 39487 steps/s (collection: 2.346s, learning 0.144s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0109
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 11.8518
                       Mean reward: 6.89
               Mean episode length: 928.80
Episode_Reward/track_lin_vel_xy_exp: 0.3792
Episode_Reward/track_ang_vel_z_exp: 0.3410
       Episode_Reward/lin_vel_z_l2: -0.0271
      Episode_Reward/ang_vel_xy_l2: -0.0941
     Episode_Reward/dof_torques_l2: -0.0033
         Episode_Reward/dof_acc_l2: -0.0789
     Episode_Reward/action_rate_l2: -0.1072
      Episode_Reward/feet_air_time: -0.0170
Episode_Reward/flat_orientation_l2: -0.0408
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4885
Metrics/base_velocity/error_vel_xy: 1.0140
Metrics/base_velocity/error_vel_yaw: 0.4837
      Episode_Termination/time_out: 0.8587
  Episode_Termination/base_contact: 0.1413
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 2.49s
                      Time elapsed: 00:07:31
                               ETA: 00:12:00

################################################################################
                      [1m Learning iteration 193/500 [0m                      

                       Computation: 39388 steps/s (collection: 2.349s, learning 0.147s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0117
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 11.8543
                       Mean reward: 7.36
               Mean episode length: 942.16
Episode_Reward/track_lin_vel_xy_exp: 0.3747
Episode_Reward/track_ang_vel_z_exp: 0.3477
       Episode_Reward/lin_vel_z_l2: -0.0272
      Episode_Reward/ang_vel_xy_l2: -0.0958
     Episode_Reward/dof_torques_l2: -0.0034
         Episode_Reward/dof_acc_l2: -0.0787
     Episode_Reward/action_rate_l2: -0.1100
      Episode_Reward/feet_air_time: -0.0184
Episode_Reward/flat_orientation_l2: -0.0281
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4936
Metrics/base_velocity/error_vel_xy: 1.0620
Metrics/base_velocity/error_vel_yaw: 0.5031
      Episode_Termination/time_out: 0.8587
  Episode_Termination/base_contact: 0.1413
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 2.50s
                      Time elapsed: 00:07:34
                               ETA: 00:11:58

################################################################################
                      [1m Learning iteration 194/500 [0m                      

                       Computation: 39371 steps/s (collection: 2.353s, learning 0.144s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0112
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 11.8599
                       Mean reward: 7.55
               Mean episode length: 944.26
Episode_Reward/track_lin_vel_xy_exp: 0.4147
Episode_Reward/track_ang_vel_z_exp: 0.3447
       Episode_Reward/lin_vel_z_l2: -0.0284
      Episode_Reward/ang_vel_xy_l2: -0.0970
     Episode_Reward/dof_torques_l2: -0.0033
         Episode_Reward/dof_acc_l2: -0.0856
     Episode_Reward/action_rate_l2: -0.1099
      Episode_Reward/feet_air_time: -0.0183
Episode_Reward/flat_orientation_l2: -0.0265
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.4983
Metrics/base_velocity/error_vel_xy: 0.9657
Metrics/base_velocity/error_vel_yaw: 0.4873
      Episode_Termination/time_out: 0.8581
  Episode_Termination/base_contact: 0.1419
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 2.50s
                      Time elapsed: 00:07:36
                               ETA: 00:11:56

################################################################################
                      [1m Learning iteration 195/500 [0m                      

                       Computation: 39580 steps/s (collection: 2.339s, learning 0.145s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0113
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 11.8538
                       Mean reward: 7.39
               Mean episode length: 928.46
Episode_Reward/track_lin_vel_xy_exp: 0.4006
Episode_Reward/track_ang_vel_z_exp: 0.3463
       Episode_Reward/lin_vel_z_l2: -0.0288
      Episode_Reward/ang_vel_xy_l2: -0.0984
     Episode_Reward/dof_torques_l2: -0.0032
         Episode_Reward/dof_acc_l2: -0.0891
     Episode_Reward/action_rate_l2: -0.1104
      Episode_Reward/feet_air_time: -0.0187
Episode_Reward/flat_orientation_l2: -0.0245
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.5060
Metrics/base_velocity/error_vel_xy: 0.9846
Metrics/base_velocity/error_vel_yaw: 0.4728
      Episode_Termination/time_out: 0.8588
  Episode_Termination/base_contact: 0.1412
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 2.48s
                      Time elapsed: 00:07:39
                               ETA: 00:11:54

################################################################################
                      [1m Learning iteration 196/500 [0m                      

                       Computation: 39270 steps/s (collection: 2.358s, learning 0.145s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0138
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 11.8544
                       Mean reward: 7.29
               Mean episode length: 937.66
Episode_Reward/track_lin_vel_xy_exp: 0.4040
Episode_Reward/track_ang_vel_z_exp: 0.3455
       Episode_Reward/lin_vel_z_l2: -0.0281
      Episode_Reward/ang_vel_xy_l2: -0.0965
     Episode_Reward/dof_torques_l2: -0.0033
         Episode_Reward/dof_acc_l2: -0.0828
     Episode_Reward/action_rate_l2: -0.1106
      Episode_Reward/feet_air_time: -0.0185
Episode_Reward/flat_orientation_l2: -0.0376
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.5121
Metrics/base_velocity/error_vel_xy: 0.9754
Metrics/base_velocity/error_vel_yaw: 0.4887
      Episode_Termination/time_out: 0.8598
  Episode_Termination/base_contact: 0.1402
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 2.50s
                      Time elapsed: 00:07:41
                               ETA: 00:11:52

################################################################################
                      [1m Learning iteration 197/500 [0m                      

                       Computation: 39371 steps/s (collection: 2.353s, learning 0.144s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0100
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 11.8656
                       Mean reward: 7.48
               Mean episode length: 950.46
Episode_Reward/track_lin_vel_xy_exp: 0.3887
Episode_Reward/track_ang_vel_z_exp: 0.3556
       Episode_Reward/lin_vel_z_l2: -0.0289
      Episode_Reward/ang_vel_xy_l2: -0.1002
     Episode_Reward/dof_torques_l2: -0.0035
         Episode_Reward/dof_acc_l2: -0.0853
     Episode_Reward/action_rate_l2: -0.1140
      Episode_Reward/feet_air_time: -0.0184
Episode_Reward/flat_orientation_l2: -0.0275
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.5187
Metrics/base_velocity/error_vel_xy: 1.0584
Metrics/base_velocity/error_vel_yaw: 0.5129
      Episode_Termination/time_out: 0.8607
  Episode_Termination/base_contact: 0.1393
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 2.50s
                      Time elapsed: 00:07:44
                               ETA: 00:11:50

################################################################################
                      [1m Learning iteration 198/500 [0m                      

                       Computation: 39491 steps/s (collection: 2.345s, learning 0.144s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0117
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 11.8516
                       Mean reward: 7.19
               Mean episode length: 946.30
Episode_Reward/track_lin_vel_xy_exp: 0.3736
Episode_Reward/track_ang_vel_z_exp: 0.3518
       Episode_Reward/lin_vel_z_l2: -0.0272
      Episode_Reward/ang_vel_xy_l2: -0.0983
     Episode_Reward/dof_torques_l2: -0.0034
         Episode_Reward/dof_acc_l2: -0.0819
     Episode_Reward/action_rate_l2: -0.1117
      Episode_Reward/feet_air_time: -0.0174
Episode_Reward/flat_orientation_l2: -0.0262
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.5261
Metrics/base_velocity/error_vel_xy: 1.0858
Metrics/base_velocity/error_vel_yaw: 0.5040
      Episode_Termination/time_out: 0.8638
  Episode_Termination/base_contact: 0.1362
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 2.49s
                      Time elapsed: 00:07:46
                               ETA: 00:11:48

################################################################################
                      [1m Learning iteration 199/500 [0m                      

                       Computation: 39525 steps/s (collection: 2.343s, learning 0.144s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0106
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 11.8397
                       Mean reward: 6.93
               Mean episode length: 881.36
Episode_Reward/track_lin_vel_xy_exp: 0.3480
Episode_Reward/track_ang_vel_z_exp: 0.3319
       Episode_Reward/lin_vel_z_l2: -0.0255
      Episode_Reward/ang_vel_xy_l2: -0.0916
     Episode_Reward/dof_torques_l2: -0.0032
         Episode_Reward/dof_acc_l2: -0.0746
     Episode_Reward/action_rate_l2: -0.1048
      Episode_Reward/feet_air_time: -0.0168
Episode_Reward/flat_orientation_l2: -0.0253
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.5308
Metrics/base_velocity/error_vel_xy: 1.0304
Metrics/base_velocity/error_vel_yaw: 0.4678
      Episode_Termination/time_out: 0.8648
  Episode_Termination/base_contact: 0.1352
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 2.49s
                      Time elapsed: 00:07:49
                               ETA: 00:11:46

################################################################################
                      [1m Learning iteration 200/500 [0m                      

                       Computation: 39836 steps/s (collection: 2.324s, learning 0.143s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0126
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 11.8483
                       Mean reward: 7.30
               Mean episode length: 922.81
Episode_Reward/track_lin_vel_xy_exp: 0.4022
Episode_Reward/track_ang_vel_z_exp: 0.3361
       Episode_Reward/lin_vel_z_l2: -0.0289
      Episode_Reward/ang_vel_xy_l2: -0.0971
     Episode_Reward/dof_torques_l2: -0.0033
         Episode_Reward/dof_acc_l2: -0.0914
     Episode_Reward/action_rate_l2: -0.1105
      Episode_Reward/feet_air_time: -0.0180
Episode_Reward/flat_orientation_l2: -0.0260
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.5362
Metrics/base_velocity/error_vel_xy: 0.9527
Metrics/base_velocity/error_vel_yaw: 0.4897
      Episode_Termination/time_out: 0.8634
  Episode_Termination/base_contact: 0.1366
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 2.47s
                      Time elapsed: 00:07:51
                               ETA: 00:11:44

################################################################################
                      [1m Learning iteration 201/500 [0m                      

                       Computation: 40038 steps/s (collection: 2.311s, learning 0.144s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0164
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 11.8631
                       Mean reward: 7.80
               Mean episode length: 918.50
Episode_Reward/track_lin_vel_xy_exp: 0.4286
Episode_Reward/track_ang_vel_z_exp: 0.3415
       Episode_Reward/lin_vel_z_l2: -0.0275
      Episode_Reward/ang_vel_xy_l2: -0.0965
     Episode_Reward/dof_torques_l2: -0.0034
         Episode_Reward/dof_acc_l2: -0.0854
     Episode_Reward/action_rate_l2: -0.1105
      Episode_Reward/feet_air_time: -0.0174
Episode_Reward/flat_orientation_l2: -0.0387
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.5430
Metrics/base_velocity/error_vel_xy: 0.9278
Metrics/base_velocity/error_vel_yaw: 0.4956
      Episode_Termination/time_out: 0.8628
  Episode_Termination/base_contact: 0.1372
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 2.46s
                      Time elapsed: 00:07:54
                               ETA: 00:11:41

################################################################################
                      [1m Learning iteration 202/500 [0m                      

                       Computation: 39651 steps/s (collection: 2.332s, learning 0.147s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0168
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 11.8882
                       Mean reward: 7.97
               Mean episode length: 887.67
Episode_Reward/track_lin_vel_xy_exp: 0.4203
Episode_Reward/track_ang_vel_z_exp: 0.3232
       Episode_Reward/lin_vel_z_l2: -0.0261
      Episode_Reward/ang_vel_xy_l2: -0.0915
     Episode_Reward/dof_torques_l2: -0.0031
         Episode_Reward/dof_acc_l2: -0.0758
     Episode_Reward/action_rate_l2: -0.1033
      Episode_Reward/feet_air_time: -0.0163
Episode_Reward/flat_orientation_l2: -0.0267
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.5473
Metrics/base_velocity/error_vel_xy: 0.8558
Metrics/base_velocity/error_vel_yaw: 0.4617
      Episode_Termination/time_out: 0.8618
  Episode_Termination/base_contact: 0.1382
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 2.48s
                      Time elapsed: 00:07:56
                               ETA: 00:11:39

################################################################################
                      [1m Learning iteration 203/500 [0m                      

                       Computation: 39705 steps/s (collection: 2.332s, learning 0.144s)
             Mean action noise std: 0.67
          Mean value_function loss: 0.0174
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 11.9130
                       Mean reward: 7.20
               Mean episode length: 930.04
Episode_Reward/track_lin_vel_xy_exp: 0.3904
Episode_Reward/track_ang_vel_z_exp: 0.3388
       Episode_Reward/lin_vel_z_l2: -0.0295
      Episode_Reward/ang_vel_xy_l2: -0.0988
     Episode_Reward/dof_torques_l2: -0.0034
         Episode_Reward/dof_acc_l2: -0.0907
     Episode_Reward/action_rate_l2: -0.1112
      Episode_Reward/feet_air_time: -0.0181
Episode_Reward/flat_orientation_l2: -0.0311
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.5512
Metrics/base_velocity/error_vel_xy: 0.9859
Metrics/base_velocity/error_vel_yaw: 0.4980
      Episode_Termination/time_out: 0.8634
  Episode_Termination/base_contact: 0.1366
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 2.48s
                      Time elapsed: 00:07:59
                               ETA: 00:11:37

################################################################################
                      [1m Learning iteration 204/500 [0m                      

                       Computation: 39362 steps/s (collection: 2.353s, learning 0.144s)
             Mean action noise std: 0.67
          Mean value_function loss: 0.0126
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 11.9288
                       Mean reward: 7.19
               Mean episode length: 876.66
Episode_Reward/track_lin_vel_xy_exp: 0.3963
Episode_Reward/track_ang_vel_z_exp: 0.3215
       Episode_Reward/lin_vel_z_l2: -0.0284
      Episode_Reward/ang_vel_xy_l2: -0.0929
     Episode_Reward/dof_torques_l2: -0.0033
         Episode_Reward/dof_acc_l2: -0.0913
     Episode_Reward/action_rate_l2: -0.1060
      Episode_Reward/feet_air_time: -0.0170
Episode_Reward/flat_orientation_l2: -0.0315
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.5561
Metrics/base_velocity/error_vel_xy: 0.9019
Metrics/base_velocity/error_vel_yaw: 0.4677
      Episode_Termination/time_out: 0.8626
  Episode_Termination/base_contact: 0.1374
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 2.50s
                      Time elapsed: 00:08:01
                               ETA: 00:11:35

################################################################################
                      [1m Learning iteration 205/500 [0m                      

                       Computation: 39724 steps/s (collection: 2.331s, learning 0.144s)
             Mean action noise std: 0.67
          Mean value_function loss: 0.0146
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 11.9322
                       Mean reward: 6.91
               Mean episode length: 940.27
Episode_Reward/track_lin_vel_xy_exp: 0.4425
Episode_Reward/track_ang_vel_z_exp: 0.3462
       Episode_Reward/lin_vel_z_l2: -0.0303
      Episode_Reward/ang_vel_xy_l2: -0.1015
     Episode_Reward/dof_torques_l2: -0.0035
         Episode_Reward/dof_acc_l2: -0.0969
     Episode_Reward/action_rate_l2: -0.1152
      Episode_Reward/feet_air_time: -0.0182
Episode_Reward/flat_orientation_l2: -0.0371
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.5628
Metrics/base_velocity/error_vel_xy: 0.9355
Metrics/base_velocity/error_vel_yaw: 0.5069
      Episode_Termination/time_out: 0.8631
  Episode_Termination/base_contact: 0.1369
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 2.47s
                      Time elapsed: 00:08:04
                               ETA: 00:11:33

################################################################################
                      [1m Learning iteration 206/500 [0m                      

                       Computation: 39693 steps/s (collection: 2.330s, learning 0.146s)
             Mean action noise std: 0.67
          Mean value_function loss: 0.0129
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 11.9441
                       Mean reward: 7.48
               Mean episode length: 908.64
Episode_Reward/track_lin_vel_xy_exp: 0.4085
Episode_Reward/track_ang_vel_z_exp: 0.3270
       Episode_Reward/lin_vel_z_l2: -0.0276
      Episode_Reward/ang_vel_xy_l2: -0.0963
     Episode_Reward/dof_torques_l2: -0.0031
         Episode_Reward/dof_acc_l2: -0.0802
     Episode_Reward/action_rate_l2: -0.1064
      Episode_Reward/feet_air_time: -0.0175
Episode_Reward/flat_orientation_l2: -0.0549
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.5701
Metrics/base_velocity/error_vel_xy: 0.9117
Metrics/base_velocity/error_vel_yaw: 0.4754
      Episode_Termination/time_out: 0.8634
  Episode_Termination/base_contact: 0.1366
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 2.48s
                      Time elapsed: 00:08:06
                               ETA: 00:11:31

################################################################################
                      [1m Learning iteration 207/500 [0m                      

                       Computation: 39670 steps/s (collection: 2.333s, learning 0.145s)
             Mean action noise std: 0.67
          Mean value_function loss: 0.0110
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 11.9386
                       Mean reward: 7.33
               Mean episode length: 933.62
Episode_Reward/track_lin_vel_xy_exp: 0.4022
Episode_Reward/track_ang_vel_z_exp: 0.3402
       Episode_Reward/lin_vel_z_l2: -0.0283
      Episode_Reward/ang_vel_xy_l2: -0.0972
     Episode_Reward/dof_torques_l2: -0.0034
         Episode_Reward/dof_acc_l2: -0.0880
     Episode_Reward/action_rate_l2: -0.1116
      Episode_Reward/feet_air_time: -0.0182
Episode_Reward/flat_orientation_l2: -0.0272
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.5732
Metrics/base_velocity/error_vel_xy: 0.9764
Metrics/base_velocity/error_vel_yaw: 0.4929
      Episode_Termination/time_out: 0.8636
  Episode_Termination/base_contact: 0.1364
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 2.48s
                      Time elapsed: 00:08:09
                               ETA: 00:11:28

################################################################################
                      [1m Learning iteration 208/500 [0m                      

                       Computation: 39589 steps/s (collection: 2.339s, learning 0.144s)
             Mean action noise std: 0.67
          Mean value_function loss: 0.0109
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 11.9447
                       Mean reward: 7.63
               Mean episode length: 927.83
Episode_Reward/track_lin_vel_xy_exp: 0.4044
Episode_Reward/track_ang_vel_z_exp: 0.3413
       Episode_Reward/lin_vel_z_l2: -0.0286
      Episode_Reward/ang_vel_xy_l2: -0.0964
     Episode_Reward/dof_torques_l2: -0.0035
         Episode_Reward/dof_acc_l2: -0.0860
     Episode_Reward/action_rate_l2: -0.1124
      Episode_Reward/feet_air_time: -0.0180
Episode_Reward/flat_orientation_l2: -0.0294
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.5772
Metrics/base_velocity/error_vel_xy: 0.9779
Metrics/base_velocity/error_vel_yaw: 0.4820
      Episode_Termination/time_out: 0.8629
  Episode_Termination/base_contact: 0.1371
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 2.48s
                      Time elapsed: 00:08:11
                               ETA: 00:11:26

################################################################################
                      [1m Learning iteration 209/500 [0m                      

                       Computation: 39670 steps/s (collection: 2.334s, learning 0.144s)
             Mean action noise std: 0.67
          Mean value_function loss: 0.0132
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 11.9527
                       Mean reward: 7.74
               Mean episode length: 940.24
Episode_Reward/track_lin_vel_xy_exp: 0.4530
Episode_Reward/track_ang_vel_z_exp: 0.3460
       Episode_Reward/lin_vel_z_l2: -0.0313
      Episode_Reward/ang_vel_xy_l2: -0.1024
     Episode_Reward/dof_torques_l2: -0.0035
         Episode_Reward/dof_acc_l2: -0.0990
     Episode_Reward/action_rate_l2: -0.1158
      Episode_Reward/feet_air_time: -0.0187
Episode_Reward/flat_orientation_l2: -0.0275
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.5826
Metrics/base_velocity/error_vel_xy: 0.9108
Metrics/base_velocity/error_vel_yaw: 0.4957
      Episode_Termination/time_out: 0.8624
  Episode_Termination/base_contact: 0.1376
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 2.48s
                      Time elapsed: 00:08:14
                               ETA: 00:11:24

################################################################################
                      [1m Learning iteration 210/500 [0m                      

                       Computation: 39986 steps/s (collection: 2.314s, learning 0.144s)
             Mean action noise std: 0.67
          Mean value_function loss: 0.0137
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 11.9632
                       Mean reward: 6.78
               Mean episode length: 900.38
Episode_Reward/track_lin_vel_xy_exp: 0.4063
Episode_Reward/track_ang_vel_z_exp: 0.3245
       Episode_Reward/lin_vel_z_l2: -0.0308
      Episode_Reward/ang_vel_xy_l2: -0.0968
     Episode_Reward/dof_torques_l2: -0.0034
         Episode_Reward/dof_acc_l2: -0.1005
     Episode_Reward/action_rate_l2: -0.1112
      Episode_Reward/feet_air_time: -0.0176
Episode_Reward/flat_orientation_l2: -0.0404
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.5873
Metrics/base_velocity/error_vel_xy: 0.9381
Metrics/base_velocity/error_vel_yaw: 0.4933
      Episode_Termination/time_out: 0.8617
  Episode_Termination/base_contact: 0.1383
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 2.46s
                      Time elapsed: 00:08:16
                               ETA: 00:11:22

################################################################################
                      [1m Learning iteration 211/500 [0m                      

                       Computation: 39721 steps/s (collection: 2.331s, learning 0.144s)
             Mean action noise std: 0.67
          Mean value_function loss: 0.0111
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 11.9571
                       Mean reward: 7.05
               Mean episode length: 944.80
Episode_Reward/track_lin_vel_xy_exp: 0.4396
Episode_Reward/track_ang_vel_z_exp: 0.3440
       Episode_Reward/lin_vel_z_l2: -0.0299
      Episode_Reward/ang_vel_xy_l2: -0.1007
     Episode_Reward/dof_torques_l2: -0.0036
         Episode_Reward/dof_acc_l2: -0.0938
     Episode_Reward/action_rate_l2: -0.1160
      Episode_Reward/feet_air_time: -0.0179
Episode_Reward/flat_orientation_l2: -0.0552
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.5955
Metrics/base_velocity/error_vel_xy: 0.9566
Metrics/base_velocity/error_vel_yaw: 0.5207
      Episode_Termination/time_out: 0.8618
  Episode_Termination/base_contact: 0.1382
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 2.47s
                      Time elapsed: 00:08:18
                               ETA: 00:11:20

################################################################################
                      [1m Learning iteration 212/500 [0m                      

                       Computation: 39968 steps/s (collection: 2.315s, learning 0.144s)
             Mean action noise std: 0.67
          Mean value_function loss: 0.0103
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 11.9470
                       Mean reward: 6.38
               Mean episode length: 953.61
Episode_Reward/track_lin_vel_xy_exp: 0.4127
Episode_Reward/track_ang_vel_z_exp: 0.3499
       Episode_Reward/lin_vel_z_l2: -0.0300
      Episode_Reward/ang_vel_xy_l2: -0.1032
     Episode_Reward/dof_torques_l2: -0.0035
         Episode_Reward/dof_acc_l2: -0.0995
     Episode_Reward/action_rate_l2: -0.1187
      Episode_Reward/feet_air_time: -0.0194
Episode_Reward/flat_orientation_l2: -0.0900
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.6028
Metrics/base_velocity/error_vel_xy: 1.0237
Metrics/base_velocity/error_vel_yaw: 0.5247
      Episode_Termination/time_out: 0.8631
  Episode_Termination/base_contact: 0.1369
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 2.46s
                      Time elapsed: 00:08:21
                               ETA: 00:11:17

################################################################################
                      [1m Learning iteration 213/500 [0m                      

                       Computation: 40307 steps/s (collection: 2.295s, learning 0.144s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0096
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 11.9285
                       Mean reward: 8.26
               Mean episode length: 902.93
Episode_Reward/track_lin_vel_xy_exp: 0.4497
Episode_Reward/track_ang_vel_z_exp: 0.3322
       Episode_Reward/lin_vel_z_l2: -0.0294
      Episode_Reward/ang_vel_xy_l2: -0.0972
     Episode_Reward/dof_torques_l2: -0.0034
         Episode_Reward/dof_acc_l2: -0.0897
     Episode_Reward/action_rate_l2: -0.1110
      Episode_Reward/feet_air_time: -0.0178
Episode_Reward/flat_orientation_l2: -0.0274
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.6086
Metrics/base_velocity/error_vel_xy: 0.8321
Metrics/base_velocity/error_vel_yaw: 0.4732
      Episode_Termination/time_out: 0.8628
  Episode_Termination/base_contact: 0.1372
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 2.44s
                      Time elapsed: 00:08:23
                               ETA: 00:11:15

################################################################################
                      [1m Learning iteration 214/500 [0m                      

                       Computation: 40416 steps/s (collection: 2.290s, learning 0.142s)
             Mean action noise std: 0.67
          Mean value_function loss: 0.0116
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 11.9250
                       Mean reward: 7.45
               Mean episode length: 931.18
Episode_Reward/track_lin_vel_xy_exp: 0.4217
Episode_Reward/track_ang_vel_z_exp: 0.3384
       Episode_Reward/lin_vel_z_l2: -0.0304
      Episode_Reward/ang_vel_xy_l2: -0.1005
     Episode_Reward/dof_torques_l2: -0.0035
         Episode_Reward/dof_acc_l2: -0.0958
     Episode_Reward/action_rate_l2: -0.1150
      Episode_Reward/feet_air_time: -0.0182
Episode_Reward/flat_orientation_l2: -0.0265
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.6128
Metrics/base_velocity/error_vel_xy: 0.9378
Metrics/base_velocity/error_vel_yaw: 0.5107
      Episode_Termination/time_out: 0.8611
  Episode_Termination/base_contact: 0.1389
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 2.43s
                      Time elapsed: 00:08:26
                               ETA: 00:11:13

################################################################################
                      [1m Learning iteration 215/500 [0m                      

                       Computation: 40091 steps/s (collection: 2.309s, learning 0.143s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0101
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 11.9285
                       Mean reward: 6.90
               Mean episode length: 924.75
Episode_Reward/track_lin_vel_xy_exp: 0.3830
Episode_Reward/track_ang_vel_z_exp: 0.3405
       Episode_Reward/lin_vel_z_l2: -0.0296
      Episode_Reward/ang_vel_xy_l2: -0.0996
     Episode_Reward/dof_torques_l2: -0.0035
         Episode_Reward/dof_acc_l2: -0.0897
     Episode_Reward/action_rate_l2: -0.1139
      Episode_Reward/feet_air_time: -0.0184
Episode_Reward/flat_orientation_l2: -0.0279
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.6165
Metrics/base_velocity/error_vel_xy: 1.0055
Metrics/base_velocity/error_vel_yaw: 0.4907
      Episode_Termination/time_out: 0.8599
  Episode_Termination/base_contact: 0.1401
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 2.45s
                      Time elapsed: 00:08:28
                               ETA: 00:11:11

################################################################################
                      [1m Learning iteration 216/500 [0m                      

                       Computation: 40159 steps/s (collection: 2.303s, learning 0.145s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0109
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 11.9153
                       Mean reward: 7.95
               Mean episode length: 977.54
Episode_Reward/track_lin_vel_xy_exp: 0.5103
Episode_Reward/track_ang_vel_z_exp: 0.3585
       Episode_Reward/lin_vel_z_l2: -0.0328
      Episode_Reward/ang_vel_xy_l2: -0.1066
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1067
     Episode_Reward/action_rate_l2: -0.1232
      Episode_Reward/feet_air_time: -0.0189
Episode_Reward/flat_orientation_l2: -0.0497
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.6205
Metrics/base_velocity/error_vel_xy: 0.8899
Metrics/base_velocity/error_vel_yaw: 0.5269
      Episode_Termination/time_out: 0.8600
  Episode_Termination/base_contact: 0.1400
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 2.45s
                      Time elapsed: 00:08:31
                               ETA: 00:11:09

################################################################################
                      [1m Learning iteration 217/500 [0m                      

                       Computation: 39955 steps/s (collection: 2.314s, learning 0.146s)
             Mean action noise std: 0.67
          Mean value_function loss: 0.0119
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 11.9165
                       Mean reward: 8.27
               Mean episode length: 959.43
Episode_Reward/track_lin_vel_xy_exp: 0.4552
Episode_Reward/track_ang_vel_z_exp: 0.3581
       Episode_Reward/lin_vel_z_l2: -0.0301
      Episode_Reward/ang_vel_xy_l2: -0.1032
     Episode_Reward/dof_torques_l2: -0.0036
         Episode_Reward/dof_acc_l2: -0.0929
     Episode_Reward/action_rate_l2: -0.1186
      Episode_Reward/feet_air_time: -0.0188
Episode_Reward/flat_orientation_l2: -0.0319
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.6278
Metrics/base_velocity/error_vel_xy: 0.9479
Metrics/base_velocity/error_vel_yaw: 0.4989
      Episode_Termination/time_out: 0.8608
  Episode_Termination/base_contact: 0.1392
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 2.46s
                      Time elapsed: 00:08:33
                               ETA: 00:11:06

################################################################################
                      [1m Learning iteration 218/500 [0m                      

                       Computation: 39771 steps/s (collection: 2.325s, learning 0.146s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0115
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 11.9183
                       Mean reward: 7.16
               Mean episode length: 889.19
Episode_Reward/track_lin_vel_xy_exp: 0.4169
Episode_Reward/track_ang_vel_z_exp: 0.3275
       Episode_Reward/lin_vel_z_l2: -0.0303
      Episode_Reward/ang_vel_xy_l2: -0.0998
     Episode_Reward/dof_torques_l2: -0.0033
         Episode_Reward/dof_acc_l2: -0.1017
     Episode_Reward/action_rate_l2: -0.1118
      Episode_Reward/feet_air_time: -0.0179
Episode_Reward/flat_orientation_l2: -0.0323
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.6315
Metrics/base_velocity/error_vel_xy: 0.9042
Metrics/base_velocity/error_vel_yaw: 0.4899
      Episode_Termination/time_out: 0.8598
  Episode_Termination/base_contact: 0.1402
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 2.47s
                      Time elapsed: 00:08:36
                               ETA: 00:11:04

################################################################################
                      [1m Learning iteration 219/500 [0m                      

                       Computation: 40127 steps/s (collection: 2.307s, learning 0.143s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0114
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 11.9013
                       Mean reward: 8.69
               Mean episode length: 954.11
Episode_Reward/track_lin_vel_xy_exp: 0.4905
Episode_Reward/track_ang_vel_z_exp: 0.3541
       Episode_Reward/lin_vel_z_l2: -0.0306
      Episode_Reward/ang_vel_xy_l2: -0.1042
     Episode_Reward/dof_torques_l2: -0.0036
         Episode_Reward/dof_acc_l2: -0.1046
     Episode_Reward/action_rate_l2: -0.1195
      Episode_Reward/feet_air_time: -0.0187
Episode_Reward/flat_orientation_l2: -0.0288
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.6395
Metrics/base_velocity/error_vel_xy: 0.8972
Metrics/base_velocity/error_vel_yaw: 0.4975
      Episode_Termination/time_out: 0.8581
  Episode_Termination/base_contact: 0.1419
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 2.45s
                      Time elapsed: 00:08:38
                               ETA: 00:11:02

################################################################################
                      [1m Learning iteration 220/500 [0m                      

                       Computation: 40075 steps/s (collection: 2.309s, learning 0.144s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0128
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 11.8926
                       Mean reward: 7.91
               Mean episode length: 943.81
Episode_Reward/track_lin_vel_xy_exp: 0.5071
Episode_Reward/track_ang_vel_z_exp: 0.3595
       Episode_Reward/lin_vel_z_l2: -0.0326
      Episode_Reward/ang_vel_xy_l2: -0.1073
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1056
     Episode_Reward/action_rate_l2: -0.1232
      Episode_Reward/feet_air_time: -0.0200
Episode_Reward/flat_orientation_l2: -0.0453
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.6469
Metrics/base_velocity/error_vel_xy: 0.8936
Metrics/base_velocity/error_vel_yaw: 0.5239
      Episode_Termination/time_out: 0.8577
  Episode_Termination/base_contact: 0.1423
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 2.45s
                      Time elapsed: 00:08:41
                               ETA: 00:11:00

################################################################################
                      [1m Learning iteration 221/500 [0m                      

                       Computation: 40095 steps/s (collection: 2.308s, learning 0.144s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0117
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 11.8953
                       Mean reward: 8.37
               Mean episode length: 953.79
Episode_Reward/track_lin_vel_xy_exp: 0.4971
Episode_Reward/track_ang_vel_z_exp: 0.3554
       Episode_Reward/lin_vel_z_l2: -0.0301
      Episode_Reward/ang_vel_xy_l2: -0.1041
     Episode_Reward/dof_torques_l2: -0.0036
         Episode_Reward/dof_acc_l2: -0.1004
     Episode_Reward/action_rate_l2: -0.1207
      Episode_Reward/feet_air_time: -0.0195
Episode_Reward/flat_orientation_l2: -0.0258
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.6530
Metrics/base_velocity/error_vel_xy: 0.8848
Metrics/base_velocity/error_vel_yaw: 0.5117
      Episode_Termination/time_out: 0.8571
  Episode_Termination/base_contact: 0.1429
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 2.45s
                      Time elapsed: 00:08:43
                               ETA: 00:10:57

################################################################################
                      [1m Learning iteration 222/500 [0m                      

                       Computation: 40095 steps/s (collection: 2.307s, learning 0.144s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0118
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 11.8955
                       Mean reward: 7.61
               Mean episode length: 954.46
Episode_Reward/track_lin_vel_xy_exp: 0.4565
Episode_Reward/track_ang_vel_z_exp: 0.3471
       Episode_Reward/lin_vel_z_l2: -0.0307
      Episode_Reward/ang_vel_xy_l2: -0.1049
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1057
     Episode_Reward/action_rate_l2: -0.1213
      Episode_Reward/feet_air_time: -0.0194
Episode_Reward/flat_orientation_l2: -0.0289
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.6592
Metrics/base_velocity/error_vel_xy: 0.9482
Metrics/base_velocity/error_vel_yaw: 0.5342
      Episode_Termination/time_out: 0.8578
  Episode_Termination/base_contact: 0.1422
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 2.45s
                      Time elapsed: 00:08:45
                               ETA: 00:10:55

################################################################################
                      [1m Learning iteration 223/500 [0m                      

                       Computation: 40145 steps/s (collection: 2.306s, learning 0.143s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0110
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 11.8903
                       Mean reward: 7.94
               Mean episode length: 960.85
Episode_Reward/track_lin_vel_xy_exp: 0.4839
Episode_Reward/track_ang_vel_z_exp: 0.3532
       Episode_Reward/lin_vel_z_l2: -0.0344
      Episode_Reward/ang_vel_xy_l2: -0.1105
     Episode_Reward/dof_torques_l2: -0.0038
         Episode_Reward/dof_acc_l2: -0.1186
     Episode_Reward/action_rate_l2: -0.1254
      Episode_Reward/feet_air_time: -0.0198
Episode_Reward/flat_orientation_l2: -0.0318
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.6687
Metrics/base_velocity/error_vel_xy: 0.9339
Metrics/base_velocity/error_vel_yaw: 0.5355
      Episode_Termination/time_out: 0.8592
  Episode_Termination/base_contact: 0.1408
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 2.45s
                      Time elapsed: 00:08:48
                               ETA: 00:10:53

################################################################################
                      [1m Learning iteration 224/500 [0m                      

                       Computation: 39985 steps/s (collection: 2.314s, learning 0.145s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0117
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 11.8931
                       Mean reward: 7.93
               Mean episode length: 946.73
Episode_Reward/track_lin_vel_xy_exp: 0.4451
Episode_Reward/track_ang_vel_z_exp: 0.3398
       Episode_Reward/lin_vel_z_l2: -0.0308
      Episode_Reward/ang_vel_xy_l2: -0.1033
     Episode_Reward/dof_torques_l2: -0.0035
         Episode_Reward/dof_acc_l2: -0.1025
     Episode_Reward/action_rate_l2: -0.1178
      Episode_Reward/feet_air_time: -0.0191
Episode_Reward/flat_orientation_l2: -0.0333
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.6784
Metrics/base_velocity/error_vel_xy: 0.9070
Metrics/base_velocity/error_vel_yaw: 0.5069
      Episode_Termination/time_out: 0.8593
  Episode_Termination/base_contact: 0.1407
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 2.46s
                      Time elapsed: 00:08:50
                               ETA: 00:10:51

################################################################################
                      [1m Learning iteration 225/500 [0m                      

                       Computation: 40220 steps/s (collection: 2.298s, learning 0.146s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0117
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 11.8936
                       Mean reward: 7.97
               Mean episode length: 927.43
Episode_Reward/track_lin_vel_xy_exp: 0.4567
Episode_Reward/track_ang_vel_z_exp: 0.3501
       Episode_Reward/lin_vel_z_l2: -0.0299
      Episode_Reward/ang_vel_xy_l2: -0.1017
     Episode_Reward/dof_torques_l2: -0.0035
         Episode_Reward/dof_acc_l2: -0.0985
     Episode_Reward/action_rate_l2: -0.1179
      Episode_Reward/feet_air_time: -0.0186
Episode_Reward/flat_orientation_l2: -0.0285
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.6867
Metrics/base_velocity/error_vel_xy: 0.8973
Metrics/base_velocity/error_vel_yaw: 0.4754
      Episode_Termination/time_out: 0.8598
  Episode_Termination/base_contact: 0.1402
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 2.44s
                      Time elapsed: 00:08:53
                               ETA: 00:10:48

################################################################################
                      [1m Learning iteration 226/500 [0m                      

                       Computation: 39706 steps/s (collection: 2.332s, learning 0.144s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0109
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 11.8809
                       Mean reward: 7.35
               Mean episode length: 934.48
Episode_Reward/track_lin_vel_xy_exp: 0.4444
Episode_Reward/track_ang_vel_z_exp: 0.3506
       Episode_Reward/lin_vel_z_l2: -0.0326
      Episode_Reward/ang_vel_xy_l2: -0.1058
     Episode_Reward/dof_torques_l2: -0.0036
         Episode_Reward/dof_acc_l2: -0.1081
     Episode_Reward/action_rate_l2: -0.1222
      Episode_Reward/feet_air_time: -0.0199
Episode_Reward/flat_orientation_l2: -0.0307
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.6926
Metrics/base_velocity/error_vel_xy: 0.9748
Metrics/base_velocity/error_vel_yaw: 0.5108
      Episode_Termination/time_out: 0.8601
  Episode_Termination/base_contact: 0.1399
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 2.48s
                      Time elapsed: 00:08:55
                               ETA: 00:10:46

################################################################################
                      [1m Learning iteration 227/500 [0m                      

                       Computation: 39573 steps/s (collection: 2.340s, learning 0.144s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0107
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 11.8609
                       Mean reward: 8.02
               Mean episode length: 935.97
Episode_Reward/track_lin_vel_xy_exp: 0.4537
Episode_Reward/track_ang_vel_z_exp: 0.3515
       Episode_Reward/lin_vel_z_l2: -0.0315
      Episode_Reward/ang_vel_xy_l2: -0.1042
     Episode_Reward/dof_torques_l2: -0.0036
         Episode_Reward/dof_acc_l2: -0.0970
     Episode_Reward/action_rate_l2: -0.1197
      Episode_Reward/feet_air_time: -0.0187
Episode_Reward/flat_orientation_l2: -0.0330
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.6975
Metrics/base_velocity/error_vel_xy: 0.9315
Metrics/base_velocity/error_vel_yaw: 0.5033
      Episode_Termination/time_out: 0.8613
  Episode_Termination/base_contact: 0.1387
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 2.48s
                      Time elapsed: 00:08:58
                               ETA: 00:10:44

################################################################################
                      [1m Learning iteration 228/500 [0m                      

                       Computation: 39743 steps/s (collection: 2.329s, learning 0.145s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0103
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 11.8381
                       Mean reward: 8.07
               Mean episode length: 942.07
Episode_Reward/track_lin_vel_xy_exp: 0.4595
Episode_Reward/track_ang_vel_z_exp: 0.3450
       Episode_Reward/lin_vel_z_l2: -0.0318
      Episode_Reward/ang_vel_xy_l2: -0.1033
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1040
     Episode_Reward/action_rate_l2: -0.1212
      Episode_Reward/feet_air_time: -0.0190
Episode_Reward/flat_orientation_l2: -0.0299
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.7039
Metrics/base_velocity/error_vel_xy: 0.9169
Metrics/base_velocity/error_vel_yaw: 0.5036
      Episode_Termination/time_out: 0.8628
  Episode_Termination/base_contact: 0.1372
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 2.47s
                      Time elapsed: 00:09:00
                               ETA: 00:10:42

################################################################################
                      [1m Learning iteration 229/500 [0m                      

                       Computation: 39660 steps/s (collection: 2.335s, learning 0.144s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0101
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 11.8390
                       Mean reward: 7.88
               Mean episode length: 934.05
Episode_Reward/track_lin_vel_xy_exp: 0.4529
Episode_Reward/track_ang_vel_z_exp: 0.3346
       Episode_Reward/lin_vel_z_l2: -0.0301
      Episode_Reward/ang_vel_xy_l2: -0.1019
     Episode_Reward/dof_torques_l2: -0.0036
         Episode_Reward/dof_acc_l2: -0.1042
     Episode_Reward/action_rate_l2: -0.1177
      Episode_Reward/feet_air_time: -0.0182
Episode_Reward/flat_orientation_l2: -0.0293
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.7107
Metrics/base_velocity/error_vel_xy: 0.8851
Metrics/base_velocity/error_vel_yaw: 0.5072
      Episode_Termination/time_out: 0.8640
  Episode_Termination/base_contact: 0.1360
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 2.48s
                      Time elapsed: 00:09:03
                               ETA: 00:10:40

################################################################################
                      [1m Learning iteration 230/500 [0m                      

                       Computation: 39582 steps/s (collection: 2.340s, learning 0.144s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0104
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 11.8232
                       Mean reward: 8.34
               Mean episode length: 964.94
Episode_Reward/track_lin_vel_xy_exp: 0.4599
Episode_Reward/track_ang_vel_z_exp: 0.3541
       Episode_Reward/lin_vel_z_l2: -0.0308
      Episode_Reward/ang_vel_xy_l2: -0.1046
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1015
     Episode_Reward/action_rate_l2: -0.1230
      Episode_Reward/feet_air_time: -0.0190
Episode_Reward/flat_orientation_l2: -0.0280
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.7187
Metrics/base_velocity/error_vel_xy: 0.9455
Metrics/base_velocity/error_vel_yaw: 0.5139
      Episode_Termination/time_out: 0.8654
  Episode_Termination/base_contact: 0.1346
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 2.48s
                      Time elapsed: 00:09:05
                               ETA: 00:10:37

################################################################################
                      [1m Learning iteration 231/500 [0m                      

                       Computation: 39767 steps/s (collection: 2.329s, learning 0.143s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0123
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 11.8186
                       Mean reward: 7.82
               Mean episode length: 941.69
Episode_Reward/track_lin_vel_xy_exp: 0.4632
Episode_Reward/track_ang_vel_z_exp: 0.3380
       Episode_Reward/lin_vel_z_l2: -0.0318
      Episode_Reward/ang_vel_xy_l2: -0.1029
     Episode_Reward/dof_torques_l2: -0.0036
         Episode_Reward/dof_acc_l2: -0.1083
     Episode_Reward/action_rate_l2: -0.1195
      Episode_Reward/feet_air_time: -0.0191
Episode_Reward/flat_orientation_l2: -0.0304
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.7253
Metrics/base_velocity/error_vel_xy: 0.8768
Metrics/base_velocity/error_vel_yaw: 0.5014
      Episode_Termination/time_out: 0.8678
  Episode_Termination/base_contact: 0.1322
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 2.47s
                      Time elapsed: 00:09:08
                               ETA: 00:10:35

################################################################################
                      [1m Learning iteration 232/500 [0m                      

                       Computation: 39533 steps/s (collection: 2.342s, learning 0.144s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0114
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 11.8349
                       Mean reward: 7.13
               Mean episode length: 929.24
Episode_Reward/track_lin_vel_xy_exp: 0.4480
Episode_Reward/track_ang_vel_z_exp: 0.3381
       Episode_Reward/lin_vel_z_l2: -0.0327
      Episode_Reward/ang_vel_xy_l2: -0.1032
     Episode_Reward/dof_torques_l2: -0.0035
         Episode_Reward/dof_acc_l2: -0.1102
     Episode_Reward/action_rate_l2: -0.1206
      Episode_Reward/feet_air_time: -0.0192
Episode_Reward/flat_orientation_l2: -0.0355
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.7344
Metrics/base_velocity/error_vel_xy: 0.9234
Metrics/base_velocity/error_vel_yaw: 0.5057
      Episode_Termination/time_out: 0.8675
  Episode_Termination/base_contact: 0.1325
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 2.49s
                      Time elapsed: 00:09:10
                               ETA: 00:10:33

################################################################################
                      [1m Learning iteration 233/500 [0m                      

                       Computation: 39908 steps/s (collection: 2.320s, learning 0.143s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0099
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 11.8453
                       Mean reward: 7.47
               Mean episode length: 956.99
Episode_Reward/track_lin_vel_xy_exp: 0.4741
Episode_Reward/track_ang_vel_z_exp: 0.3640
       Episode_Reward/lin_vel_z_l2: -0.0317
      Episode_Reward/ang_vel_xy_l2: -0.1066
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1064
     Episode_Reward/action_rate_l2: -0.1260
      Episode_Reward/feet_air_time: -0.0193
Episode_Reward/flat_orientation_l2: -0.0290
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.7406
Metrics/base_velocity/error_vel_xy: 0.9534
Metrics/base_velocity/error_vel_yaw: 0.5260
      Episode_Termination/time_out: 0.8682
  Episode_Termination/base_contact: 0.1318
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 2.46s
                      Time elapsed: 00:09:13
                               ETA: 00:10:31

################################################################################
                      [1m Learning iteration 234/500 [0m                      

                       Computation: 39909 steps/s (collection: 2.319s, learning 0.144s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0104
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 11.8372
                       Mean reward: 8.10
               Mean episode length: 964.54
Episode_Reward/track_lin_vel_xy_exp: 0.4875
Episode_Reward/track_ang_vel_z_exp: 0.3546
       Episode_Reward/lin_vel_z_l2: -0.0329
      Episode_Reward/ang_vel_xy_l2: -0.1056
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1115
     Episode_Reward/action_rate_l2: -0.1246
      Episode_Reward/feet_air_time: -0.0193
Episode_Reward/flat_orientation_l2: -0.0296
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.7476
Metrics/base_velocity/error_vel_xy: 0.8989
Metrics/base_velocity/error_vel_yaw: 0.5214
      Episode_Termination/time_out: 0.8700
  Episode_Termination/base_contact: 0.1300
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 2.46s
                      Time elapsed: 00:09:15
                               ETA: 00:10:28

################################################################################
                      [1m Learning iteration 235/500 [0m                      

                       Computation: 39925 steps/s (collection: 2.318s, learning 0.144s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0099
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 11.8224
                       Mean reward: 7.70
               Mean episode length: 964.68
Episode_Reward/track_lin_vel_xy_exp: 0.4384
Episode_Reward/track_ang_vel_z_exp: 0.3513
       Episode_Reward/lin_vel_z_l2: -0.0313
      Episode_Reward/ang_vel_xy_l2: -0.1043
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1053
     Episode_Reward/action_rate_l2: -0.1224
      Episode_Reward/feet_air_time: -0.0196
Episode_Reward/flat_orientation_l2: -0.0294
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.7562
Metrics/base_velocity/error_vel_xy: 0.9759
Metrics/base_velocity/error_vel_yaw: 0.5150
      Episode_Termination/time_out: 0.8709
  Episode_Termination/base_contact: 0.1291
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 2.46s
                      Time elapsed: 00:09:18
                               ETA: 00:10:26

################################################################################
                      [1m Learning iteration 236/500 [0m                      

                       Computation: 40099 steps/s (collection: 2.307s, learning 0.145s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0099
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 11.7874
                       Mean reward: 8.26
               Mean episode length: 981.75
Episode_Reward/track_lin_vel_xy_exp: 0.4683
Episode_Reward/track_ang_vel_z_exp: 0.3560
       Episode_Reward/lin_vel_z_l2: -0.0306
      Episode_Reward/ang_vel_xy_l2: -0.1064
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1041
     Episode_Reward/action_rate_l2: -0.1241
      Episode_Reward/feet_air_time: -0.0196
Episode_Reward/flat_orientation_l2: -0.0321
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.7605
Metrics/base_velocity/error_vel_xy: 0.9675
Metrics/base_velocity/error_vel_yaw: 0.5409
      Episode_Termination/time_out: 0.8721
  Episode_Termination/base_contact: 0.1279
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 2.45s
                      Time elapsed: 00:09:20
                               ETA: 00:10:24

################################################################################
                      [1m Learning iteration 237/500 [0m                      

                       Computation: 40140 steps/s (collection: 2.305s, learning 0.144s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0114
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 11.7657
                       Mean reward: 7.93
               Mean episode length: 949.65
Episode_Reward/track_lin_vel_xy_exp: 0.4943
Episode_Reward/track_ang_vel_z_exp: 0.3555
       Episode_Reward/lin_vel_z_l2: -0.0324
      Episode_Reward/ang_vel_xy_l2: -0.1060
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1102
     Episode_Reward/action_rate_l2: -0.1245
      Episode_Reward/feet_air_time: -0.0195
Episode_Reward/flat_orientation_l2: -0.0280
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.7641
Metrics/base_velocity/error_vel_xy: 0.9140
Metrics/base_velocity/error_vel_yaw: 0.5260
      Episode_Termination/time_out: 0.8730
  Episode_Termination/base_contact: 0.1270
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 2.45s
                      Time elapsed: 00:09:22
                               ETA: 00:10:22

################################################################################
                      [1m Learning iteration 238/500 [0m                      

                       Computation: 39930 steps/s (collection: 2.318s, learning 0.144s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0102
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 11.7539
                       Mean reward: 8.32
               Mean episode length: 933.15
Episode_Reward/track_lin_vel_xy_exp: 0.4853
Episode_Reward/track_ang_vel_z_exp: 0.3418
       Episode_Reward/lin_vel_z_l2: -0.0315
      Episode_Reward/ang_vel_xy_l2: -0.1034
     Episode_Reward/dof_torques_l2: -0.0038
         Episode_Reward/dof_acc_l2: -0.1088
     Episode_Reward/action_rate_l2: -0.1221
      Episode_Reward/feet_air_time: -0.0187
Episode_Reward/flat_orientation_l2: -0.0264
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.7726
Metrics/base_velocity/error_vel_xy: 0.8705
Metrics/base_velocity/error_vel_yaw: 0.5118
      Episode_Termination/time_out: 0.8736
  Episode_Termination/base_contact: 0.1264
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 2.46s
                      Time elapsed: 00:09:25
                               ETA: 00:10:19

################################################################################
                      [1m Learning iteration 239/500 [0m                      

                       Computation: 39891 steps/s (collection: 2.320s, learning 0.144s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0122
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 11.7400
                       Mean reward: 8.44
               Mean episode length: 943.21
Episode_Reward/track_lin_vel_xy_exp: 0.4803
Episode_Reward/track_ang_vel_z_exp: 0.3531
       Episode_Reward/lin_vel_z_l2: -0.0317
      Episode_Reward/ang_vel_xy_l2: -0.1045
     Episode_Reward/dof_torques_l2: -0.0038
         Episode_Reward/dof_acc_l2: -0.1044
     Episode_Reward/action_rate_l2: -0.1229
      Episode_Reward/feet_air_time: -0.0194
Episode_Reward/flat_orientation_l2: -0.0268
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.7807
Metrics/base_velocity/error_vel_xy: 0.9113
Metrics/base_velocity/error_vel_yaw: 0.5077
      Episode_Termination/time_out: 0.8733
  Episode_Termination/base_contact: 0.1267
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 2.46s
                      Time elapsed: 00:09:27
                               ETA: 00:10:17

################################################################################
                      [1m Learning iteration 240/500 [0m                      

                       Computation: 40010 steps/s (collection: 2.312s, learning 0.145s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0129
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 11.7478
                       Mean reward: 8.04
               Mean episode length: 950.74
Episode_Reward/track_lin_vel_xy_exp: 0.4746
Episode_Reward/track_ang_vel_z_exp: 0.3486
       Episode_Reward/lin_vel_z_l2: -0.0315
      Episode_Reward/ang_vel_xy_l2: -0.1025
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1026
     Episode_Reward/action_rate_l2: -0.1218
      Episode_Reward/feet_air_time: -0.0187
Episode_Reward/flat_orientation_l2: -0.0297
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.7908
Metrics/base_velocity/error_vel_xy: 0.9105
Metrics/base_velocity/error_vel_yaw: 0.5168
      Episode_Termination/time_out: 0.8733
  Episode_Termination/base_contact: 0.1267
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 2.46s
                      Time elapsed: 00:09:30
                               ETA: 00:10:15

################################################################################
                      [1m Learning iteration 241/500 [0m                      

                       Computation: 39770 steps/s (collection: 2.327s, learning 0.145s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0113
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 11.7382
                       Mean reward: 9.00
               Mean episode length: 978.50
Episode_Reward/track_lin_vel_xy_exp: 0.5086
Episode_Reward/track_ang_vel_z_exp: 0.3605
       Episode_Reward/lin_vel_z_l2: -0.0328
      Episode_Reward/ang_vel_xy_l2: -0.1075
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1188
     Episode_Reward/action_rate_l2: -0.1282
      Episode_Reward/feet_air_time: -0.0194
Episode_Reward/flat_orientation_l2: -0.0305
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.8024
Metrics/base_velocity/error_vel_xy: 0.9050
Metrics/base_velocity/error_vel_yaw: 0.5342
      Episode_Termination/time_out: 0.8767
  Episode_Termination/base_contact: 0.1233
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 2.47s
                      Time elapsed: 00:09:32
                               ETA: 00:10:12

################################################################################
                      [1m Learning iteration 242/500 [0m                      

                       Computation: 39352 steps/s (collection: 2.354s, learning 0.144s)
             Mean action noise std: 0.66
          Mean value_function loss: 0.0120
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 11.7385
                       Mean reward: 8.48
               Mean episode length: 975.41
Episode_Reward/track_lin_vel_xy_exp: 0.4900
Episode_Reward/track_ang_vel_z_exp: 0.3593
       Episode_Reward/lin_vel_z_l2: -0.0311
      Episode_Reward/ang_vel_xy_l2: -0.1060
     Episode_Reward/dof_torques_l2: -0.0038
         Episode_Reward/dof_acc_l2: -0.1076
     Episode_Reward/action_rate_l2: -0.1253
      Episode_Reward/feet_air_time: -0.0192
Episode_Reward/flat_orientation_l2: -0.0283
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.8129
Metrics/base_velocity/error_vel_xy: 0.9284
Metrics/base_velocity/error_vel_yaw: 0.5252
      Episode_Termination/time_out: 0.8799
  Episode_Termination/base_contact: 0.1201
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 2.50s
                      Time elapsed: 00:09:35
                               ETA: 00:10:10

################################################################################
                      [1m Learning iteration 243/500 [0m                      

                       Computation: 39431 steps/s (collection: 2.349s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0115
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 11.7317
                       Mean reward: 8.84
               Mean episode length: 969.86
Episode_Reward/track_lin_vel_xy_exp: 0.5248
Episode_Reward/track_ang_vel_z_exp: 0.3609
       Episode_Reward/lin_vel_z_l2: -0.0327
      Episode_Reward/ang_vel_xy_l2: -0.1097
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1176
     Episode_Reward/action_rate_l2: -0.1280
      Episode_Reward/feet_air_time: -0.0197
Episode_Reward/flat_orientation_l2: -0.0281
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.8240
Metrics/base_velocity/error_vel_xy: 0.8862
Metrics/base_velocity/error_vel_yaw: 0.5316
      Episode_Termination/time_out: 0.8825
  Episode_Termination/base_contact: 0.1175
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 2.49s
                      Time elapsed: 00:09:37
                               ETA: 00:10:08

################################################################################
                      [1m Learning iteration 244/500 [0m                      

                       Computation: 39060 steps/s (collection: 2.372s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0139
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 11.7168
                       Mean reward: 8.84
               Mean episode length: 929.19
Episode_Reward/track_lin_vel_xy_exp: 0.5093
Episode_Reward/track_ang_vel_z_exp: 0.3402
       Episode_Reward/lin_vel_z_l2: -0.0320
      Episode_Reward/ang_vel_xy_l2: -0.1020
     Episode_Reward/dof_torques_l2: -0.0036
         Episode_Reward/dof_acc_l2: -0.1043
     Episode_Reward/action_rate_l2: -0.1199
      Episode_Reward/feet_air_time: -0.0185
Episode_Reward/flat_orientation_l2: -0.0344
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.8340
Metrics/base_velocity/error_vel_xy: 0.8168
Metrics/base_velocity/error_vel_yaw: 0.5114
      Episode_Termination/time_out: 0.8846
  Episode_Termination/base_contact: 0.1154
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 2.52s
                      Time elapsed: 00:09:40
                               ETA: 00:10:06

################################################################################
                      [1m Learning iteration 245/500 [0m                      

                       Computation: 39224 steps/s (collection: 2.362s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0112
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 11.7309
                       Mean reward: 8.83
               Mean episode length: 945.89
Episode_Reward/track_lin_vel_xy_exp: 0.5050
Episode_Reward/track_ang_vel_z_exp: 0.3482
       Episode_Reward/lin_vel_z_l2: -0.0308
      Episode_Reward/ang_vel_xy_l2: -0.1031
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1035
     Episode_Reward/action_rate_l2: -0.1212
      Episode_Reward/feet_air_time: -0.0184
Episode_Reward/flat_orientation_l2: -0.0281
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.8418
Metrics/base_velocity/error_vel_xy: 0.8597
Metrics/base_velocity/error_vel_yaw: 0.5175
      Episode_Termination/time_out: 0.8854
  Episode_Termination/base_contact: 0.1146
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 2.51s
                      Time elapsed: 00:09:42
                               ETA: 00:10:04

################################################################################
                      [1m Learning iteration 246/500 [0m                      

                       Computation: 39165 steps/s (collection: 2.366s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0129
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 11.7298
                       Mean reward: 8.58
               Mean episode length: 929.20
Episode_Reward/track_lin_vel_xy_exp: 0.4945
Episode_Reward/track_ang_vel_z_exp: 0.3443
       Episode_Reward/lin_vel_z_l2: -0.0318
      Episode_Reward/ang_vel_xy_l2: -0.1020
     Episode_Reward/dof_torques_l2: -0.0038
         Episode_Reward/dof_acc_l2: -0.1073
     Episode_Reward/action_rate_l2: -0.1231
      Episode_Reward/feet_air_time: -0.0189
Episode_Reward/flat_orientation_l2: -0.0294
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.8469
Metrics/base_velocity/error_vel_xy: 0.8649
Metrics/base_velocity/error_vel_yaw: 0.5230
      Episode_Termination/time_out: 0.8862
  Episode_Termination/base_contact: 0.1138
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 2.51s
                      Time elapsed: 00:09:45
                               ETA: 00:10:01

################################################################################
                      [1m Learning iteration 247/500 [0m                      

                       Computation: 38991 steps/s (collection: 2.368s, learning 0.153s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0119
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 11.7255
                       Mean reward: 8.30
               Mean episode length: 956.90
Episode_Reward/track_lin_vel_xy_exp: 0.4823
Episode_Reward/track_ang_vel_z_exp: 0.3526
       Episode_Reward/lin_vel_z_l2: -0.0327
      Episode_Reward/ang_vel_xy_l2: -0.1054
     Episode_Reward/dof_torques_l2: -0.0038
         Episode_Reward/dof_acc_l2: -0.1085
     Episode_Reward/action_rate_l2: -0.1248
      Episode_Reward/feet_air_time: -0.0189
Episode_Reward/flat_orientation_l2: -0.0344
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.8549
Metrics/base_velocity/error_vel_xy: 0.9112
Metrics/base_velocity/error_vel_yaw: 0.5245
      Episode_Termination/time_out: 0.8867
  Episode_Termination/base_contact: 0.1133
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 2.52s
                      Time elapsed: 00:09:47
                               ETA: 00:09:59

################################################################################
                      [1m Learning iteration 248/500 [0m                      

                       Computation: 38754 steps/s (collection: 2.388s, learning 0.148s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0111
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 11.7078
                       Mean reward: 9.03
               Mean episode length: 964.78
Episode_Reward/track_lin_vel_xy_exp: 0.5342
Episode_Reward/track_ang_vel_z_exp: 0.3636
       Episode_Reward/lin_vel_z_l2: -0.0312
      Episode_Reward/ang_vel_xy_l2: -0.1049
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1039
     Episode_Reward/action_rate_l2: -0.1253
      Episode_Reward/feet_air_time: -0.0188
Episode_Reward/flat_orientation_l2: -0.0289
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.8614
Metrics/base_velocity/error_vel_xy: 0.8633
Metrics/base_velocity/error_vel_yaw: 0.5204
      Episode_Termination/time_out: 0.8876
  Episode_Termination/base_contact: 0.1124
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 2.54s
                      Time elapsed: 00:09:50
                               ETA: 00:09:57

################################################################################
                      [1m Learning iteration 249/500 [0m                      

                       Computation: 39101 steps/s (collection: 2.362s, learning 0.152s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0130
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 11.6982
                       Mean reward: 8.67
               Mean episode length: 969.99
Episode_Reward/track_lin_vel_xy_exp: 0.4905
Episode_Reward/track_ang_vel_z_exp: 0.3424
       Episode_Reward/lin_vel_z_l2: -0.0319
      Episode_Reward/ang_vel_xy_l2: -0.1032
     Episode_Reward/dof_torques_l2: -0.0038
         Episode_Reward/dof_acc_l2: -0.1118
     Episode_Reward/action_rate_l2: -0.1232
      Episode_Reward/feet_air_time: -0.0188
Episode_Reward/flat_orientation_l2: -0.0350
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.8685
Metrics/base_velocity/error_vel_xy: 0.8714
Metrics/base_velocity/error_vel_yaw: 0.5333
      Episode_Termination/time_out: 0.8888
  Episode_Termination/base_contact: 0.1112
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 2.51s
                      Time elapsed: 00:09:52
                               ETA: 00:09:55

################################################################################
                      [1m Learning iteration 250/500 [0m                      

                       Computation: 39062 steps/s (collection: 2.372s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0121
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 11.6856
                       Mean reward: 7.94
               Mean episode length: 903.32
Episode_Reward/track_lin_vel_xy_exp: 0.4961
Episode_Reward/track_ang_vel_z_exp: 0.3298
       Episode_Reward/lin_vel_z_l2: -0.0307
      Episode_Reward/ang_vel_xy_l2: -0.0977
     Episode_Reward/dof_torques_l2: -0.0036
         Episode_Reward/dof_acc_l2: -0.1060
     Episode_Reward/action_rate_l2: -0.1172
      Episode_Reward/feet_air_time: -0.0181
Episode_Reward/flat_orientation_l2: -0.0346
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.8734
Metrics/base_velocity/error_vel_xy: 0.7916
Metrics/base_velocity/error_vel_yaw: 0.4889
      Episode_Termination/time_out: 0.8886
  Episode_Termination/base_contact: 0.1114
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 2.52s
                      Time elapsed: 00:09:55
                               ETA: 00:09:53

################################################################################
                      [1m Learning iteration 251/500 [0m                      

                       Computation: 39259 steps/s (collection: 2.359s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0133
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 11.6748
                       Mean reward: 7.89
               Mean episode length: 919.73
Episode_Reward/track_lin_vel_xy_exp: 0.4841
Episode_Reward/track_ang_vel_z_exp: 0.3398
       Episode_Reward/lin_vel_z_l2: -0.0325
      Episode_Reward/ang_vel_xy_l2: -0.1013
     Episode_Reward/dof_torques_l2: -0.0038
         Episode_Reward/dof_acc_l2: -0.1027
     Episode_Reward/action_rate_l2: -0.1210
      Episode_Reward/feet_air_time: -0.0186
Episode_Reward/flat_orientation_l2: -0.0309
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.8780
Metrics/base_velocity/error_vel_xy: 0.8611
Metrics/base_velocity/error_vel_yaw: 0.5102
      Episode_Termination/time_out: 0.8880
  Episode_Termination/base_contact: 0.1120
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 2.50s
                      Time elapsed: 00:09:57
                               ETA: 00:09:50

################################################################################
                      [1m Learning iteration 252/500 [0m                      

                       Computation: 39289 steps/s (collection: 2.360s, learning 0.142s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0126
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 11.6669
                       Mean reward: 8.98
               Mean episode length: 970.56
Episode_Reward/track_lin_vel_xy_exp: 0.5008
Episode_Reward/track_ang_vel_z_exp: 0.3537
       Episode_Reward/lin_vel_z_l2: -0.0335
      Episode_Reward/ang_vel_xy_l2: -0.1051
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1129
     Episode_Reward/action_rate_l2: -0.1255
      Episode_Reward/feet_air_time: -0.0190
Episode_Reward/flat_orientation_l2: -0.0280
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.8840
Metrics/base_velocity/error_vel_xy: 0.8862
Metrics/base_velocity/error_vel_yaw: 0.5318
      Episode_Termination/time_out: 0.8900
  Episode_Termination/base_contact: 0.1100
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 2.50s
                      Time elapsed: 00:10:00
                               ETA: 00:09:48

################################################################################
                      [1m Learning iteration 253/500 [0m                      

                       Computation: 39145 steps/s (collection: 2.369s, learning 0.142s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0127
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 11.6596
                       Mean reward: 8.67
               Mean episode length: 944.74
Episode_Reward/track_lin_vel_xy_exp: 0.5069
Episode_Reward/track_ang_vel_z_exp: 0.3446
       Episode_Reward/lin_vel_z_l2: -0.0326
      Episode_Reward/ang_vel_xy_l2: -0.1016
     Episode_Reward/dof_torques_l2: -0.0038
         Episode_Reward/dof_acc_l2: -0.1054
     Episode_Reward/action_rate_l2: -0.1215
      Episode_Reward/feet_air_time: -0.0185
Episode_Reward/flat_orientation_l2: -0.0282
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.8903
Metrics/base_velocity/error_vel_xy: 0.8240
Metrics/base_velocity/error_vel_yaw: 0.5128
      Episode_Termination/time_out: 0.8911
  Episode_Termination/base_contact: 0.1089
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 2.51s
                      Time elapsed: 00:10:02
                               ETA: 00:09:46

################################################################################
                      [1m Learning iteration 254/500 [0m                      

                       Computation: 39392 steps/s (collection: 2.352s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0117
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 11.6650
                       Mean reward: 8.15
               Mean episode length: 950.81
Episode_Reward/track_lin_vel_xy_exp: 0.4875
Episode_Reward/track_ang_vel_z_exp: 0.3555
       Episode_Reward/lin_vel_z_l2: -0.0324
      Episode_Reward/ang_vel_xy_l2: -0.1044
     Episode_Reward/dof_torques_l2: -0.0038
         Episode_Reward/dof_acc_l2: -0.1130
     Episode_Reward/action_rate_l2: -0.1242
      Episode_Reward/feet_air_time: -0.0187
Episode_Reward/flat_orientation_l2: -0.0301
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.8950
Metrics/base_velocity/error_vel_xy: 0.9068
Metrics/base_velocity/error_vel_yaw: 0.5181
      Episode_Termination/time_out: 0.8908
  Episode_Termination/base_contact: 0.1092
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 2.50s
                      Time elapsed: 00:10:05
                               ETA: 00:09:44

################################################################################
                      [1m Learning iteration 255/500 [0m                      

                       Computation: 39087 steps/s (collection: 2.369s, learning 0.146s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0111
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 11.6637
                       Mean reward: 8.28
               Mean episode length: 925.40
Episode_Reward/track_lin_vel_xy_exp: 0.4958
Episode_Reward/track_ang_vel_z_exp: 0.3358
       Episode_Reward/lin_vel_z_l2: -0.0340
      Episode_Reward/ang_vel_xy_l2: -0.1014
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1151
     Episode_Reward/action_rate_l2: -0.1214
      Episode_Reward/feet_air_time: -0.0188
Episode_Reward/flat_orientation_l2: -0.0330
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.9046
Metrics/base_velocity/error_vel_xy: 0.8287
Metrics/base_velocity/error_vel_yaw: 0.5098
      Episode_Termination/time_out: 0.8923
  Episode_Termination/base_contact: 0.1077
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 2.51s
                      Time elapsed: 00:10:07
                               ETA: 00:09:41

################################################################################
                      [1m Learning iteration 256/500 [0m                      

                       Computation: 38887 steps/s (collection: 2.382s, learning 0.146s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0106
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 11.6627
                       Mean reward: 8.48
               Mean episode length: 928.32
Episode_Reward/track_lin_vel_xy_exp: 0.5110
Episode_Reward/track_ang_vel_z_exp: 0.3428
       Episode_Reward/lin_vel_z_l2: -0.0324
      Episode_Reward/ang_vel_xy_l2: -0.0998
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1092
     Episode_Reward/action_rate_l2: -0.1206
      Episode_Reward/feet_air_time: -0.0191
Episode_Reward/flat_orientation_l2: -0.0274
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.9124
Metrics/base_velocity/error_vel_xy: 0.8221
Metrics/base_velocity/error_vel_yaw: 0.5064
      Episode_Termination/time_out: 0.8925
  Episode_Termination/base_contact: 0.1075
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 2.53s
                      Time elapsed: 00:10:10
                               ETA: 00:09:39

################################################################################
                      [1m Learning iteration 257/500 [0m                      

                       Computation: 38988 steps/s (collection: 2.377s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0117
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 11.6631
                       Mean reward: 8.76
               Mean episode length: 924.46
Episode_Reward/track_lin_vel_xy_exp: 0.4860
Episode_Reward/track_ang_vel_z_exp: 0.3363
       Episode_Reward/lin_vel_z_l2: -0.0317
      Episode_Reward/ang_vel_xy_l2: -0.0989
     Episode_Reward/dof_torques_l2: -0.0038
         Episode_Reward/dof_acc_l2: -0.1061
     Episode_Reward/action_rate_l2: -0.1188
      Episode_Reward/feet_air_time: -0.0182
Episode_Reward/flat_orientation_l2: -0.0334
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.9182
Metrics/base_velocity/error_vel_xy: 0.8385
Metrics/base_velocity/error_vel_yaw: 0.5157
      Episode_Termination/time_out: 0.8914
  Episode_Termination/base_contact: 0.1086
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 2.52s
                      Time elapsed: 00:10:12
                               ETA: 00:09:37

################################################################################
                      [1m Learning iteration 258/500 [0m                      

                       Computation: 39202 steps/s (collection: 2.363s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0110
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 11.6574
                       Mean reward: 7.68
               Mean episode length: 959.46
Episode_Reward/track_lin_vel_xy_exp: 0.4623
Episode_Reward/track_ang_vel_z_exp: 0.3489
       Episode_Reward/lin_vel_z_l2: -0.0321
      Episode_Reward/ang_vel_xy_l2: -0.1014
     Episode_Reward/dof_torques_l2: -0.0038
         Episode_Reward/dof_acc_l2: -0.1096
     Episode_Reward/action_rate_l2: -0.1230
      Episode_Reward/feet_air_time: -0.0193
Episode_Reward/flat_orientation_l2: -0.0409
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.9238
Metrics/base_velocity/error_vel_xy: 0.9339
Metrics/base_velocity/error_vel_yaw: 0.5223
      Episode_Termination/time_out: 0.8910
  Episode_Termination/base_contact: 0.1090
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 2.51s
                      Time elapsed: 00:10:15
                               ETA: 00:09:35

################################################################################
                      [1m Learning iteration 259/500 [0m                      

                       Computation: 39097 steps/s (collection: 2.370s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0116
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 11.6525
                       Mean reward: 8.11
               Mean episode length: 929.00
Episode_Reward/track_lin_vel_xy_exp: 0.4647
Episode_Reward/track_ang_vel_z_exp: 0.3481
       Episode_Reward/lin_vel_z_l2: -0.0303
      Episode_Reward/ang_vel_xy_l2: -0.1008
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1017
     Episode_Reward/action_rate_l2: -0.1200
      Episode_Reward/feet_air_time: -0.0187
Episode_Reward/flat_orientation_l2: -0.0251
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.9286
Metrics/base_velocity/error_vel_xy: 0.8957
Metrics/base_velocity/error_vel_yaw: 0.4966
      Episode_Termination/time_out: 0.8905
  Episode_Termination/base_contact: 0.1095
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 2.51s
                      Time elapsed: 00:10:17
                               ETA: 00:09:32

################################################################################
                      [1m Learning iteration 260/500 [0m                      

                       Computation: 39463 steps/s (collection: 2.345s, learning 0.146s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0122
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 11.6392
                       Mean reward: 7.75
               Mean episode length: 958.00
Episode_Reward/track_lin_vel_xy_exp: 0.4722
Episode_Reward/track_ang_vel_z_exp: 0.3409
       Episode_Reward/lin_vel_z_l2: -0.0328
      Episode_Reward/ang_vel_xy_l2: -0.1006
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1154
     Episode_Reward/action_rate_l2: -0.1215
      Episode_Reward/feet_air_time: -0.0191
Episode_Reward/flat_orientation_l2: -0.0397
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.9350
Metrics/base_velocity/error_vel_xy: 0.8971
Metrics/base_velocity/error_vel_yaw: 0.5335
      Episode_Termination/time_out: 0.8907
  Episode_Termination/base_contact: 0.1093
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 2.49s
                      Time elapsed: 00:10:20
                               ETA: 00:09:30

################################################################################
                      [1m Learning iteration 261/500 [0m                      

                       Computation: 39702 steps/s (collection: 2.332s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0105
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 11.6419
                       Mean reward: 7.86
               Mean episode length: 957.18
Episode_Reward/track_lin_vel_xy_exp: 0.4653
Episode_Reward/track_ang_vel_z_exp: 0.3527
       Episode_Reward/lin_vel_z_l2: -0.0316
      Episode_Reward/ang_vel_xy_l2: -0.1029
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1041
     Episode_Reward/action_rate_l2: -0.1227
      Episode_Reward/feet_air_time: -0.0194
Episode_Reward/flat_orientation_l2: -0.0390
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.9411
Metrics/base_velocity/error_vel_xy: 0.9725
Metrics/base_velocity/error_vel_yaw: 0.5244
      Episode_Termination/time_out: 0.8924
  Episode_Termination/base_contact: 0.1076
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 2.48s
                      Time elapsed: 00:10:22
                               ETA: 00:09:28

################################################################################
                      [1m Learning iteration 262/500 [0m                      

                       Computation: 39359 steps/s (collection: 2.352s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0118
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 11.6382
                       Mean reward: 8.19
               Mean episode length: 917.22
Episode_Reward/track_lin_vel_xy_exp: 0.4789
Episode_Reward/track_ang_vel_z_exp: 0.3387
       Episode_Reward/lin_vel_z_l2: -0.0319
      Episode_Reward/ang_vel_xy_l2: -0.0981
     Episode_Reward/dof_torques_l2: -0.0038
         Episode_Reward/dof_acc_l2: -0.1060
     Episode_Reward/action_rate_l2: -0.1199
      Episode_Reward/feet_air_time: -0.0179
Episode_Reward/flat_orientation_l2: -0.0258
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.9435
Metrics/base_velocity/error_vel_xy: 0.8638
Metrics/base_velocity/error_vel_yaw: 0.5094
      Episode_Termination/time_out: 0.8922
  Episode_Termination/base_contact: 0.1078
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 2.50s
                      Time elapsed: 00:10:25
                               ETA: 00:09:25

################################################################################
                      [1m Learning iteration 263/500 [0m                      

                       Computation: 39344 steps/s (collection: 2.354s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0116
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 11.6246
                       Mean reward: 8.81
               Mean episode length: 937.74
Episode_Reward/track_lin_vel_xy_exp: 0.5032
Episode_Reward/track_ang_vel_z_exp: 0.3472
       Episode_Reward/lin_vel_z_l2: -0.0318
      Episode_Reward/ang_vel_xy_l2: -0.1007
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1084
     Episode_Reward/action_rate_l2: -0.1205
      Episode_Reward/feet_air_time: -0.0190
Episode_Reward/flat_orientation_l2: -0.0265
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.9503
Metrics/base_velocity/error_vel_xy: 0.8302
Metrics/base_velocity/error_vel_yaw: 0.4930
      Episode_Termination/time_out: 0.8915
  Episode_Termination/base_contact: 0.1085
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 2.50s
                      Time elapsed: 00:10:27
                               ETA: 00:09:23

################################################################################
                      [1m Learning iteration 264/500 [0m                      

                       Computation: 39392 steps/s (collection: 2.352s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0115
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 11.6157
                       Mean reward: 8.44
               Mean episode length: 924.11
Episode_Reward/track_lin_vel_xy_exp: 0.4720
Episode_Reward/track_ang_vel_z_exp: 0.3386
       Episode_Reward/lin_vel_z_l2: -0.0315
      Episode_Reward/ang_vel_xy_l2: -0.0990
     Episode_Reward/dof_torques_l2: -0.0038
         Episode_Reward/dof_acc_l2: -0.1063
     Episode_Reward/action_rate_l2: -0.1187
      Episode_Reward/feet_air_time: -0.0182
Episode_Reward/flat_orientation_l2: -0.0280
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.9534
Metrics/base_velocity/error_vel_xy: 0.8848
Metrics/base_velocity/error_vel_yaw: 0.5070
      Episode_Termination/time_out: 0.8895
  Episode_Termination/base_contact: 0.1105
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 2.50s
                      Time elapsed: 00:10:30
                               ETA: 00:09:21

################################################################################
                      [1m Learning iteration 265/500 [0m                      

                       Computation: 39334 steps/s (collection: 2.356s, learning 0.143s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0126
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 11.6065
                       Mean reward: 8.40
               Mean episode length: 930.34
Episode_Reward/track_lin_vel_xy_exp: 0.5376
Episode_Reward/track_ang_vel_z_exp: 0.3411
       Episode_Reward/lin_vel_z_l2: -0.0341
      Episode_Reward/ang_vel_xy_l2: -0.1028
     Episode_Reward/dof_torques_l2: -0.0038
         Episode_Reward/dof_acc_l2: -0.1174
     Episode_Reward/action_rate_l2: -0.1232
      Episode_Reward/feet_air_time: -0.0193
Episode_Reward/flat_orientation_l2: -0.0314
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.9598
Metrics/base_velocity/error_vel_xy: 0.7858
Metrics/base_velocity/error_vel_yaw: 0.5328
      Episode_Termination/time_out: 0.8888
  Episode_Termination/base_contact: 0.1112
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 2.50s
                      Time elapsed: 00:10:32
                               ETA: 00:09:19

################################################################################
                      [1m Learning iteration 266/500 [0m                      

                       Computation: 38869 steps/s (collection: 2.385s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0110
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 11.6034
                       Mean reward: 9.40
               Mean episode length: 952.60
Episode_Reward/track_lin_vel_xy_exp: 0.5256
Episode_Reward/track_ang_vel_z_exp: 0.3440
       Episode_Reward/lin_vel_z_l2: -0.0325
      Episode_Reward/ang_vel_xy_l2: -0.1003
     Episode_Reward/dof_torques_l2: -0.0038
         Episode_Reward/dof_acc_l2: -0.1088
     Episode_Reward/action_rate_l2: -0.1203
      Episode_Reward/feet_air_time: -0.0181
Episode_Reward/flat_orientation_l2: -0.0299
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.9679
Metrics/base_velocity/error_vel_xy: 0.7824
Metrics/base_velocity/error_vel_yaw: 0.5044
      Episode_Termination/time_out: 0.8874
  Episode_Termination/base_contact: 0.1126
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 2.53s
                      Time elapsed: 00:10:35
                               ETA: 00:09:16

################################################################################
                      [1m Learning iteration 267/500 [0m                      

                       Computation: 39053 steps/s (collection: 2.373s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0110
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 11.5808
                       Mean reward: 8.45
               Mean episode length: 939.22
Episode_Reward/track_lin_vel_xy_exp: 0.4906
Episode_Reward/track_ang_vel_z_exp: 0.3416
       Episode_Reward/lin_vel_z_l2: -0.0333
      Episode_Reward/ang_vel_xy_l2: -0.0998
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1061
     Episode_Reward/action_rate_l2: -0.1206
      Episode_Reward/feet_air_time: -0.0192
Episode_Reward/flat_orientation_l2: -0.0286
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.9780
Metrics/base_velocity/error_vel_xy: 0.8631
Metrics/base_velocity/error_vel_yaw: 0.5180
      Episode_Termination/time_out: 0.8871
  Episode_Termination/base_contact: 0.1129
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 2.52s
                      Time elapsed: 00:10:37
                               ETA: 00:09:14

################################################################################
                      [1m Learning iteration 268/500 [0m                      

                       Computation: 39075 steps/s (collection: 2.371s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0102
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 11.5758
                       Mean reward: 8.54
               Mean episode length: 933.11
Episode_Reward/track_lin_vel_xy_exp: 0.5081
Episode_Reward/track_ang_vel_z_exp: 0.3418
       Episode_Reward/lin_vel_z_l2: -0.0334
      Episode_Reward/ang_vel_xy_l2: -0.0983
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1107
     Episode_Reward/action_rate_l2: -0.1203
      Episode_Reward/feet_air_time: -0.0188
Episode_Reward/flat_orientation_l2: -0.0283
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.9849
Metrics/base_velocity/error_vel_xy: 0.8178
Metrics/base_velocity/error_vel_yaw: 0.5077
      Episode_Termination/time_out: 0.8864
  Episode_Termination/base_contact: 0.1136
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 2.52s
                      Time elapsed: 00:10:40
                               ETA: 00:09:12

################################################################################
                      [1m Learning iteration 269/500 [0m                      

                       Computation: 38933 steps/s (collection: 2.380s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0114
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 11.5699
                       Mean reward: 8.74
               Mean episode length: 937.51
Episode_Reward/track_lin_vel_xy_exp: 0.5297
Episode_Reward/track_ang_vel_z_exp: 0.3450
       Episode_Reward/lin_vel_z_l2: -0.0332
      Episode_Reward/ang_vel_xy_l2: -0.0999
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1128
     Episode_Reward/action_rate_l2: -0.1218
      Episode_Reward/feet_air_time: -0.0182
Episode_Reward/flat_orientation_l2: -0.0263
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 0.9947
Metrics/base_velocity/error_vel_xy: 0.8151
Metrics/base_velocity/error_vel_yaw: 0.5194
      Episode_Termination/time_out: 0.8862
  Episode_Termination/base_contact: 0.1138
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 2.52s
                      Time elapsed: 00:10:43
                               ETA: 00:09:10

################################################################################
                      [1m Learning iteration 270/500 [0m                      

                       Computation: 38853 steps/s (collection: 2.386s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0125
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 11.5710
                       Mean reward: 8.58
               Mean episode length: 969.41
Episode_Reward/track_lin_vel_xy_exp: 0.4743
Episode_Reward/track_ang_vel_z_exp: 0.3557
       Episode_Reward/lin_vel_z_l2: -0.0330
      Episode_Reward/ang_vel_xy_l2: -0.1015
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1109
     Episode_Reward/action_rate_l2: -0.1256
      Episode_Reward/feet_air_time: -0.0192
Episode_Reward/flat_orientation_l2: -0.0259
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.0003
Metrics/base_velocity/error_vel_xy: 0.9562
Metrics/base_velocity/error_vel_yaw: 0.5380
      Episode_Termination/time_out: 0.8867
  Episode_Termination/base_contact: 0.1133
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 2.53s
                      Time elapsed: 00:10:45
                               ETA: 00:09:07

################################################################################
                      [1m Learning iteration 271/500 [0m                      

                       Computation: 38704 steps/s (collection: 2.394s, learning 0.146s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0110
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 11.5831
                       Mean reward: 8.24
               Mean episode length: 949.76
Episode_Reward/track_lin_vel_xy_exp: 0.5519
Episode_Reward/track_ang_vel_z_exp: 0.3464
       Episode_Reward/lin_vel_z_l2: -0.0355
      Episode_Reward/ang_vel_xy_l2: -0.1042
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1220
     Episode_Reward/action_rate_l2: -0.1258
      Episode_Reward/feet_air_time: -0.0197
Episode_Reward/flat_orientation_l2: -0.0301
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.0081
Metrics/base_velocity/error_vel_xy: 0.8003
Metrics/base_velocity/error_vel_yaw: 0.5517
      Episode_Termination/time_out: 0.8882
  Episode_Termination/base_contact: 0.1118
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 2.54s
                      Time elapsed: 00:10:48
                               ETA: 00:09:05

################################################################################
                      [1m Learning iteration 272/500 [0m                      

                       Computation: 38564 steps/s (collection: 2.404s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0134
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 11.5886
                       Mean reward: 8.80
               Mean episode length: 946.35
Episode_Reward/track_lin_vel_xy_exp: 0.5034
Episode_Reward/track_ang_vel_z_exp: 0.3432
       Episode_Reward/lin_vel_z_l2: -0.0318
      Episode_Reward/ang_vel_xy_l2: -0.0992
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1076
     Episode_Reward/action_rate_l2: -0.1208
      Episode_Reward/feet_air_time: -0.0190
Episode_Reward/flat_orientation_l2: -0.0260
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.0163
Metrics/base_velocity/error_vel_xy: 0.8408
Metrics/base_velocity/error_vel_yaw: 0.5220
      Episode_Termination/time_out: 0.8874
  Episode_Termination/base_contact: 0.1126
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 2.55s
                      Time elapsed: 00:10:50
                               ETA: 00:09:03

################################################################################
                      [1m Learning iteration 273/500 [0m                      

                       Computation: 38901 steps/s (collection: 2.383s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0097
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 11.5878
                       Mean reward: 8.24
               Mean episode length: 943.69
Episode_Reward/track_lin_vel_xy_exp: 0.4921
Episode_Reward/track_ang_vel_z_exp: 0.3498
       Episode_Reward/lin_vel_z_l2: -0.0327
      Episode_Reward/ang_vel_xy_l2: -0.1005
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1184
     Episode_Reward/action_rate_l2: -0.1231
      Episode_Reward/feet_air_time: -0.0194
Episode_Reward/flat_orientation_l2: -0.0255
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.0245
Metrics/base_velocity/error_vel_xy: 0.8754
Metrics/base_velocity/error_vel_yaw: 0.5176
      Episode_Termination/time_out: 0.8866
  Episode_Termination/base_contact: 0.1134
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 2.53s
                      Time elapsed: 00:10:53
                               ETA: 00:09:01

################################################################################
                      [1m Learning iteration 274/500 [0m                      

                       Computation: 38530 steps/s (collection: 2.404s, learning 0.147s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0107
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 11.5877
                       Mean reward: 8.84
               Mean episode length: 934.78
Episode_Reward/track_lin_vel_xy_exp: 0.5086
Episode_Reward/track_ang_vel_z_exp: 0.3450
       Episode_Reward/lin_vel_z_l2: -0.0320
      Episode_Reward/ang_vel_xy_l2: -0.0997
     Episode_Reward/dof_torques_l2: -0.0038
         Episode_Reward/dof_acc_l2: -0.1241
     Episode_Reward/action_rate_l2: -0.1197
      Episode_Reward/feet_air_time: -0.0185
Episode_Reward/flat_orientation_l2: -0.0280
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.0309
Metrics/base_velocity/error_vel_xy: 0.8397
Metrics/base_velocity/error_vel_yaw: 0.5241
      Episode_Termination/time_out: 0.8873
  Episode_Termination/base_contact: 0.1127
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 2.55s
                      Time elapsed: 00:10:55
                               ETA: 00:08:58

################################################################################
                      [1m Learning iteration 275/500 [0m                      

                       Computation: 38924 steps/s (collection: 2.381s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0112
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 11.5719
                       Mean reward: 8.50
               Mean episode length: 929.28
Episode_Reward/track_lin_vel_xy_exp: 0.4895
Episode_Reward/track_ang_vel_z_exp: 0.3361
       Episode_Reward/lin_vel_z_l2: -0.0349
      Episode_Reward/ang_vel_xy_l2: -0.0981
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1115
     Episode_Reward/action_rate_l2: -0.1199
      Episode_Reward/feet_air_time: -0.0182
Episode_Reward/flat_orientation_l2: -0.0318
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.0393
Metrics/base_velocity/error_vel_xy: 0.8471
Metrics/base_velocity/error_vel_yaw: 0.5079
      Episode_Termination/time_out: 0.8860
  Episode_Termination/base_contact: 0.1140
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 2.53s
                      Time elapsed: 00:10:58
                               ETA: 00:08:56

################################################################################
                      [1m Learning iteration 276/500 [0m                      

                       Computation: 38898 steps/s (collection: 2.378s, learning 0.149s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0118
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 11.5716
                       Mean reward: 8.34
               Mean episode length: 945.51
Episode_Reward/track_lin_vel_xy_exp: 0.4756
Episode_Reward/track_ang_vel_z_exp: 0.3465
       Episode_Reward/lin_vel_z_l2: -0.0320
      Episode_Reward/ang_vel_xy_l2: -0.0995
     Episode_Reward/dof_torques_l2: -0.0038
         Episode_Reward/dof_acc_l2: -0.1006
     Episode_Reward/action_rate_l2: -0.1197
      Episode_Reward/feet_air_time: -0.0191
Episode_Reward/flat_orientation_l2: -0.0269
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.0458
Metrics/base_velocity/error_vel_xy: 0.8751
Metrics/base_velocity/error_vel_yaw: 0.5162
      Episode_Termination/time_out: 0.8852
  Episode_Termination/base_contact: 0.1148
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 2.53s
                      Time elapsed: 00:11:00
                               ETA: 00:08:54

################################################################################
                      [1m Learning iteration 277/500 [0m                      

                       Computation: 38891 steps/s (collection: 2.379s, learning 0.148s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0113
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 11.5748
                       Mean reward: 9.14
               Mean episode length: 906.04
Episode_Reward/track_lin_vel_xy_exp: 0.4883
Episode_Reward/track_ang_vel_z_exp: 0.3313
       Episode_Reward/lin_vel_z_l2: -0.0314
      Episode_Reward/ang_vel_xy_l2: -0.0946
     Episode_Reward/dof_torques_l2: -0.0036
         Episode_Reward/dof_acc_l2: -0.1031
     Episode_Reward/action_rate_l2: -0.1142
      Episode_Reward/feet_air_time: -0.0174
Episode_Reward/flat_orientation_l2: -0.0290
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.0492
Metrics/base_velocity/error_vel_xy: 0.7950
Metrics/base_velocity/error_vel_yaw: 0.4868
      Episode_Termination/time_out: 0.8840
  Episode_Termination/base_contact: 0.1160
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 2.53s
                      Time elapsed: 00:11:03
                               ETA: 00:08:52

################################################################################
                      [1m Learning iteration 278/500 [0m                      

                       Computation: 39079 steps/s (collection: 2.368s, learning 0.147s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0117
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 11.5713
                       Mean reward: 8.90
               Mean episode length: 935.67
Episode_Reward/track_lin_vel_xy_exp: 0.5111
Episode_Reward/track_ang_vel_z_exp: 0.3449
       Episode_Reward/lin_vel_z_l2: -0.0316
      Episode_Reward/ang_vel_xy_l2: -0.1008
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1056
     Episode_Reward/action_rate_l2: -0.1197
      Episode_Reward/feet_air_time: -0.0191
Episode_Reward/flat_orientation_l2: -0.0308
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.0546
Metrics/base_velocity/error_vel_xy: 0.8348
Metrics/base_velocity/error_vel_yaw: 0.5179
      Episode_Termination/time_out: 0.8826
  Episode_Termination/base_contact: 0.1174
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 2.52s
                      Time elapsed: 00:11:05
                               ETA: 00:08:49

################################################################################
                      [1m Learning iteration 279/500 [0m                      

                       Computation: 39287 steps/s (collection: 2.356s, learning 0.146s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0111
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 11.5608
                       Mean reward: 8.96
               Mean episode length: 942.28
Episode_Reward/track_lin_vel_xy_exp: 0.5493
Episode_Reward/track_ang_vel_z_exp: 0.3493
       Episode_Reward/lin_vel_z_l2: -0.0348
      Episode_Reward/ang_vel_xy_l2: -0.1004
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1239
     Episode_Reward/action_rate_l2: -0.1235
      Episode_Reward/feet_air_time: -0.0186
Episode_Reward/flat_orientation_l2: -0.0263
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.0641
Metrics/base_velocity/error_vel_xy: 0.7794
Metrics/base_velocity/error_vel_yaw: 0.5108
      Episode_Termination/time_out: 0.8811
  Episode_Termination/base_contact: 0.1189
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 2.50s
                      Time elapsed: 00:11:08
                               ETA: 00:08:47

################################################################################
                      [1m Learning iteration 280/500 [0m                      

                       Computation: 39010 steps/s (collection: 2.375s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0106
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 11.5644
                       Mean reward: 9.37
               Mean episode length: 951.52
Episode_Reward/track_lin_vel_xy_exp: 0.5112
Episode_Reward/track_ang_vel_z_exp: 0.3526
       Episode_Reward/lin_vel_z_l2: -0.0343
      Episode_Reward/ang_vel_xy_l2: -0.1024
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1128
     Episode_Reward/action_rate_l2: -0.1237
      Episode_Reward/feet_air_time: -0.0190
Episode_Reward/flat_orientation_l2: -0.0320
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.0750
Metrics/base_velocity/error_vel_xy: 0.8909
Metrics/base_velocity/error_vel_yaw: 0.5271
      Episode_Termination/time_out: 0.8795
  Episode_Termination/base_contact: 0.1205
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 2.52s
                      Time elapsed: 00:11:10
                               ETA: 00:08:45

################################################################################
                      [1m Learning iteration 281/500 [0m                      

                       Computation: 39199 steps/s (collection: 2.362s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0127
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 11.5664
                       Mean reward: 9.10
               Mean episode length: 975.93
Episode_Reward/track_lin_vel_xy_exp: 0.5191
Episode_Reward/track_ang_vel_z_exp: 0.3464
       Episode_Reward/lin_vel_z_l2: -0.0329
      Episode_Reward/ang_vel_xy_l2: -0.1011
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1135
     Episode_Reward/action_rate_l2: -0.1236
      Episode_Reward/feet_air_time: -0.0194
Episode_Reward/flat_orientation_l2: -0.0286
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.0860
Metrics/base_velocity/error_vel_xy: 0.8601
Metrics/base_velocity/error_vel_yaw: 0.5475
      Episode_Termination/time_out: 0.8804
  Episode_Termination/base_contact: 0.1196
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 2.51s
                      Time elapsed: 00:11:13
                               ETA: 00:08:42

################################################################################
                      [1m Learning iteration 282/500 [0m                      

                       Computation: 39316 steps/s (collection: 2.356s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0114
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 11.5547
                       Mean reward: 9.13
               Mean episode length: 945.49
Episode_Reward/track_lin_vel_xy_exp: 0.5203
Episode_Reward/track_ang_vel_z_exp: 0.3446
       Episode_Reward/lin_vel_z_l2: -0.0340
      Episode_Reward/ang_vel_xy_l2: -0.0990
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1160
     Episode_Reward/action_rate_l2: -0.1209
      Episode_Reward/feet_air_time: -0.0184
Episode_Reward/flat_orientation_l2: -0.0277
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.0988
Metrics/base_velocity/error_vel_xy: 0.8351
Metrics/base_velocity/error_vel_yaw: 0.5308
      Episode_Termination/time_out: 0.8809
  Episode_Termination/base_contact: 0.1191
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 2.50s
                      Time elapsed: 00:11:15
                               ETA: 00:08:40

################################################################################
                      [1m Learning iteration 283/500 [0m                      

                       Computation: 39445 steps/s (collection: 2.345s, learning 0.147s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0108
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 11.5407
                       Mean reward: 8.85
               Mean episode length: 956.38
Episode_Reward/track_lin_vel_xy_exp: 0.5107
Episode_Reward/track_ang_vel_z_exp: 0.3421
       Episode_Reward/lin_vel_z_l2: -0.0335
      Episode_Reward/ang_vel_xy_l2: -0.0986
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1140
     Episode_Reward/action_rate_l2: -0.1220
      Episode_Reward/feet_air_time: -0.0191
Episode_Reward/flat_orientation_l2: -0.0264
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.1091
Metrics/base_velocity/error_vel_xy: 0.8379
Metrics/base_velocity/error_vel_yaw: 0.5361
      Episode_Termination/time_out: 0.8796
  Episode_Termination/base_contact: 0.1204
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 2.49s
                      Time elapsed: 00:11:18
                               ETA: 00:08:38

################################################################################
                      [1m Learning iteration 284/500 [0m                      

                       Computation: 39191 steps/s (collection: 2.362s, learning 0.147s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0120
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 11.5476
                       Mean reward: 8.85
               Mean episode length: 946.94
Episode_Reward/track_lin_vel_xy_exp: 0.5314
Episode_Reward/track_ang_vel_z_exp: 0.3456
       Episode_Reward/lin_vel_z_l2: -0.0337
      Episode_Reward/ang_vel_xy_l2: -0.1006
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1200
     Episode_Reward/action_rate_l2: -0.1238
      Episode_Reward/feet_air_time: -0.0191
Episode_Reward/flat_orientation_l2: -0.0260
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.1203
Metrics/base_velocity/error_vel_xy: 0.8183
Metrics/base_velocity/error_vel_yaw: 0.5453
      Episode_Termination/time_out: 0.8789
  Episode_Termination/base_contact: 0.1211
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 2.51s
                      Time elapsed: 00:11:20
                               ETA: 00:08:36

################################################################################
                      [1m Learning iteration 285/500 [0m                      

                       Computation: 39301 steps/s (collection: 2.357s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0110
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 11.5427
                       Mean reward: 9.65
               Mean episode length: 979.27
Episode_Reward/track_lin_vel_xy_exp: 0.5640
Episode_Reward/track_ang_vel_z_exp: 0.3542
       Episode_Reward/lin_vel_z_l2: -0.0341
      Episode_Reward/ang_vel_xy_l2: -0.1013
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1159
     Episode_Reward/action_rate_l2: -0.1244
      Episode_Reward/feet_air_time: -0.0190
Episode_Reward/flat_orientation_l2: -0.0276
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.1312
Metrics/base_velocity/error_vel_xy: 0.7881
Metrics/base_velocity/error_vel_yaw: 0.5467
      Episode_Termination/time_out: 0.8787
  Episode_Termination/base_contact: 0.1213
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 2.50s
                      Time elapsed: 00:11:23
                               ETA: 00:08:33

################################################################################
                      [1m Learning iteration 286/500 [0m                      

                       Computation: 38876 steps/s (collection: 2.383s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0127
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 11.5511
                       Mean reward: 9.59
               Mean episode length: 946.52
Episode_Reward/track_lin_vel_xy_exp: 0.5558
Episode_Reward/track_ang_vel_z_exp: 0.3562
       Episode_Reward/lin_vel_z_l2: -0.0322
      Episode_Reward/ang_vel_xy_l2: -0.0995
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1139
     Episode_Reward/action_rate_l2: -0.1221
      Episode_Reward/feet_air_time: -0.0186
Episode_Reward/flat_orientation_l2: -0.0268
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.1403
Metrics/base_velocity/error_vel_xy: 0.7857
Metrics/base_velocity/error_vel_yaw: 0.5083
      Episode_Termination/time_out: 0.8794
  Episode_Termination/base_contact: 0.1206
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 2.53s
                      Time elapsed: 00:11:25
                               ETA: 00:08:31

################################################################################
                      [1m Learning iteration 287/500 [0m                      

                       Computation: 39044 steps/s (collection: 2.375s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0125
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 11.5489
                       Mean reward: 8.66
               Mean episode length: 948.13
Episode_Reward/track_lin_vel_xy_exp: 0.5013
Episode_Reward/track_ang_vel_z_exp: 0.3461
       Episode_Reward/lin_vel_z_l2: -0.0327
      Episode_Reward/ang_vel_xy_l2: -0.1005
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1122
     Episode_Reward/action_rate_l2: -0.1230
      Episode_Reward/feet_air_time: -0.0193
Episode_Reward/flat_orientation_l2: -0.0274
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.1462
Metrics/base_velocity/error_vel_xy: 0.8730
Metrics/base_velocity/error_vel_yaw: 0.5396
      Episode_Termination/time_out: 0.8798
  Episode_Termination/base_contact: 0.1202
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 2.52s
                      Time elapsed: 00:11:28
                               ETA: 00:08:29

################################################################################
                      [1m Learning iteration 288/500 [0m                      

                       Computation: 39333 steps/s (collection: 2.354s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0118
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 11.5374
                       Mean reward: 8.68
               Mean episode length: 930.94
Episode_Reward/track_lin_vel_xy_exp: 0.5498
Episode_Reward/track_ang_vel_z_exp: 0.3445
       Episode_Reward/lin_vel_z_l2: -0.0372
      Episode_Reward/ang_vel_xy_l2: -0.0993
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1188
     Episode_Reward/action_rate_l2: -0.1229
      Episode_Reward/feet_air_time: -0.0186
Episode_Reward/flat_orientation_l2: -0.0287
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.1558
Metrics/base_velocity/error_vel_xy: 0.7819
Metrics/base_velocity/error_vel_yaw: 0.5187
      Episode_Termination/time_out: 0.8802
  Episode_Termination/base_contact: 0.1198
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 2.50s
                      Time elapsed: 00:11:30
                               ETA: 00:08:26

################################################################################
                      [1m Learning iteration 289/500 [0m                      

                       Computation: 39219 steps/s (collection: 2.361s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0127
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 11.5351
                       Mean reward: 9.19
               Mean episode length: 932.42
Episode_Reward/track_lin_vel_xy_exp: 0.5434
Episode_Reward/track_ang_vel_z_exp: 0.3431
       Episode_Reward/lin_vel_z_l2: -0.0351
      Episode_Reward/ang_vel_xy_l2: -0.0985
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1196
     Episode_Reward/action_rate_l2: -0.1221
      Episode_Reward/feet_air_time: -0.0186
Episode_Reward/flat_orientation_l2: -0.0290
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.1646
Metrics/base_velocity/error_vel_xy: 0.7694
Metrics/base_velocity/error_vel_yaw: 0.5114
      Episode_Termination/time_out: 0.8795
  Episode_Termination/base_contact: 0.1205
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 2.51s
                      Time elapsed: 00:11:33
                               ETA: 00:08:24

################################################################################
                      [1m Learning iteration 290/500 [0m                      

                       Computation: 39048 steps/s (collection: 2.373s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0116
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 11.5298
                       Mean reward: 7.46
               Mean episode length: 903.85
Episode_Reward/track_lin_vel_xy_exp: 0.4931
Episode_Reward/track_ang_vel_z_exp: 0.3267
       Episode_Reward/lin_vel_z_l2: -0.0324
      Episode_Reward/ang_vel_xy_l2: -0.0967
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1069
     Episode_Reward/action_rate_l2: -0.1160
      Episode_Reward/feet_air_time: -0.0177
Episode_Reward/flat_orientation_l2: -0.0345
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.1689
Metrics/base_velocity/error_vel_xy: 0.7935
Metrics/base_velocity/error_vel_yaw: 0.5368
      Episode_Termination/time_out: 0.8782
  Episode_Termination/base_contact: 0.1218
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 2.52s
                      Time elapsed: 00:11:35
                               ETA: 00:08:22

################################################################################
                      [1m Learning iteration 291/500 [0m                      

                       Computation: 39103 steps/s (collection: 2.370s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0122
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 11.5340
                       Mean reward: 8.45
               Mean episode length: 919.37
Episode_Reward/track_lin_vel_xy_exp: 0.5259
Episode_Reward/track_ang_vel_z_exp: 0.3338
       Episode_Reward/lin_vel_z_l2: -0.0337
      Episode_Reward/ang_vel_xy_l2: -0.0974
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1094
     Episode_Reward/action_rate_l2: -0.1175
      Episode_Reward/feet_air_time: -0.0178
Episode_Reward/flat_orientation_l2: -0.0290
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.1724
Metrics/base_velocity/error_vel_xy: 0.7947
Metrics/base_velocity/error_vel_yaw: 0.5365
      Episode_Termination/time_out: 0.8771
  Episode_Termination/base_contact: 0.1229
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 2.51s
                      Time elapsed: 00:11:38
                               ETA: 00:08:19

################################################################################
                      [1m Learning iteration 292/500 [0m                      

                       Computation: 38754 steps/s (collection: 2.392s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0120
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 11.5250
                       Mean reward: 8.92
               Mean episode length: 931.65
Episode_Reward/track_lin_vel_xy_exp: 0.5130
Episode_Reward/track_ang_vel_z_exp: 0.3379
       Episode_Reward/lin_vel_z_l2: -0.0356
      Episode_Reward/ang_vel_xy_l2: -0.0976
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1178
     Episode_Reward/action_rate_l2: -0.1207
      Episode_Reward/feet_air_time: -0.0185
Episode_Reward/flat_orientation_l2: -0.0281
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.1783
Metrics/base_velocity/error_vel_xy: 0.8143
Metrics/base_velocity/error_vel_yaw: 0.5105
      Episode_Termination/time_out: 0.8770
  Episode_Termination/base_contact: 0.1230
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 2.54s
                      Time elapsed: 00:11:40
                               ETA: 00:08:17

################################################################################
                      [1m Learning iteration 293/500 [0m                      

                       Computation: 39298 steps/s (collection: 2.358s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0134
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 11.5249
                       Mean reward: 9.66
               Mean episode length: 949.59
Episode_Reward/track_lin_vel_xy_exp: 0.5520
Episode_Reward/track_ang_vel_z_exp: 0.3477
       Episode_Reward/lin_vel_z_l2: -0.0362
      Episode_Reward/ang_vel_xy_l2: -0.1001
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1202
     Episode_Reward/action_rate_l2: -0.1233
      Episode_Reward/feet_air_time: -0.0190
Episode_Reward/flat_orientation_l2: -0.0288
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.1872
Metrics/base_velocity/error_vel_xy: 0.7693
Metrics/base_velocity/error_vel_yaw: 0.5115
      Episode_Termination/time_out: 0.8764
  Episode_Termination/base_contact: 0.1236
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 2.50s
                      Time elapsed: 00:11:43
                               ETA: 00:08:15

################################################################################
                      [1m Learning iteration 294/500 [0m                      

                       Computation: 39295 steps/s (collection: 2.357s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0133
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 11.5099
                       Mean reward: 8.02
               Mean episode length: 903.96
Episode_Reward/track_lin_vel_xy_exp: 0.4557
Episode_Reward/track_ang_vel_z_exp: 0.3077
       Episode_Reward/lin_vel_z_l2: -0.0375
      Episode_Reward/ang_vel_xy_l2: -0.0950
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1108
     Episode_Reward/action_rate_l2: -0.1118
      Episode_Reward/feet_air_time: -0.0169
Episode_Reward/flat_orientation_l2: -0.0386
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.1933
Metrics/base_velocity/error_vel_xy: 0.7610
Metrics/base_velocity/error_vel_yaw: 0.4933
      Episode_Termination/time_out: 0.8757
  Episode_Termination/base_contact: 0.1243
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 2.50s
                      Time elapsed: 00:11:45
                               ETA: 00:08:12

################################################################################
                      [1m Learning iteration 295/500 [0m                      

                       Computation: 38976 steps/s (collection: 2.379s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0152
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 11.5096
                       Mean reward: 9.05
               Mean episode length: 903.15
Episode_Reward/track_lin_vel_xy_exp: 0.5035
Episode_Reward/track_ang_vel_z_exp: 0.3383
       Episode_Reward/lin_vel_z_l2: -0.0309
      Episode_Reward/ang_vel_xy_l2: -0.0960
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1065
     Episode_Reward/action_rate_l2: -0.1161
      Episode_Reward/feet_air_time: -0.0184
Episode_Reward/flat_orientation_l2: -0.0269
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.2006
Metrics/base_velocity/error_vel_xy: 0.7909
Metrics/base_velocity/error_vel_yaw: 0.4874
      Episode_Termination/time_out: 0.8741
  Episode_Termination/base_contact: 0.1259
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 2.52s
                      Time elapsed: 00:11:48
                               ETA: 00:08:10

################################################################################
                      [1m Learning iteration 296/500 [0m                      

                       Computation: 38914 steps/s (collection: 2.381s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0129
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 11.5064
                       Mean reward: 8.53
               Mean episode length: 894.60
Episode_Reward/track_lin_vel_xy_exp: 0.5091
Episode_Reward/track_ang_vel_z_exp: 0.3214
       Episode_Reward/lin_vel_z_l2: -0.0362
      Episode_Reward/ang_vel_xy_l2: -0.0968
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1171
     Episode_Reward/action_rate_l2: -0.1158
      Episode_Reward/feet_air_time: -0.0177
Episode_Reward/flat_orientation_l2: -0.0368
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.2068
Metrics/base_velocity/error_vel_xy: 0.7458
Metrics/base_velocity/error_vel_yaw: 0.5090
      Episode_Termination/time_out: 0.8724
  Episode_Termination/base_contact: 0.1276
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 2.53s
                      Time elapsed: 00:11:51
                               ETA: 00:08:08

################################################################################
                      [1m Learning iteration 297/500 [0m                      

                       Computation: 38894 steps/s (collection: 2.382s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0127
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 11.5129
                       Mean reward: 8.58
               Mean episode length: 905.02
Episode_Reward/track_lin_vel_xy_exp: 0.5178
Episode_Reward/track_ang_vel_z_exp: 0.3338
       Episode_Reward/lin_vel_z_l2: -0.0352
      Episode_Reward/ang_vel_xy_l2: -0.0974
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1170
     Episode_Reward/action_rate_l2: -0.1189
      Episode_Reward/feet_air_time: -0.0180
Episode_Reward/flat_orientation_l2: -0.0322
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.2161
Metrics/base_velocity/error_vel_xy: 0.7655
Metrics/base_velocity/error_vel_yaw: 0.5115
      Episode_Termination/time_out: 0.8714
  Episode_Termination/base_contact: 0.1286
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 2.53s
                      Time elapsed: 00:11:53
                               ETA: 00:08:06

################################################################################
                      [1m Learning iteration 298/500 [0m                      

                       Computation: 38792 steps/s (collection: 2.389s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0126
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 11.5052
                       Mean reward: 8.92
               Mean episode length: 916.67
Episode_Reward/track_lin_vel_xy_exp: 0.5164
Episode_Reward/track_ang_vel_z_exp: 0.3296
       Episode_Reward/lin_vel_z_l2: -0.0348
      Episode_Reward/ang_vel_xy_l2: -0.0951
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1175
     Episode_Reward/action_rate_l2: -0.1175
      Episode_Reward/feet_air_time: -0.0175
Episode_Reward/flat_orientation_l2: -0.0303
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.2249
Metrics/base_velocity/error_vel_xy: 0.7493
Metrics/base_velocity/error_vel_yaw: 0.5100
      Episode_Termination/time_out: 0.8711
  Episode_Termination/base_contact: 0.1289
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 2.53s
                      Time elapsed: 00:11:56
                               ETA: 00:08:03

################################################################################
                      [1m Learning iteration 299/500 [0m                      

                       Computation: 39047 steps/s (collection: 2.372s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0119
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 11.4834
                       Mean reward: 8.48
               Mean episode length: 872.49
Episode_Reward/track_lin_vel_xy_exp: 0.4570
Episode_Reward/track_ang_vel_z_exp: 0.3143
       Episode_Reward/lin_vel_z_l2: -0.0327
      Episode_Reward/ang_vel_xy_l2: -0.0921
     Episode_Reward/dof_torques_l2: -0.0036
         Episode_Reward/dof_acc_l2: -0.1040
     Episode_Reward/action_rate_l2: -0.1110
      Episode_Reward/feet_air_time: -0.0167
Episode_Reward/flat_orientation_l2: -0.0258
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.2314
Metrics/base_velocity/error_vel_xy: 0.7829
Metrics/base_velocity/error_vel_yaw: 0.4704
      Episode_Termination/time_out: 0.8704
  Episode_Termination/base_contact: 0.1296
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 2.52s
                      Time elapsed: 00:11:58
                               ETA: 00:08:01

################################################################################
                      [1m Learning iteration 300/500 [0m                      

                       Computation: 39085 steps/s (collection: 2.370s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0128
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 11.4723
                       Mean reward: 8.78
               Mean episode length: 898.35
Episode_Reward/track_lin_vel_xy_exp: 0.5286
Episode_Reward/track_ang_vel_z_exp: 0.3285
       Episode_Reward/lin_vel_z_l2: -0.0362
      Episode_Reward/ang_vel_xy_l2: -0.0952
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1232
     Episode_Reward/action_rate_l2: -0.1182
      Episode_Reward/feet_air_time: -0.0181
Episode_Reward/flat_orientation_l2: -0.0327
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.2389
Metrics/base_velocity/error_vel_xy: 0.7481
Metrics/base_velocity/error_vel_yaw: 0.5138
      Episode_Termination/time_out: 0.8686
  Episode_Termination/base_contact: 0.1314
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 2.52s
                      Time elapsed: 00:12:01
                               ETA: 00:07:59

################################################################################
                      [1m Learning iteration 301/500 [0m                      

                       Computation: 38940 steps/s (collection: 2.382s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0138
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 11.4886
                       Mean reward: 8.33
               Mean episode length: 918.75
Episode_Reward/track_lin_vel_xy_exp: 0.5388
Episode_Reward/track_ang_vel_z_exp: 0.3290
       Episode_Reward/lin_vel_z_l2: -0.0366
      Episode_Reward/ang_vel_xy_l2: -0.0985
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1271
     Episode_Reward/action_rate_l2: -0.1199
      Episode_Reward/feet_air_time: -0.0180
Episode_Reward/flat_orientation_l2: -0.0349
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.2472
Metrics/base_velocity/error_vel_xy: 0.7421
Metrics/base_velocity/error_vel_yaw: 0.5250
      Episode_Termination/time_out: 0.8675
  Episode_Termination/base_contact: 0.1325
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 2.52s
                      Time elapsed: 00:12:03
                               ETA: 00:07:56

################################################################################
                      [1m Learning iteration 302/500 [0m                      

                       Computation: 38934 steps/s (collection: 2.379s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0129
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 11.4862
                       Mean reward: 9.02
               Mean episode length: 915.06
Episode_Reward/track_lin_vel_xy_exp: 0.5456
Episode_Reward/track_ang_vel_z_exp: 0.3335
       Episode_Reward/lin_vel_z_l2: -0.0339
      Episode_Reward/ang_vel_xy_l2: -0.0970
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1184
     Episode_Reward/action_rate_l2: -0.1195
      Episode_Reward/feet_air_time: -0.0184
Episode_Reward/flat_orientation_l2: -0.0296
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.2542
Metrics/base_velocity/error_vel_xy: 0.7356
Metrics/base_velocity/error_vel_yaw: 0.5279
      Episode_Termination/time_out: 0.8660
  Episode_Termination/base_contact: 0.1340
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 2.52s
                      Time elapsed: 00:12:06
                               ETA: 00:07:54

################################################################################
                      [1m Learning iteration 303/500 [0m                      

                       Computation: 38758 steps/s (collection: 2.391s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0128
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 11.4777
                       Mean reward: 7.68
               Mean episode length: 903.96
Episode_Reward/track_lin_vel_xy_exp: 0.4991
Episode_Reward/track_ang_vel_z_exp: 0.3179
       Episode_Reward/lin_vel_z_l2: -0.0359
      Episode_Reward/ang_vel_xy_l2: -0.0952
     Episode_Reward/dof_torques_l2: -0.0038
         Episode_Reward/dof_acc_l2: -0.1176
     Episode_Reward/action_rate_l2: -0.1158
      Episode_Reward/feet_air_time: -0.0177
Episode_Reward/flat_orientation_l2: -0.0433
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.2617
Metrics/base_velocity/error_vel_xy: 0.7657
Metrics/base_velocity/error_vel_yaw: 0.5382
      Episode_Termination/time_out: 0.8633
  Episode_Termination/base_contact: 0.1367
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 2.54s
                      Time elapsed: 00:12:08
                               ETA: 00:07:52

################################################################################
                      [1m Learning iteration 304/500 [0m                      

                       Computation: 38761 steps/s (collection: 2.390s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0133
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 11.4752
                       Mean reward: 8.91
               Mean episode length: 893.15
Episode_Reward/track_lin_vel_xy_exp: 0.5418
Episode_Reward/track_ang_vel_z_exp: 0.3276
       Episode_Reward/lin_vel_z_l2: -0.0359
      Episode_Reward/ang_vel_xy_l2: -0.0952
     Episode_Reward/dof_torques_l2: -0.0038
         Episode_Reward/dof_acc_l2: -0.1190
     Episode_Reward/action_rate_l2: -0.1170
      Episode_Reward/feet_air_time: -0.0179
Episode_Reward/flat_orientation_l2: -0.0308
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.2677
Metrics/base_velocity/error_vel_xy: 0.6989
Metrics/base_velocity/error_vel_yaw: 0.5113
      Episode_Termination/time_out: 0.8616
  Episode_Termination/base_contact: 0.1384
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 2.54s
                      Time elapsed: 00:12:11
                               ETA: 00:07:49

################################################################################
                      [1m Learning iteration 305/500 [0m                      

                       Computation: 38790 steps/s (collection: 2.392s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0133
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 11.4833
                       Mean reward: 9.05
               Mean episode length: 912.70
Episode_Reward/track_lin_vel_xy_exp: 0.5717
Episode_Reward/track_ang_vel_z_exp: 0.3308
       Episode_Reward/lin_vel_z_l2: -0.0372
      Episode_Reward/ang_vel_xy_l2: -0.0985
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1301
     Episode_Reward/action_rate_l2: -0.1213
      Episode_Reward/feet_air_time: -0.0183
Episode_Reward/flat_orientation_l2: -0.0275
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.2790
Metrics/base_velocity/error_vel_xy: 0.6811
Metrics/base_velocity/error_vel_yaw: 0.5189
      Episode_Termination/time_out: 0.8611
  Episode_Termination/base_contact: 0.1389
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 2.53s
                      Time elapsed: 00:12:13
                               ETA: 00:07:47

################################################################################
                      [1m Learning iteration 306/500 [0m                      

                       Computation: 39109 steps/s (collection: 2.369s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0126
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 11.4849
                       Mean reward: 8.40
               Mean episode length: 865.79
Episode_Reward/track_lin_vel_xy_exp: 0.5368
Episode_Reward/track_ang_vel_z_exp: 0.3109
       Episode_Reward/lin_vel_z_l2: -0.0350
      Episode_Reward/ang_vel_xy_l2: -0.0918
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1170
     Episode_Reward/action_rate_l2: -0.1123
      Episode_Reward/feet_air_time: -0.0168
Episode_Reward/flat_orientation_l2: -0.0372
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.2890
Metrics/base_velocity/error_vel_xy: 0.6425
Metrics/base_velocity/error_vel_yaw: 0.4882
      Episode_Termination/time_out: 0.8615
  Episode_Termination/base_contact: 0.1385
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 2.51s
                      Time elapsed: 00:12:16
                               ETA: 00:07:45

################################################################################
                      [1m Learning iteration 307/500 [0m                      

                       Computation: 39068 steps/s (collection: 2.372s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0127
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 11.4804
                       Mean reward: 7.99
               Mean episode length: 905.05
Episode_Reward/track_lin_vel_xy_exp: 0.5218
Episode_Reward/track_ang_vel_z_exp: 0.3282
       Episode_Reward/lin_vel_z_l2: -0.0359
      Episode_Reward/ang_vel_xy_l2: -0.0965
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1239
     Episode_Reward/action_rate_l2: -0.1195
      Episode_Reward/feet_air_time: -0.0182
Episode_Reward/flat_orientation_l2: -0.0308
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.2987
Metrics/base_velocity/error_vel_xy: 0.7728
Metrics/base_velocity/error_vel_yaw: 0.5279
      Episode_Termination/time_out: 0.8606
  Episode_Termination/base_contact: 0.1394
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 2.52s
                      Time elapsed: 00:12:18
                               ETA: 00:07:42

################################################################################
                      [1m Learning iteration 308/500 [0m                      

                       Computation: 39031 steps/s (collection: 2.375s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0123
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 11.5059
                       Mean reward: 9.00
               Mean episode length: 933.33
Episode_Reward/track_lin_vel_xy_exp: 0.5344
Episode_Reward/track_ang_vel_z_exp: 0.3225
       Episode_Reward/lin_vel_z_l2: -0.0353
      Episode_Reward/ang_vel_xy_l2: -0.0941
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1223
     Episode_Reward/action_rate_l2: -0.1175
      Episode_Reward/feet_air_time: -0.0178
Episode_Reward/flat_orientation_l2: -0.0312
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.3097
Metrics/base_velocity/error_vel_xy: 0.7056
Metrics/base_velocity/error_vel_yaw: 0.5036
      Episode_Termination/time_out: 0.8611
  Episode_Termination/base_contact: 0.1389
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 2.52s
                      Time elapsed: 00:12:21
                               ETA: 00:07:40

################################################################################
                      [1m Learning iteration 309/500 [0m                      

                       Computation: 39211 steps/s (collection: 2.363s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0124
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 11.5093
                       Mean reward: 9.27
               Mean episode length: 947.33
Episode_Reward/track_lin_vel_xy_exp: 0.5791
Episode_Reward/track_ang_vel_z_exp: 0.3496
       Episode_Reward/lin_vel_z_l2: -0.0382
      Episode_Reward/ang_vel_xy_l2: -0.1007
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1288
     Episode_Reward/action_rate_l2: -0.1240
      Episode_Reward/feet_air_time: -0.0183
Episode_Reward/flat_orientation_l2: -0.0357
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.3237
Metrics/base_velocity/error_vel_xy: 0.7397
Metrics/base_velocity/error_vel_yaw: 0.5168
      Episode_Termination/time_out: 0.8607
  Episode_Termination/base_contact: 0.1393
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 2.51s
                      Time elapsed: 00:12:23
                               ETA: 00:07:38

################################################################################
                      [1m Learning iteration 310/500 [0m                      

                       Computation: 39134 steps/s (collection: 2.366s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0118
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 11.4862
                       Mean reward: 9.95
               Mean episode length: 921.94
Episode_Reward/track_lin_vel_xy_exp: 0.5988
Episode_Reward/track_ang_vel_z_exp: 0.3335
       Episode_Reward/lin_vel_z_l2: -0.0363
      Episode_Reward/ang_vel_xy_l2: -0.0969
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1284
     Episode_Reward/action_rate_l2: -0.1205
      Episode_Reward/feet_air_time: -0.0181
Episode_Reward/flat_orientation_l2: -0.0303
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.3327
Metrics/base_velocity/error_vel_xy: 0.6415
Metrics/base_velocity/error_vel_yaw: 0.5209
      Episode_Termination/time_out: 0.8599
  Episode_Termination/base_contact: 0.1401
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 2.51s
                      Time elapsed: 00:12:26
                               ETA: 00:07:35

################################################################################
                      [1m Learning iteration 311/500 [0m                      

                       Computation: 39327 steps/s (collection: 2.357s, learning 0.142s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0136
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 11.4709
                       Mean reward: 9.02
               Mean episode length: 899.61
Episode_Reward/track_lin_vel_xy_exp: 0.5715
Episode_Reward/track_ang_vel_z_exp: 0.3203
       Episode_Reward/lin_vel_z_l2: -0.0382
      Episode_Reward/ang_vel_xy_l2: -0.0960
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1311
     Episode_Reward/action_rate_l2: -0.1209
      Episode_Reward/feet_air_time: -0.0183
Episode_Reward/flat_orientation_l2: -0.0369
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.3426
Metrics/base_velocity/error_vel_xy: 0.6580
Metrics/base_velocity/error_vel_yaw: 0.5235
      Episode_Termination/time_out: 0.8569
  Episode_Termination/base_contact: 0.1431
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 2.50s
                      Time elapsed: 00:12:28
                               ETA: 00:07:33

################################################################################
                      [1m Learning iteration 312/500 [0m                      

                       Computation: 39241 steps/s (collection: 2.361s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0121
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 11.4605
                       Mean reward: 9.34
               Mean episode length: 880.97
Episode_Reward/track_lin_vel_xy_exp: 0.5793
Episode_Reward/track_ang_vel_z_exp: 0.3216
       Episode_Reward/lin_vel_z_l2: -0.0366
      Episode_Reward/ang_vel_xy_l2: -0.0934
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1258
     Episode_Reward/action_rate_l2: -0.1168
      Episode_Reward/feet_air_time: -0.0173
Episode_Reward/flat_orientation_l2: -0.0284
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.3542
Metrics/base_velocity/error_vel_xy: 0.6054
Metrics/base_velocity/error_vel_yaw: 0.4928
      Episode_Termination/time_out: 0.8553
  Episode_Termination/base_contact: 0.1447
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 2.51s
                      Time elapsed: 00:12:31
                               ETA: 00:07:31

################################################################################
                      [1m Learning iteration 313/500 [0m                      

                       Computation: 39154 steps/s (collection: 2.368s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0133
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 11.4391
                       Mean reward: 9.19
               Mean episode length: 873.64
Episode_Reward/track_lin_vel_xy_exp: 0.5581
Episode_Reward/track_ang_vel_z_exp: 0.3207
       Episode_Reward/lin_vel_z_l2: -0.0354
      Episode_Reward/ang_vel_xy_l2: -0.0933
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1219
     Episode_Reward/action_rate_l2: -0.1158
      Episode_Reward/feet_air_time: -0.0173
Episode_Reward/flat_orientation_l2: -0.0281
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.3633
Metrics/base_velocity/error_vel_xy: 0.6501
Metrics/base_velocity/error_vel_yaw: 0.4992
      Episode_Termination/time_out: 0.8525
  Episode_Termination/base_contact: 0.1475
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 2.51s
                      Time elapsed: 00:12:33
                               ETA: 00:07:28

################################################################################
                      [1m Learning iteration 314/500 [0m                      

                       Computation: 39065 steps/s (collection: 2.371s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0141
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 11.4400
                       Mean reward: 10.19
               Mean episode length: 945.14
Episode_Reward/track_lin_vel_xy_exp: 0.5930
Episode_Reward/track_ang_vel_z_exp: 0.3404
       Episode_Reward/lin_vel_z_l2: -0.0367
      Episode_Reward/ang_vel_xy_l2: -0.0980
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1273
     Episode_Reward/action_rate_l2: -0.1221
      Episode_Reward/feet_air_time: -0.0185
Episode_Reward/flat_orientation_l2: -0.0309
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.3732
Metrics/base_velocity/error_vel_xy: 0.6807
Metrics/base_velocity/error_vel_yaw: 0.5030
      Episode_Termination/time_out: 0.8517
  Episode_Termination/base_contact: 0.1483
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 2.52s
                      Time elapsed: 00:12:36
                               ETA: 00:07:26

################################################################################
                      [1m Learning iteration 315/500 [0m                      

                       Computation: 39125 steps/s (collection: 2.370s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0131
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 11.4420
                       Mean reward: 9.66
               Mean episode length: 938.02
Episode_Reward/track_lin_vel_xy_exp: 0.5792
Episode_Reward/track_ang_vel_z_exp: 0.3328
       Episode_Reward/lin_vel_z_l2: -0.0356
      Episode_Reward/ang_vel_xy_l2: -0.0960
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1232
     Episode_Reward/action_rate_l2: -0.1194
      Episode_Reward/feet_air_time: -0.0183
Episode_Reward/flat_orientation_l2: -0.0309
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.3831
Metrics/base_velocity/error_vel_xy: 0.6704
Metrics/base_velocity/error_vel_yaw: 0.5064
      Episode_Termination/time_out: 0.8524
  Episode_Termination/base_contact: 0.1476
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 2.51s
                      Time elapsed: 00:12:38
                               ETA: 00:07:24

################################################################################
                      [1m Learning iteration 316/500 [0m                      

                       Computation: 39284 steps/s (collection: 2.360s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0126
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 11.4358
                       Mean reward: 8.21
               Mean episode length: 904.52
Episode_Reward/track_lin_vel_xy_exp: 0.5214
Episode_Reward/track_ang_vel_z_exp: 0.3250
       Episode_Reward/lin_vel_z_l2: -0.0374
      Episode_Reward/ang_vel_xy_l2: -0.0948
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1258
     Episode_Reward/action_rate_l2: -0.1201
      Episode_Reward/feet_air_time: -0.0177
Episode_Reward/flat_orientation_l2: -0.0378
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.3902
Metrics/base_velocity/error_vel_xy: 0.7617
Metrics/base_velocity/error_vel_yaw: 0.5267
      Episode_Termination/time_out: 0.8517
  Episode_Termination/base_contact: 0.1483
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 2.50s
                      Time elapsed: 00:12:41
                               ETA: 00:07:21

################################################################################
                      [1m Learning iteration 317/500 [0m                      

                       Computation: 39293 steps/s (collection: 2.358s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0130
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 11.4317
                       Mean reward: 9.61
               Mean episode length: 895.51
Episode_Reward/track_lin_vel_xy_exp: 0.5856
Episode_Reward/track_ang_vel_z_exp: 0.3283
       Episode_Reward/lin_vel_z_l2: -0.0368
      Episode_Reward/ang_vel_xy_l2: -0.0935
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1264
     Episode_Reward/action_rate_l2: -0.1185
      Episode_Reward/feet_air_time: -0.0171
Episode_Reward/flat_orientation_l2: -0.0278
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.3973
Metrics/base_velocity/error_vel_xy: 0.6392
Metrics/base_velocity/error_vel_yaw: 0.4898
      Episode_Termination/time_out: 0.8506
  Episode_Termination/base_contact: 0.1494
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 2.50s
                      Time elapsed: 00:12:43
                               ETA: 00:07:19

################################################################################
                      [1m Learning iteration 318/500 [0m                      

                       Computation: 39344 steps/s (collection: 2.352s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0129
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 11.4397
                       Mean reward: 10.06
               Mean episode length: 932.30
Episode_Reward/track_lin_vel_xy_exp: 0.6153
Episode_Reward/track_ang_vel_z_exp: 0.3350
       Episode_Reward/lin_vel_z_l2: -0.0370
      Episode_Reward/ang_vel_xy_l2: -0.0972
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1337
     Episode_Reward/action_rate_l2: -0.1213
      Episode_Reward/feet_air_time: -0.0180
Episode_Reward/flat_orientation_l2: -0.0303
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.4049
Metrics/base_velocity/error_vel_xy: 0.6084
Metrics/base_velocity/error_vel_yaw: 0.5055
      Episode_Termination/time_out: 0.8506
  Episode_Termination/base_contact: 0.1494
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 2.50s
                      Time elapsed: 00:12:46
                               ETA: 00:07:17

################################################################################
                      [1m Learning iteration 319/500 [0m                      

                       Computation: 39346 steps/s (collection: 2.354s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0126
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 11.4455
                       Mean reward: 9.49
               Mean episode length: 910.48
Episode_Reward/track_lin_vel_xy_exp: 0.5723
Episode_Reward/track_ang_vel_z_exp: 0.3311
       Episode_Reward/lin_vel_z_l2: -0.0375
      Episode_Reward/ang_vel_xy_l2: -0.0973
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1386
     Episode_Reward/action_rate_l2: -0.1245
      Episode_Reward/feet_air_time: -0.0188
Episode_Reward/flat_orientation_l2: -0.0290
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.4173
Metrics/base_velocity/error_vel_xy: 0.7072
Metrics/base_velocity/error_vel_yaw: 0.5342
      Episode_Termination/time_out: 0.8514
  Episode_Termination/base_contact: 0.1486
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 2.50s
                      Time elapsed: 00:12:48
                               ETA: 00:07:14

################################################################################
                      [1m Learning iteration 320/500 [0m                      

                       Computation: 38950 steps/s (collection: 2.379s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0136
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 11.4464
                       Mean reward: 8.92
               Mean episode length: 892.30
Episode_Reward/track_lin_vel_xy_exp: 0.5563
Episode_Reward/track_ang_vel_z_exp: 0.3193
       Episode_Reward/lin_vel_z_l2: -0.0367
      Episode_Reward/ang_vel_xy_l2: -0.0931
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1324
     Episode_Reward/action_rate_l2: -0.1180
      Episode_Reward/feet_air_time: -0.0174
Episode_Reward/flat_orientation_l2: -0.0277
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.4275
Metrics/base_velocity/error_vel_xy: 0.6466
Metrics/base_velocity/error_vel_yaw: 0.4977
      Episode_Termination/time_out: 0.8510
  Episode_Termination/base_contact: 0.1490
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 2.52s
                      Time elapsed: 00:12:51
                               ETA: 00:07:12

################################################################################
                      [1m Learning iteration 321/500 [0m                      

                       Computation: 39249 steps/s (collection: 2.361s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0143
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 11.4470
                       Mean reward: 9.27
               Mean episode length: 890.95
Episode_Reward/track_lin_vel_xy_exp: 0.5628
Episode_Reward/track_ang_vel_z_exp: 0.3185
       Episode_Reward/lin_vel_z_l2: -0.0353
      Episode_Reward/ang_vel_xy_l2: -0.0909
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1260
     Episode_Reward/action_rate_l2: -0.1159
      Episode_Reward/feet_air_time: -0.0171
Episode_Reward/flat_orientation_l2: -0.0269
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.4405
Metrics/base_velocity/error_vel_xy: 0.6329
Metrics/base_velocity/error_vel_yaw: 0.4918
      Episode_Termination/time_out: 0.8504
  Episode_Termination/base_contact: 0.1496
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 2.50s
                      Time elapsed: 00:12:53
                               ETA: 00:07:10

################################################################################
                      [1m Learning iteration 322/500 [0m                      

                       Computation: 39149 steps/s (collection: 2.365s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0147
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 11.4581
                       Mean reward: 9.89
               Mean episode length: 910.26
Episode_Reward/track_lin_vel_xy_exp: 0.5754
Episode_Reward/track_ang_vel_z_exp: 0.3278
       Episode_Reward/lin_vel_z_l2: -0.0358
      Episode_Reward/ang_vel_xy_l2: -0.0940
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1245
     Episode_Reward/action_rate_l2: -0.1186
      Episode_Reward/feet_air_time: -0.0173
Episode_Reward/flat_orientation_l2: -0.0354
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.4512
Metrics/base_velocity/error_vel_xy: 0.6722
Metrics/base_velocity/error_vel_yaw: 0.5115
      Episode_Termination/time_out: 0.8487
  Episode_Termination/base_contact: 0.1513
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 2.51s
                      Time elapsed: 00:12:56
                               ETA: 00:07:07

################################################################################
                      [1m Learning iteration 323/500 [0m                      

                       Computation: 39116 steps/s (collection: 2.368s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0135
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 11.4637
                       Mean reward: 8.76
               Mean episode length: 945.40
Episode_Reward/track_lin_vel_xy_exp: 0.5626
Episode_Reward/track_ang_vel_z_exp: 0.3373
       Episode_Reward/lin_vel_z_l2: -0.0365
      Episode_Reward/ang_vel_xy_l2: -0.0979
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1271
     Episode_Reward/action_rate_l2: -0.1225
      Episode_Reward/feet_air_time: -0.0181
Episode_Reward/flat_orientation_l2: -0.0361
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.4605
Metrics/base_velocity/error_vel_xy: 0.7478
Metrics/base_velocity/error_vel_yaw: 0.5439
      Episode_Termination/time_out: 0.8461
  Episode_Termination/base_contact: 0.1539
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 2.51s
                      Time elapsed: 00:12:58
                               ETA: 00:07:05

################################################################################
                      [1m Learning iteration 324/500 [0m                      

                       Computation: 39029 steps/s (collection: 2.374s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0148
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 11.4679
                       Mean reward: 8.59
               Mean episode length: 875.07
Episode_Reward/track_lin_vel_xy_exp: 0.5389
Episode_Reward/track_ang_vel_z_exp: 0.3138
       Episode_Reward/lin_vel_z_l2: -0.0351
      Episode_Reward/ang_vel_xy_l2: -0.0921
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1233
     Episode_Reward/action_rate_l2: -0.1157
      Episode_Reward/feet_air_time: -0.0169
Episode_Reward/flat_orientation_l2: -0.0338
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.4685
Metrics/base_velocity/error_vel_xy: 0.6707
Metrics/base_velocity/error_vel_yaw: 0.4977
      Episode_Termination/time_out: 0.8463
  Episode_Termination/base_contact: 0.1537
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 2.52s
                      Time elapsed: 00:13:01
                               ETA: 00:07:03

################################################################################
                      [1m Learning iteration 325/500 [0m                      

                       Computation: 39213 steps/s (collection: 2.363s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0130
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 11.4601
                       Mean reward: 10.34
               Mean episode length: 934.76
Episode_Reward/track_lin_vel_xy_exp: 0.6156
Episode_Reward/track_ang_vel_z_exp: 0.3360
       Episode_Reward/lin_vel_z_l2: -0.0396
      Episode_Reward/ang_vel_xy_l2: -0.0994
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1395
     Episode_Reward/action_rate_l2: -0.1244
      Episode_Reward/feet_air_time: -0.0184
Episode_Reward/flat_orientation_l2: -0.0330
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.4801
Metrics/base_velocity/error_vel_xy: 0.6414
Metrics/base_velocity/error_vel_yaw: 0.5263
      Episode_Termination/time_out: 0.8450
  Episode_Termination/base_contact: 0.1550
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 2.51s
                      Time elapsed: 00:13:03
                               ETA: 00:07:00

################################################################################
                      [1m Learning iteration 326/500 [0m                      

                       Computation: 39080 steps/s (collection: 2.369s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0153
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 11.4587
                       Mean reward: 10.34
               Mean episode length: 924.63
Episode_Reward/track_lin_vel_xy_exp: 0.6166
Episode_Reward/track_ang_vel_z_exp: 0.3384
       Episode_Reward/lin_vel_z_l2: -0.0369
      Episode_Reward/ang_vel_xy_l2: -0.0953
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1330
     Episode_Reward/action_rate_l2: -0.1233
      Episode_Reward/feet_air_time: -0.0178
Episode_Reward/flat_orientation_l2: -0.0276
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.4950
Metrics/base_velocity/error_vel_xy: 0.6268
Metrics/base_velocity/error_vel_yaw: 0.5104
      Episode_Termination/time_out: 0.8446
  Episode_Termination/base_contact: 0.1554
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 2.52s
                      Time elapsed: 00:13:06
                               ETA: 00:06:58

################################################################################
                      [1m Learning iteration 327/500 [0m                      

                       Computation: 38936 steps/s (collection: 2.379s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0138
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 11.4531
                       Mean reward: 9.51
               Mean episode length: 923.60
Episode_Reward/track_lin_vel_xy_exp: 0.5844
Episode_Reward/track_ang_vel_z_exp: 0.3191
       Episode_Reward/lin_vel_z_l2: -0.0373
      Episode_Reward/ang_vel_xy_l2: -0.0935
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1292
     Episode_Reward/action_rate_l2: -0.1181
      Episode_Reward/feet_air_time: -0.0176
Episode_Reward/flat_orientation_l2: -0.0478
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.5063
Metrics/base_velocity/error_vel_xy: 0.6149
Metrics/base_velocity/error_vel_yaw: 0.5142
      Episode_Termination/time_out: 0.8425
  Episode_Termination/base_contact: 0.1575
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 2.52s
                      Time elapsed: 00:13:08
                               ETA: 00:06:56

################################################################################
                      [1m Learning iteration 328/500 [0m                      

                       Computation: 39054 steps/s (collection: 2.374s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0150
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 11.4475
                       Mean reward: 8.91
               Mean episode length: 872.80
Episode_Reward/track_lin_vel_xy_exp: 0.5979
Episode_Reward/track_ang_vel_z_exp: 0.3263
       Episode_Reward/lin_vel_z_l2: -0.0379
      Episode_Reward/ang_vel_xy_l2: -0.0944
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1348
     Episode_Reward/action_rate_l2: -0.1209
      Episode_Reward/feet_air_time: -0.0181
Episode_Reward/flat_orientation_l2: -0.0323
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.5174
Metrics/base_velocity/error_vel_xy: 0.6172
Metrics/base_velocity/error_vel_yaw: 0.5129
      Episode_Termination/time_out: 0.8421
  Episode_Termination/base_contact: 0.1579
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 2.52s
                      Time elapsed: 00:13:11
                               ETA: 00:06:53

################################################################################
                      [1m Learning iteration 329/500 [0m                      

                       Computation: 38829 steps/s (collection: 2.386s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0140
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 11.4475
                       Mean reward: 8.89
               Mean episode length: 847.90
Episode_Reward/track_lin_vel_xy_exp: 0.5096
Episode_Reward/track_ang_vel_z_exp: 0.2852
       Episode_Reward/lin_vel_z_l2: -0.0349
      Episode_Reward/ang_vel_xy_l2: -0.0838
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1194
     Episode_Reward/action_rate_l2: -0.1070
      Episode_Reward/feet_air_time: -0.0149
Episode_Reward/flat_orientation_l2: -0.0289
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.5263
Metrics/base_velocity/error_vel_xy: 0.5929
Metrics/base_velocity/error_vel_yaw: 0.4759
      Episode_Termination/time_out: 0.8397
  Episode_Termination/base_contact: 0.1603
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 2.53s
                      Time elapsed: 00:13:14
                               ETA: 00:06:51

################################################################################
                      [1m Learning iteration 330/500 [0m                      

                       Computation: 39260 steps/s (collection: 2.360s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0148
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 11.4748
                       Mean reward: 9.16
               Mean episode length: 871.57
Episode_Reward/track_lin_vel_xy_exp: 0.5143
Episode_Reward/track_ang_vel_z_exp: 0.2981
       Episode_Reward/lin_vel_z_l2: -0.0354
      Episode_Reward/ang_vel_xy_l2: -0.0865
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1244
     Episode_Reward/action_rate_l2: -0.1107
      Episode_Reward/feet_air_time: -0.0162
Episode_Reward/flat_orientation_l2: -0.0355
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.5355
Metrics/base_velocity/error_vel_xy: 0.6495
Metrics/base_velocity/error_vel_yaw: 0.4742
      Episode_Termination/time_out: 0.8377
  Episode_Termination/base_contact: 0.1623
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 2.50s
                      Time elapsed: 00:13:16
                               ETA: 00:06:49

################################################################################
                      [1m Learning iteration 331/500 [0m                      

                       Computation: 38938 steps/s (collection: 2.379s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0137
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 11.4813
                       Mean reward: 8.86
               Mean episode length: 851.93
Episode_Reward/track_lin_vel_xy_exp: 0.5452
Episode_Reward/track_ang_vel_z_exp: 0.2983
       Episode_Reward/lin_vel_z_l2: -0.0359
      Episode_Reward/ang_vel_xy_l2: -0.0880
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1199
     Episode_Reward/action_rate_l2: -0.1097
      Episode_Reward/feet_air_time: -0.0162
Episode_Reward/flat_orientation_l2: -0.0338
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.5430
Metrics/base_velocity/error_vel_xy: 0.5761
Metrics/base_velocity/error_vel_yaw: 0.4735
      Episode_Termination/time_out: 0.8377
  Episode_Termination/base_contact: 0.1623
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 2.52s
                      Time elapsed: 00:13:19
                               ETA: 00:06:46

################################################################################
                      [1m Learning iteration 332/500 [0m                      

                       Computation: 38915 steps/s (collection: 2.380s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0139
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 11.4715
                       Mean reward: 9.09
               Mean episode length: 875.78
Episode_Reward/track_lin_vel_xy_exp: 0.5746
Episode_Reward/track_ang_vel_z_exp: 0.3123
       Episode_Reward/lin_vel_z_l2: -0.0380
      Episode_Reward/ang_vel_xy_l2: -0.0925
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1292
     Episode_Reward/action_rate_l2: -0.1162
      Episode_Reward/feet_air_time: -0.0168
Episode_Reward/flat_orientation_l2: -0.0344
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.5491
Metrics/base_velocity/error_vel_xy: 0.5923
Metrics/base_velocity/error_vel_yaw: 0.5011
      Episode_Termination/time_out: 0.8361
  Episode_Termination/base_contact: 0.1639
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 2.53s
                      Time elapsed: 00:13:21
                               ETA: 00:06:44

################################################################################
                      [1m Learning iteration 333/500 [0m                      

                       Computation: 38977 steps/s (collection: 2.378s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0149
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 11.4706
                       Mean reward: 9.35
               Mean episode length: 854.09
Episode_Reward/track_lin_vel_xy_exp: 0.5861
Episode_Reward/track_ang_vel_z_exp: 0.3089
       Episode_Reward/lin_vel_z_l2: -0.0368
      Episode_Reward/ang_vel_xy_l2: -0.0905
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1283
     Episode_Reward/action_rate_l2: -0.1153
      Episode_Reward/feet_air_time: -0.0160
Episode_Reward/flat_orientation_l2: -0.0344
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.5577
Metrics/base_velocity/error_vel_xy: 0.5765
Metrics/base_velocity/error_vel_yaw: 0.5097
      Episode_Termination/time_out: 0.8348
  Episode_Termination/base_contact: 0.1652
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 2.52s
                      Time elapsed: 00:13:24
                               ETA: 00:06:42

################################################################################
                      [1m Learning iteration 334/500 [0m                      

                       Computation: 38524 steps/s (collection: 2.407s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0145
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 11.4841
                       Mean reward: 8.68
               Mean episode length: 896.20
Episode_Reward/track_lin_vel_xy_exp: 0.5851
Episode_Reward/track_ang_vel_z_exp: 0.3228
       Episode_Reward/lin_vel_z_l2: -0.0361
      Episode_Reward/ang_vel_xy_l2: -0.0934
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1282
     Episode_Reward/action_rate_l2: -0.1199
      Episode_Reward/feet_air_time: -0.0172
Episode_Reward/flat_orientation_l2: -0.0423
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.5642
Metrics/base_velocity/error_vel_xy: 0.6535
Metrics/base_velocity/error_vel_yaw: 0.5371
      Episode_Termination/time_out: 0.8332
  Episode_Termination/base_contact: 0.1668
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 2.55s
                      Time elapsed: 00:13:26
                               ETA: 00:06:39

################################################################################
                      [1m Learning iteration 335/500 [0m                      

                       Computation: 38496 steps/s (collection: 2.402s, learning 0.152s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0146
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 11.4908
                       Mean reward: 8.87
               Mean episode length: 857.09
Episode_Reward/track_lin_vel_xy_exp: 0.5734
Episode_Reward/track_ang_vel_z_exp: 0.3113
       Episode_Reward/lin_vel_z_l2: -0.0351
      Episode_Reward/ang_vel_xy_l2: -0.0878
     Episode_Reward/dof_torques_l2: -0.0038
         Episode_Reward/dof_acc_l2: -0.1250
     Episode_Reward/action_rate_l2: -0.1136
      Episode_Reward/feet_air_time: -0.0163
Episode_Reward/flat_orientation_l2: -0.0359
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.5750
Metrics/base_velocity/error_vel_xy: 0.5846
Metrics/base_velocity/error_vel_yaw: 0.4748
      Episode_Termination/time_out: 0.8319
  Episode_Termination/base_contact: 0.1681
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 2.55s
                      Time elapsed: 00:13:29
                               ETA: 00:06:37

################################################################################
                      [1m Learning iteration 336/500 [0m                      

                       Computation: 38824 steps/s (collection: 2.387s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0123
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 11.4881
                       Mean reward: 10.06
               Mean episode length: 917.70
Episode_Reward/track_lin_vel_xy_exp: 0.5930
Episode_Reward/track_ang_vel_z_exp: 0.3246
       Episode_Reward/lin_vel_z_l2: -0.0366
      Episode_Reward/ang_vel_xy_l2: -0.0936
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1311
     Episode_Reward/action_rate_l2: -0.1190
      Episode_Reward/feet_air_time: -0.0175
Episode_Reward/flat_orientation_l2: -0.0303
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.5817
Metrics/base_velocity/error_vel_xy: 0.6124
Metrics/base_velocity/error_vel_yaw: 0.5087
      Episode_Termination/time_out: 0.8298
  Episode_Termination/base_contact: 0.1702
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 2.53s
                      Time elapsed: 00:13:31
                               ETA: 00:06:35

################################################################################
                      [1m Learning iteration 337/500 [0m                      

                       Computation: 38820 steps/s (collection: 2.389s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0133
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 11.4835
                       Mean reward: 9.88
               Mean episode length: 905.81
Episode_Reward/track_lin_vel_xy_exp: 0.6159
Episode_Reward/track_ang_vel_z_exp: 0.3271
       Episode_Reward/lin_vel_z_l2: -0.0382
      Episode_Reward/ang_vel_xy_l2: -0.0956
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1410
     Episode_Reward/action_rate_l2: -0.1217
      Episode_Reward/feet_air_time: -0.0179
Episode_Reward/flat_orientation_l2: -0.0337
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.5929
Metrics/base_velocity/error_vel_xy: 0.6163
Metrics/base_velocity/error_vel_yaw: 0.5176
      Episode_Termination/time_out: 0.8301
  Episode_Termination/base_contact: 0.1699
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 2.53s
                      Time elapsed: 00:13:34
                               ETA: 00:06:32

################################################################################
                      [1m Learning iteration 338/500 [0m                      

                       Computation: 38808 steps/s (collection: 2.390s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0134
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 11.4794
                       Mean reward: 9.52
               Mean episode length: 877.21
Episode_Reward/track_lin_vel_xy_exp: 0.5842
Episode_Reward/track_ang_vel_z_exp: 0.3137
       Episode_Reward/lin_vel_z_l2: -0.0364
      Episode_Reward/ang_vel_xy_l2: -0.0909
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1315
     Episode_Reward/action_rate_l2: -0.1169
      Episode_Reward/feet_air_time: -0.0169
Episode_Reward/flat_orientation_l2: -0.0334
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.6035
Metrics/base_velocity/error_vel_xy: 0.5863
Metrics/base_velocity/error_vel_yaw: 0.5011
      Episode_Termination/time_out: 0.8298
  Episode_Termination/base_contact: 0.1702
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 2.53s
                      Time elapsed: 00:13:36
                               ETA: 00:06:30

################################################################################
                      [1m Learning iteration 339/500 [0m                      

                       Computation: 38859 steps/s (collection: 2.384s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0138
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 11.4694
                       Mean reward: 9.95
               Mean episode length: 877.75
Episode_Reward/track_lin_vel_xy_exp: 0.6185
Episode_Reward/track_ang_vel_z_exp: 0.3143
       Episode_Reward/lin_vel_z_l2: -0.0368
      Episode_Reward/ang_vel_xy_l2: -0.0912
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1300
     Episode_Reward/action_rate_l2: -0.1160
      Episode_Reward/feet_air_time: -0.0168
Episode_Reward/flat_orientation_l2: -0.0373
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.6126
Metrics/base_velocity/error_vel_xy: 0.5334
Metrics/base_velocity/error_vel_yaw: 0.4997
      Episode_Termination/time_out: 0.8287
  Episode_Termination/base_contact: 0.1714
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 2.53s
                      Time elapsed: 00:13:39
                               ETA: 00:06:27

################################################################################
                      [1m Learning iteration 340/500 [0m                      

                       Computation: 38590 steps/s (collection: 2.404s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0136
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 11.4615
                       Mean reward: 9.68
               Mean episode length: 843.71
Episode_Reward/track_lin_vel_xy_exp: 0.5970
Episode_Reward/track_ang_vel_z_exp: 0.3093
       Episode_Reward/lin_vel_z_l2: -0.0365
      Episode_Reward/ang_vel_xy_l2: -0.0878
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1225
     Episode_Reward/action_rate_l2: -0.1151
      Episode_Reward/feet_air_time: -0.0168
Episode_Reward/flat_orientation_l2: -0.0284
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.6243
Metrics/base_velocity/error_vel_xy: 0.5415
Metrics/base_velocity/error_vel_yaw: 0.4826
      Episode_Termination/time_out: 0.8262
  Episode_Termination/base_contact: 0.1740
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 2.55s
                      Time elapsed: 00:13:41
                               ETA: 00:06:25

################################################################################
                      [1m Learning iteration 341/500 [0m                      

                       Computation: 38747 steps/s (collection: 2.393s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0136
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 11.4703
                       Mean reward: 9.44
               Mean episode length: 881.68
Episode_Reward/track_lin_vel_xy_exp: 0.5742
Episode_Reward/track_ang_vel_z_exp: 0.3116
       Episode_Reward/lin_vel_z_l2: -0.0360
      Episode_Reward/ang_vel_xy_l2: -0.0903
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1433
     Episode_Reward/action_rate_l2: -0.1162
      Episode_Reward/feet_air_time: -0.0166
Episode_Reward/flat_orientation_l2: -0.0358
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.6315
Metrics/base_velocity/error_vel_xy: 0.6088
Metrics/base_velocity/error_vel_yaw: 0.5145
      Episode_Termination/time_out: 0.8246
  Episode_Termination/base_contact: 0.1756
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 2.54s
                      Time elapsed: 00:13:44
                               ETA: 00:06:23

################################################################################
                      [1m Learning iteration 342/500 [0m                      

                       Computation: 38889 steps/s (collection: 2.385s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0144
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 11.4881
                       Mean reward: 9.03
               Mean episode length: 888.13
Episode_Reward/track_lin_vel_xy_exp: 0.5969
Episode_Reward/track_ang_vel_z_exp: 0.3218
       Episode_Reward/lin_vel_z_l2: -0.0372
      Episode_Reward/ang_vel_xy_l2: -0.0968
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1662
     Episode_Reward/action_rate_l2: -0.1234
      Episode_Reward/feet_air_time: -0.0174
Episode_Reward/flat_orientation_l2: -0.0466
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.6416
Metrics/base_velocity/error_vel_xy: 0.6583
Metrics/base_velocity/error_vel_yaw: 0.5646
      Episode_Termination/time_out: 0.8257
  Episode_Termination/base_contact: 0.1746
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 2.53s
                      Time elapsed: 00:13:46
                               ETA: 00:06:20

################################################################################
                      [1m Learning iteration 343/500 [0m                      

                       Computation: 39009 steps/s (collection: 2.376s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0136
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 11.4910
                       Mean reward: 10.80
               Mean episode length: 913.47
Episode_Reward/track_lin_vel_xy_exp: 0.6558
Episode_Reward/track_ang_vel_z_exp: 0.3365
       Episode_Reward/lin_vel_z_l2: -0.0356
      Episode_Reward/ang_vel_xy_l2: -0.0945
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1279
     Episode_Reward/action_rate_l2: -0.1220
      Episode_Reward/feet_air_time: -0.0171
Episode_Reward/flat_orientation_l2: -0.0335
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.6501
Metrics/base_velocity/error_vel_xy: 0.5772
Metrics/base_velocity/error_vel_yaw: 0.5215
      Episode_Termination/time_out: 0.8253
  Episode_Termination/base_contact: 0.1749
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 2.52s
                      Time elapsed: 00:13:49
                               ETA: 00:06:18

################################################################################
                      [1m Learning iteration 344/500 [0m                      

                       Computation: 39203 steps/s (collection: 2.362s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0140
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 11.4893
                       Mean reward: 10.42
               Mean episode length: 892.11
Episode_Reward/track_lin_vel_xy_exp: 0.6314
Episode_Reward/track_ang_vel_z_exp: 0.3204
       Episode_Reward/lin_vel_z_l2: -0.0348
      Episode_Reward/ang_vel_xy_l2: -0.0907
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1440
     Episode_Reward/action_rate_l2: -0.1190
      Episode_Reward/feet_air_time: -0.0173
Episode_Reward/flat_orientation_l2: -0.0257
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.6618
Metrics/base_velocity/error_vel_xy: 0.5287
Metrics/base_velocity/error_vel_yaw: 0.4963
      Episode_Termination/time_out: 0.8264
  Episode_Termination/base_contact: 0.1739
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 2.51s
                      Time elapsed: 00:13:51
                               ETA: 00:06:16

################################################################################
                      [1m Learning iteration 345/500 [0m                      

                       Computation: 39050 steps/s (collection: 2.375s, learning 0.142s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0133
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 11.4725
                       Mean reward: 10.28
               Mean episode length: 888.27
Episode_Reward/track_lin_vel_xy_exp: 0.6115
Episode_Reward/track_ang_vel_z_exp: 0.3094
       Episode_Reward/lin_vel_z_l2: -0.0351
      Episode_Reward/ang_vel_xy_l2: -0.0873
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1290
     Episode_Reward/action_rate_l2: -0.1151
      Episode_Reward/feet_air_time: -0.0169
Episode_Reward/flat_orientation_l2: -0.0358
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.6705
Metrics/base_velocity/error_vel_xy: 0.5176
Metrics/base_velocity/error_vel_yaw: 0.4827
      Episode_Termination/time_out: 0.8261
  Episode_Termination/base_contact: 0.1742
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 2.52s
                      Time elapsed: 00:13:54
                               ETA: 00:06:13

################################################################################
                      [1m Learning iteration 346/500 [0m                      

                       Computation: 38966 steps/s (collection: 2.379s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0144
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 11.4618
                       Mean reward: 9.14
               Mean episode length: 870.53
Episode_Reward/track_lin_vel_xy_exp: 0.5644
Episode_Reward/track_ang_vel_z_exp: 0.3116
       Episode_Reward/lin_vel_z_l2: -0.0396
      Episode_Reward/ang_vel_xy_l2: -0.0933
     Episode_Reward/dof_torques_l2: -0.0038
         Episode_Reward/dof_acc_l2: -0.1368
     Episode_Reward/action_rate_l2: -0.1179
      Episode_Reward/feet_air_time: -0.0171
Episode_Reward/flat_orientation_l2: -0.0430
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.6783
Metrics/base_velocity/error_vel_xy: 0.6224
Metrics/base_velocity/error_vel_yaw: 0.5004
      Episode_Termination/time_out: 0.8262
  Episode_Termination/base_contact: 0.1740
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 2.52s
                      Time elapsed: 00:13:57
                               ETA: 00:06:11

################################################################################
                      [1m Learning iteration 347/500 [0m                      

                       Computation: 39169 steps/s (collection: 2.365s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0132
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 11.4541
                       Mean reward: 10.75
               Mean episode length: 913.40
Episode_Reward/track_lin_vel_xy_exp: 0.6527
Episode_Reward/track_ang_vel_z_exp: 0.3292
       Episode_Reward/lin_vel_z_l2: -0.0365
      Episode_Reward/ang_vel_xy_l2: -0.0931
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1374
     Episode_Reward/action_rate_l2: -0.1233
      Episode_Reward/feet_air_time: -0.0177
Episode_Reward/flat_orientation_l2: -0.0326
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.6905
Metrics/base_velocity/error_vel_xy: 0.5565
Metrics/base_velocity/error_vel_yaw: 0.5230
      Episode_Termination/time_out: 0.8273
  Episode_Termination/base_contact: 0.1729
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 2.51s
                      Time elapsed: 00:13:59
                               ETA: 00:06:09

################################################################################
                      [1m Learning iteration 348/500 [0m                      

                       Computation: 39001 steps/s (collection: 2.377s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0133
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 11.4418
                       Mean reward: 10.30
               Mean episode length: 895.21
Episode_Reward/track_lin_vel_xy_exp: 0.5763
Episode_Reward/track_ang_vel_z_exp: 0.3026
       Episode_Reward/lin_vel_z_l2: -0.0352
      Episode_Reward/ang_vel_xy_l2: -0.0862
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1244
     Episode_Reward/action_rate_l2: -0.1142
      Episode_Reward/feet_air_time: -0.0160
Episode_Reward/flat_orientation_l2: -0.0284
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.6993
Metrics/base_velocity/error_vel_xy: 0.5618
Metrics/base_velocity/error_vel_yaw: 0.4954
      Episode_Termination/time_out: 0.8271
  Episode_Termination/base_contact: 0.1731
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 2.52s
                      Time elapsed: 00:14:02
                               ETA: 00:06:06

################################################################################
                      [1m Learning iteration 349/500 [0m                      

                       Computation: 39501 steps/s (collection: 2.344s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0142
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 11.4376
                       Mean reward: 10.62
               Mean episode length: 922.87
Episode_Reward/track_lin_vel_xy_exp: 0.6255
Episode_Reward/track_ang_vel_z_exp: 0.3291
       Episode_Reward/lin_vel_z_l2: -0.0365
      Episode_Reward/ang_vel_xy_l2: -0.0934
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1328
     Episode_Reward/action_rate_l2: -0.1230
      Episode_Reward/feet_air_time: -0.0176
Episode_Reward/flat_orientation_l2: -0.0349
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.7137
Metrics/base_velocity/error_vel_xy: 0.6273
Metrics/base_velocity/error_vel_yaw: 0.5461
      Episode_Termination/time_out: 0.8277
  Episode_Termination/base_contact: 0.1726
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 2.49s
                      Time elapsed: 00:14:04
                               ETA: 00:06:04

################################################################################
                      [1m Learning iteration 350/500 [0m                      

                       Computation: 39546 steps/s (collection: 2.341s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0143
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 11.4537
                       Mean reward: 10.18
               Mean episode length: 922.07
Episode_Reward/track_lin_vel_xy_exp: 0.6171
Episode_Reward/track_ang_vel_z_exp: 0.3291
       Episode_Reward/lin_vel_z_l2: -0.0378
      Episode_Reward/ang_vel_xy_l2: -0.0935
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1338
     Episode_Reward/action_rate_l2: -0.1228
      Episode_Reward/feet_air_time: -0.0176
Episode_Reward/flat_orientation_l2: -0.0381
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.7258
Metrics/base_velocity/error_vel_xy: 0.6136
Metrics/base_velocity/error_vel_yaw: 0.5111
      Episode_Termination/time_out: 0.8286
  Episode_Termination/base_contact: 0.1716
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 2.49s
                      Time elapsed: 00:14:07
                               ETA: 00:06:01

################################################################################
                      [1m Learning iteration 351/500 [0m                      

                       Computation: 39427 steps/s (collection: 2.349s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0135
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 11.4540
                       Mean reward: 10.60
               Mean episode length: 924.62
Episode_Reward/track_lin_vel_xy_exp: 0.6631
Episode_Reward/track_ang_vel_z_exp: 0.3381
       Episode_Reward/lin_vel_z_l2: -0.0353
      Episode_Reward/ang_vel_xy_l2: -0.0945
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1334
     Episode_Reward/action_rate_l2: -0.1241
      Episode_Reward/feet_air_time: -0.0179
Episode_Reward/flat_orientation_l2: -0.0384
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.7365
Metrics/base_velocity/error_vel_xy: 0.5839
Metrics/base_velocity/error_vel_yaw: 0.5167
      Episode_Termination/time_out: 0.8284
  Episode_Termination/base_contact: 0.1718
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 2.49s
                      Time elapsed: 00:14:09
                               ETA: 00:05:59

################################################################################
                      [1m Learning iteration 352/500 [0m                      

                       Computation: 39041 steps/s (collection: 2.372s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0134
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 11.4664
                       Mean reward: 10.82
               Mean episode length: 952.19
Episode_Reward/track_lin_vel_xy_exp: 0.6463
Episode_Reward/track_ang_vel_z_exp: 0.3331
       Episode_Reward/lin_vel_z_l2: -0.0375
      Episode_Reward/ang_vel_xy_l2: -0.0952
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1400
     Episode_Reward/action_rate_l2: -0.1258
      Episode_Reward/feet_air_time: -0.0179
Episode_Reward/flat_orientation_l2: -0.0307
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.7467
Metrics/base_velocity/error_vel_xy: 0.6034
Metrics/base_velocity/error_vel_yaw: 0.5312
      Episode_Termination/time_out: 0.8300
  Episode_Termination/base_contact: 0.1702
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 2.52s
                      Time elapsed: 00:14:12
                               ETA: 00:05:57

################################################################################
                      [1m Learning iteration 353/500 [0m                      

                       Computation: 39369 steps/s (collection: 2.352s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0134
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 11.4801
                       Mean reward: 10.33
               Mean episode length: 902.39
Episode_Reward/track_lin_vel_xy_exp: 0.6321
Episode_Reward/track_ang_vel_z_exp: 0.3256
       Episode_Reward/lin_vel_z_l2: -0.0372
      Episode_Reward/ang_vel_xy_l2: -0.0925
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1377
     Episode_Reward/action_rate_l2: -0.1223
      Episode_Reward/feet_air_time: -0.0173
Episode_Reward/flat_orientation_l2: -0.0352
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.7596
Metrics/base_velocity/error_vel_xy: 0.5976
Metrics/base_velocity/error_vel_yaw: 0.5216
      Episode_Termination/time_out: 0.8326
  Episode_Termination/base_contact: 0.1677
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 2.50s
                      Time elapsed: 00:14:14
                               ETA: 00:05:54

################################################################################
                      [1m Learning iteration 354/500 [0m                      

                       Computation: 39272 steps/s (collection: 2.359s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0135
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 11.4781
                       Mean reward: 10.24
               Mean episode length: 916.97
Episode_Reward/track_lin_vel_xy_exp: 0.6194
Episode_Reward/track_ang_vel_z_exp: 0.3207
       Episode_Reward/lin_vel_z_l2: -0.0374
      Episode_Reward/ang_vel_xy_l2: -0.0935
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1404
     Episode_Reward/action_rate_l2: -0.1235
      Episode_Reward/feet_air_time: -0.0178
Episode_Reward/flat_orientation_l2: -0.0360
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.7710
Metrics/base_velocity/error_vel_xy: 0.5844
Metrics/base_velocity/error_vel_yaw: 0.5364
      Episode_Termination/time_out: 0.8344
  Episode_Termination/base_contact: 0.1659
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 2.50s
                      Time elapsed: 00:14:17
                               ETA: 00:05:52

################################################################################
                      [1m Learning iteration 355/500 [0m                      

                       Computation: 39389 steps/s (collection: 2.352s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0151
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 11.4748
                       Mean reward: 10.39
               Mean episode length: 902.68
Episode_Reward/track_lin_vel_xy_exp: 0.6272
Episode_Reward/track_ang_vel_z_exp: 0.3208
       Episode_Reward/lin_vel_z_l2: -0.0373
      Episode_Reward/ang_vel_xy_l2: -0.0932
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1338
     Episode_Reward/action_rate_l2: -0.1214
      Episode_Reward/feet_air_time: -0.0172
Episode_Reward/flat_orientation_l2: -0.0388
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.7814
Metrics/base_velocity/error_vel_xy: 0.5604
Metrics/base_velocity/error_vel_yaw: 0.5189
      Episode_Termination/time_out: 0.8354
  Episode_Termination/base_contact: 0.1649
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 2.50s
                      Time elapsed: 00:14:19
                               ETA: 00:05:50

################################################################################
                      [1m Learning iteration 356/500 [0m                      

                       Computation: 39363 steps/s (collection: 2.353s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0122
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 11.4831
                       Mean reward: 10.43
               Mean episode length: 922.64
Episode_Reward/track_lin_vel_xy_exp: 0.6553
Episode_Reward/track_ang_vel_z_exp: 0.3365
       Episode_Reward/lin_vel_z_l2: -0.0385
      Episode_Reward/ang_vel_xy_l2: -0.0968
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1420
     Episode_Reward/action_rate_l2: -0.1270
      Episode_Reward/feet_air_time: -0.0185
Episode_Reward/flat_orientation_l2: -0.0331
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.7939
Metrics/base_velocity/error_vel_xy: 0.6000
Metrics/base_velocity/error_vel_yaw: 0.5433
      Episode_Termination/time_out: 0.8356
  Episode_Termination/base_contact: 0.1647
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 2.50s
                      Time elapsed: 00:14:22
                               ETA: 00:05:47

################################################################################
                      [1m Learning iteration 357/500 [0m                      

                       Computation: 39126 steps/s (collection: 2.368s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0137
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 11.4757
                       Mean reward: 10.49
               Mean episode length: 930.44
Episode_Reward/track_lin_vel_xy_exp: 0.6389
Episode_Reward/track_ang_vel_z_exp: 0.3255
       Episode_Reward/lin_vel_z_l2: -0.0384
      Episode_Reward/ang_vel_xy_l2: -0.0925
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1422
     Episode_Reward/action_rate_l2: -0.1228
      Episode_Reward/feet_air_time: -0.0183
Episode_Reward/flat_orientation_l2: -0.0355
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.8075
Metrics/base_velocity/error_vel_xy: 0.5554
Metrics/base_velocity/error_vel_yaw: 0.5119
      Episode_Termination/time_out: 0.8350
  Episode_Termination/base_contact: 0.1653
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 2.51s
                      Time elapsed: 00:14:24
                               ETA: 00:05:45

################################################################################
                      [1m Learning iteration 358/500 [0m                      

                       Computation: 39162 steps/s (collection: 2.365s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0139
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 11.4809
                       Mean reward: 9.96
               Mean episode length: 882.89
Episode_Reward/track_lin_vel_xy_exp: 0.6342
Episode_Reward/track_ang_vel_z_exp: 0.3234
       Episode_Reward/lin_vel_z_l2: -0.0363
      Episode_Reward/ang_vel_xy_l2: -0.0905
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1309
     Episode_Reward/action_rate_l2: -0.1221
      Episode_Reward/feet_air_time: -0.0172
Episode_Reward/flat_orientation_l2: -0.0297
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.8208
Metrics/base_velocity/error_vel_xy: 0.5493
Metrics/base_velocity/error_vel_yaw: 0.5141
      Episode_Termination/time_out: 0.8360
  Episode_Termination/base_contact: 0.1642
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 2.51s
                      Time elapsed: 00:14:27
                               ETA: 00:05:42

################################################################################
                      [1m Learning iteration 359/500 [0m                      

                       Computation: 39495 steps/s (collection: 2.344s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0124
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 11.4728
                       Mean reward: 9.46
               Mean episode length: 917.84
Episode_Reward/track_lin_vel_xy_exp: 0.6493
Episode_Reward/track_ang_vel_z_exp: 0.3336
       Episode_Reward/lin_vel_z_l2: -0.0373
      Episode_Reward/ang_vel_xy_l2: -0.0947
     Episode_Reward/dof_torques_l2: -0.0045
         Episode_Reward/dof_acc_l2: -0.1436
     Episode_Reward/action_rate_l2: -0.1284
      Episode_Reward/feet_air_time: -0.0181
Episode_Reward/flat_orientation_l2: -0.0434
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.8334
Metrics/base_velocity/error_vel_xy: 0.5958
Metrics/base_velocity/error_vel_yaw: 0.5517
      Episode_Termination/time_out: 0.8359
  Episode_Termination/base_contact: 0.1643
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 2.49s
                      Time elapsed: 00:14:29
                               ETA: 00:05:40

################################################################################
                      [1m Learning iteration 360/500 [0m                      

                       Computation: 39697 steps/s (collection: 2.333s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0138
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 11.4715
                       Mean reward: 10.45
               Mean episode length: 936.24
Episode_Reward/track_lin_vel_xy_exp: 0.6343
Episode_Reward/track_ang_vel_z_exp: 0.3260
       Episode_Reward/lin_vel_z_l2: -0.0367
      Episode_Reward/ang_vel_xy_l2: -0.0936
     Episode_Reward/dof_torques_l2: -0.0043
         Episode_Reward/dof_acc_l2: -0.1402
     Episode_Reward/action_rate_l2: -0.1251
      Episode_Reward/feet_air_time: -0.0177
Episode_Reward/flat_orientation_l2: -0.0351
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.8452
Metrics/base_velocity/error_vel_xy: 0.5828
Metrics/base_velocity/error_vel_yaw: 0.5311
      Episode_Termination/time_out: 0.8353
  Episode_Termination/base_contact: 0.1649
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 2.48s
                      Time elapsed: 00:14:32
                               ETA: 00:05:38

################################################################################
                      [1m Learning iteration 361/500 [0m                      

                       Computation: 39417 steps/s (collection: 2.351s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0124
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 11.4660
                       Mean reward: 9.95
               Mean episode length: 904.34
Episode_Reward/track_lin_vel_xy_exp: 0.6277
Episode_Reward/track_ang_vel_z_exp: 0.3236
       Episode_Reward/lin_vel_z_l2: -0.0363
      Episode_Reward/ang_vel_xy_l2: -0.0934
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1450
     Episode_Reward/action_rate_l2: -0.1217
      Episode_Reward/feet_air_time: -0.0173
Episode_Reward/flat_orientation_l2: -0.0303
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.8555
Metrics/base_velocity/error_vel_xy: 0.5784
Metrics/base_velocity/error_vel_yaw: 0.5150
      Episode_Termination/time_out: 0.8358
  Episode_Termination/base_contact: 0.1645
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 2.49s
                      Time elapsed: 00:14:34
                               ETA: 00:05:35

################################################################################
                      [1m Learning iteration 362/500 [0m                      

                       Computation: 39182 steps/s (collection: 2.359s, learning 0.149s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0132
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 11.4571
                       Mean reward: 10.67
               Mean episode length: 921.68
Episode_Reward/track_lin_vel_xy_exp: 0.6446
Episode_Reward/track_ang_vel_z_exp: 0.3327
       Episode_Reward/lin_vel_z_l2: -0.0357
      Episode_Reward/ang_vel_xy_l2: -0.0928
     Episode_Reward/dof_torques_l2: -0.0043
         Episode_Reward/dof_acc_l2: -0.1377
     Episode_Reward/action_rate_l2: -0.1250
      Episode_Reward/feet_air_time: -0.0180
Episode_Reward/flat_orientation_l2: -0.0357
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.8657
Metrics/base_velocity/error_vel_xy: 0.5762
Metrics/base_velocity/error_vel_yaw: 0.5167
      Episode_Termination/time_out: 0.8361
  Episode_Termination/base_contact: 0.1642
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 2.51s
                      Time elapsed: 00:14:37
                               ETA: 00:05:33

################################################################################
                      [1m Learning iteration 363/500 [0m                      

                       Computation: 39231 steps/s (collection: 2.362s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0130
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 11.4395
                       Mean reward: 10.01
               Mean episode length: 922.97
Episode_Reward/track_lin_vel_xy_exp: 0.6209
Episode_Reward/track_ang_vel_z_exp: 0.3226
       Episode_Reward/lin_vel_z_l2: -0.0387
      Episode_Reward/ang_vel_xy_l2: -0.0953
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1484
     Episode_Reward/action_rate_l2: -0.1251
      Episode_Reward/feet_air_time: -0.0175
Episode_Reward/flat_orientation_l2: -0.0398
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.8828
Metrics/base_velocity/error_vel_xy: 0.5892
Metrics/base_velocity/error_vel_yaw: 0.5376
      Episode_Termination/time_out: 0.8370
  Episode_Termination/base_contact: 0.1633
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 2.51s
                      Time elapsed: 00:14:39
                               ETA: 00:05:31

################################################################################
                      [1m Learning iteration 364/500 [0m                      

                       Computation: 39043 steps/s (collection: 2.374s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0126
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 11.4428
                       Mean reward: 10.04
               Mean episode length: 905.01
Episode_Reward/track_lin_vel_xy_exp: 0.6216
Episode_Reward/track_ang_vel_z_exp: 0.3273
       Episode_Reward/lin_vel_z_l2: -0.0364
      Episode_Reward/ang_vel_xy_l2: -0.0924
     Episode_Reward/dof_torques_l2: -0.0043
         Episode_Reward/dof_acc_l2: -0.1361
     Episode_Reward/action_rate_l2: -0.1244
      Episode_Reward/feet_air_time: -0.0177
Episode_Reward/flat_orientation_l2: -0.0304
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.8937
Metrics/base_velocity/error_vel_xy: 0.6154
Metrics/base_velocity/error_vel_yaw: 0.5274
      Episode_Termination/time_out: 0.8380
  Episode_Termination/base_contact: 0.1622
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 2.52s
                      Time elapsed: 00:14:42
                               ETA: 00:05:28

################################################################################
                      [1m Learning iteration 365/500 [0m                      

                       Computation: 39202 steps/s (collection: 2.363s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0124
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 11.4496
                       Mean reward: 10.95
               Mean episode length: 948.61
Episode_Reward/track_lin_vel_xy_exp: 0.6530
Episode_Reward/track_ang_vel_z_exp: 0.3386
       Episode_Reward/lin_vel_z_l2: -0.0369
      Episode_Reward/ang_vel_xy_l2: -0.0968
     Episode_Reward/dof_torques_l2: -0.0043
         Episode_Reward/dof_acc_l2: -0.1419
     Episode_Reward/action_rate_l2: -0.1278
      Episode_Reward/feet_air_time: -0.0183
Episode_Reward/flat_orientation_l2: -0.0324
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.9037
Metrics/base_velocity/error_vel_xy: 0.6207
Metrics/base_velocity/error_vel_yaw: 0.5465
      Episode_Termination/time_out: 0.8380
  Episode_Termination/base_contact: 0.1622
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 2.51s
                      Time elapsed: 00:14:44
                               ETA: 00:05:26

################################################################################
                      [1m Learning iteration 366/500 [0m                      

                       Computation: 39199 steps/s (collection: 2.364s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0126
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 11.4569
                       Mean reward: 10.81
               Mean episode length: 952.56
Episode_Reward/track_lin_vel_xy_exp: 0.6632
Episode_Reward/track_ang_vel_z_exp: 0.3386
       Episode_Reward/lin_vel_z_l2: -0.0379
      Episode_Reward/ang_vel_xy_l2: -0.0961
     Episode_Reward/dof_torques_l2: -0.0043
         Episode_Reward/dof_acc_l2: -0.1396
     Episode_Reward/action_rate_l2: -0.1282
      Episode_Reward/feet_air_time: -0.0183
Episode_Reward/flat_orientation_l2: -0.0350
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.9177
Metrics/base_velocity/error_vel_xy: 0.5838
Metrics/base_velocity/error_vel_yaw: 0.5370
      Episode_Termination/time_out: 0.8409
  Episode_Termination/base_contact: 0.1594
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 2.51s
                      Time elapsed: 00:14:47
                               ETA: 00:05:23

################################################################################
                      [1m Learning iteration 367/500 [0m                      

                       Computation: 39142 steps/s (collection: 2.368s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0144
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 11.4530
                       Mean reward: 10.15
               Mean episode length: 928.60
Episode_Reward/track_lin_vel_xy_exp: 0.6459
Episode_Reward/track_ang_vel_z_exp: 0.3353
       Episode_Reward/lin_vel_z_l2: -0.0375
      Episode_Reward/ang_vel_xy_l2: -0.0963
     Episode_Reward/dof_torques_l2: -0.0043
         Episode_Reward/dof_acc_l2: -0.1455
     Episode_Reward/action_rate_l2: -0.1288
      Episode_Reward/feet_air_time: -0.0182
Episode_Reward/flat_orientation_l2: -0.0373
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.9290
Metrics/base_velocity/error_vel_xy: 0.6158
Metrics/base_velocity/error_vel_yaw: 0.5385
      Episode_Termination/time_out: 0.8422
  Episode_Termination/base_contact: 0.1580
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 2.51s
                      Time elapsed: 00:14:49
                               ETA: 00:05:21

################################################################################
                      [1m Learning iteration 368/500 [0m                      

                       Computation: 39385 steps/s (collection: 2.352s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0148
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 11.4448
                       Mean reward: 10.18
               Mean episode length: 894.06
Episode_Reward/track_lin_vel_xy_exp: 0.6370
Episode_Reward/track_ang_vel_z_exp: 0.3248
       Episode_Reward/lin_vel_z_l2: -0.0369
      Episode_Reward/ang_vel_xy_l2: -0.0928
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1410
     Episode_Reward/action_rate_l2: -0.1238
      Episode_Reward/feet_air_time: -0.0179
Episode_Reward/flat_orientation_l2: -0.0306
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.9424
Metrics/base_velocity/error_vel_xy: 0.5742
Metrics/base_velocity/error_vel_yaw: 0.5214
      Episode_Termination/time_out: 0.8433
  Episode_Termination/base_contact: 0.1570
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 2.50s
                      Time elapsed: 00:14:52
                               ETA: 00:05:19

################################################################################
                      [1m Learning iteration 369/500 [0m                      

                       Computation: 39289 steps/s (collection: 2.360s, learning 0.142s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0130
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 11.4363
                       Mean reward: 10.40
               Mean episode length: 937.77
Episode_Reward/track_lin_vel_xy_exp: 0.6229
Episode_Reward/track_ang_vel_z_exp: 0.3261
       Episode_Reward/lin_vel_z_l2: -0.0392
      Episode_Reward/ang_vel_xy_l2: -0.0947
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1406
     Episode_Reward/action_rate_l2: -0.1250
      Episode_Reward/feet_air_time: -0.0174
Episode_Reward/flat_orientation_l2: -0.0388
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.9494
Metrics/base_velocity/error_vel_xy: 0.6202
Metrics/base_velocity/error_vel_yaw: 0.5282
      Episode_Termination/time_out: 0.8423
  Episode_Termination/base_contact: 0.1580
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 2.50s
                      Time elapsed: 00:14:54
                               ETA: 00:05:16

################################################################################
                      [1m Learning iteration 370/500 [0m                      

                       Computation: 38917 steps/s (collection: 2.379s, learning 0.147s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0146
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 11.4448
                       Mean reward: 10.44
               Mean episode length: 920.56
Episode_Reward/track_lin_vel_xy_exp: 0.6642
Episode_Reward/track_ang_vel_z_exp: 0.3350
       Episode_Reward/lin_vel_z_l2: -0.0384
      Episode_Reward/ang_vel_xy_l2: -0.0950
     Episode_Reward/dof_torques_l2: -0.0044
         Episode_Reward/dof_acc_l2: -0.1405
     Episode_Reward/action_rate_l2: -0.1280
      Episode_Reward/feet_air_time: -0.0181
Episode_Reward/flat_orientation_l2: -0.0367
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.9606
Metrics/base_velocity/error_vel_xy: 0.5836
Metrics/base_velocity/error_vel_yaw: 0.5467
      Episode_Termination/time_out: 0.8444
  Episode_Termination/base_contact: 0.1559
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 2.53s
                      Time elapsed: 00:14:57
                               ETA: 00:05:14

################################################################################
                      [1m Learning iteration 371/500 [0m                      

                       Computation: 39181 steps/s (collection: 2.365s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0145
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 11.4531
                       Mean reward: 9.77
               Mean episode length: 957.35
Episode_Reward/track_lin_vel_xy_exp: 0.6355
Episode_Reward/track_ang_vel_z_exp: 0.3347
       Episode_Reward/lin_vel_z_l2: -0.0379
      Episode_Reward/ang_vel_xy_l2: -0.0989
     Episode_Reward/dof_torques_l2: -0.0044
         Episode_Reward/dof_acc_l2: -0.1538
     Episode_Reward/action_rate_l2: -0.1308
      Episode_Reward/feet_air_time: -0.0189
Episode_Reward/flat_orientation_l2: -0.0390
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.9703
Metrics/base_velocity/error_vel_xy: 0.6861
Metrics/base_velocity/error_vel_yaw: 0.5921
      Episode_Termination/time_out: 0.8477
  Episode_Termination/base_contact: 0.1525
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 2.51s
                      Time elapsed: 00:14:59
                               ETA: 00:05:11

################################################################################
                      [1m Learning iteration 372/500 [0m                      

                       Computation: 39210 steps/s (collection: 2.363s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0128
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 11.4509
                       Mean reward: 10.64
               Mean episode length: 908.04
Episode_Reward/track_lin_vel_xy_exp: 0.6344
Episode_Reward/track_ang_vel_z_exp: 0.3158
       Episode_Reward/lin_vel_z_l2: -0.0351
      Episode_Reward/ang_vel_xy_l2: -0.0881
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1303
     Episode_Reward/action_rate_l2: -0.1187
      Episode_Reward/feet_air_time: -0.0169
Episode_Reward/flat_orientation_l2: -0.0342
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.9818
Metrics/base_velocity/error_vel_xy: 0.5101
Metrics/base_velocity/error_vel_yaw: 0.5001
      Episode_Termination/time_out: 0.8500
  Episode_Termination/base_contact: 0.1503
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 2.51s
                      Time elapsed: 00:15:02
                               ETA: 00:05:09

################################################################################
                      [1m Learning iteration 373/500 [0m                      

                       Computation: 39181 steps/s (collection: 2.365s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0141
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 11.4521
                       Mean reward: 9.61
               Mean episode length: 885.71
Episode_Reward/track_lin_vel_xy_exp: 0.6166
Episode_Reward/track_ang_vel_z_exp: 0.3201
       Episode_Reward/lin_vel_z_l2: -0.0359
      Episode_Reward/ang_vel_xy_l2: -0.0936
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1360
     Episode_Reward/action_rate_l2: -0.1231
      Episode_Reward/feet_air_time: -0.0182
Episode_Reward/flat_orientation_l2: -0.0391
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.9891
Metrics/base_velocity/error_vel_xy: 0.6114
Metrics/base_velocity/error_vel_yaw: 0.5513
      Episode_Termination/time_out: 0.8519
  Episode_Termination/base_contact: 0.1484
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 2.51s
                      Time elapsed: 00:15:04
                               ETA: 00:05:07

################################################################################
                      [1m Learning iteration 374/500 [0m                      

                       Computation: 39171 steps/s (collection: 2.366s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0125
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 11.4617
                       Mean reward: 9.26
               Mean episode length: 890.54
Episode_Reward/track_lin_vel_xy_exp: 0.5744
Episode_Reward/track_ang_vel_z_exp: 0.3108
       Episode_Reward/lin_vel_z_l2: -0.0368
      Episode_Reward/ang_vel_xy_l2: -0.0914
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1403
     Episode_Reward/action_rate_l2: -0.1207
      Episode_Reward/feet_air_time: -0.0169
Episode_Reward/flat_orientation_l2: -0.0329
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 1.9981
Metrics/base_velocity/error_vel_xy: 0.6234
Metrics/base_velocity/error_vel_yaw: 0.5212
      Episode_Termination/time_out: 0.8531
  Episode_Termination/base_contact: 0.1471
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 2.51s
                      Time elapsed: 00:15:07
                               ETA: 00:05:04

################################################################################
                      [1m Learning iteration 375/500 [0m                      

                       Computation: 38982 steps/s (collection: 2.376s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0148
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 11.4560
                       Mean reward: 8.97
               Mean episode length: 878.82
Episode_Reward/track_lin_vel_xy_exp: 0.5990
Episode_Reward/track_ang_vel_z_exp: 0.3179
       Episode_Reward/lin_vel_z_l2: -0.0355
      Episode_Reward/ang_vel_xy_l2: -0.0926
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1321
     Episode_Reward/action_rate_l2: -0.1215
      Episode_Reward/feet_air_time: -0.0175
Episode_Reward/flat_orientation_l2: -0.0414
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.0060
Metrics/base_velocity/error_vel_xy: 0.6180
Metrics/base_velocity/error_vel_yaw: 0.5347
      Episode_Termination/time_out: 0.8542
  Episode_Termination/base_contact: 0.1460
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 2.52s
                      Time elapsed: 00:15:09
                               ETA: 00:05:02

################################################################################
                      [1m Learning iteration 376/500 [0m                      

                       Computation: 38747 steps/s (collection: 2.393s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0144
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 11.4616
                       Mean reward: 9.55
               Mean episode length: 886.36
Episode_Reward/track_lin_vel_xy_exp: 0.6106
Episode_Reward/track_ang_vel_z_exp: 0.3137
       Episode_Reward/lin_vel_z_l2: -0.0360
      Episode_Reward/ang_vel_xy_l2: -0.0904
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1370
     Episode_Reward/action_rate_l2: -0.1207
      Episode_Reward/feet_air_time: -0.0170
Episode_Reward/flat_orientation_l2: -0.0427
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.0152
Metrics/base_velocity/error_vel_xy: 0.5726
Metrics/base_velocity/error_vel_yaw: 0.5266
      Episode_Termination/time_out: 0.8555
  Episode_Termination/base_contact: 0.1447
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 2.54s
                      Time elapsed: 00:15:12
                               ETA: 00:05:00

################################################################################
                      [1m Learning iteration 377/500 [0m                      

                       Computation: 39060 steps/s (collection: 2.370s, learning 0.147s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0127
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 11.4657
                       Mean reward: 9.93
               Mean episode length: 911.46
Episode_Reward/track_lin_vel_xy_exp: 0.6509
Episode_Reward/track_ang_vel_z_exp: 0.3298
       Episode_Reward/lin_vel_z_l2: -0.0382
      Episode_Reward/ang_vel_xy_l2: -0.0948
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1428
     Episode_Reward/action_rate_l2: -0.1261
      Episode_Reward/feet_air_time: -0.0176
Episode_Reward/flat_orientation_l2: -0.0366
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.0253
Metrics/base_velocity/error_vel_xy: 0.5772
Metrics/base_velocity/error_vel_yaw: 0.5403
      Episode_Termination/time_out: 0.8568
  Episode_Termination/base_contact: 0.1434
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 2.52s
                      Time elapsed: 00:15:14
                               ETA: 00:04:57

################################################################################
                      [1m Learning iteration 378/500 [0m                      

                       Computation: 38759 steps/s (collection: 2.391s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0145
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 11.4570
                       Mean reward: 11.06
               Mean episode length: 938.16
Episode_Reward/track_lin_vel_xy_exp: 0.6518
Episode_Reward/track_ang_vel_z_exp: 0.3291
       Episode_Reward/lin_vel_z_l2: -0.0357
      Episode_Reward/ang_vel_xy_l2: -0.0916
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1399
     Episode_Reward/action_rate_l2: -0.1248
      Episode_Reward/feet_air_time: -0.0178
Episode_Reward/flat_orientation_l2: -0.0338
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.0363
Metrics/base_velocity/error_vel_xy: 0.5500
Metrics/base_velocity/error_vel_yaw: 0.5082
      Episode_Termination/time_out: 0.8574
  Episode_Termination/base_contact: 0.1428
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 2.54s
                      Time elapsed: 00:15:17
                               ETA: 00:04:55

################################################################################
                      [1m Learning iteration 379/500 [0m                      

                       Computation: 38834 steps/s (collection: 2.385s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0138
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 11.4614
                       Mean reward: 9.26
               Mean episode length: 879.38
Episode_Reward/track_lin_vel_xy_exp: 0.5988
Episode_Reward/track_ang_vel_z_exp: 0.3128
       Episode_Reward/lin_vel_z_l2: -0.0380
      Episode_Reward/ang_vel_xy_l2: -0.0902
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1447
     Episode_Reward/action_rate_l2: -0.1205
      Episode_Reward/feet_air_time: -0.0172
Episode_Reward/flat_orientation_l2: -0.0388
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.0483
Metrics/base_velocity/error_vel_xy: 0.5965
Metrics/base_velocity/error_vel_yaw: 0.5232
      Episode_Termination/time_out: 0.8560
  Episode_Termination/base_contact: 0.1442
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 2.53s
                      Time elapsed: 00:15:19
                               ETA: 00:04:52

################################################################################
                      [1m Learning iteration 380/500 [0m                      

                       Computation: 38768 steps/s (collection: 2.389s, learning 0.147s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0136
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 11.4654
                       Mean reward: 10.62
               Mean episode length: 918.56
Episode_Reward/track_lin_vel_xy_exp: 0.6302
Episode_Reward/track_ang_vel_z_exp: 0.3292
       Episode_Reward/lin_vel_z_l2: -0.0355
      Episode_Reward/ang_vel_xy_l2: -0.0923
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1321
     Episode_Reward/action_rate_l2: -0.1243
      Episode_Reward/feet_air_time: -0.0181
Episode_Reward/flat_orientation_l2: -0.0373
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.0603
Metrics/base_velocity/error_vel_xy: 0.6187
Metrics/base_velocity/error_vel_yaw: 0.5281
      Episode_Termination/time_out: 0.8569
  Episode_Termination/base_contact: 0.1433
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 2.54s
                      Time elapsed: 00:15:22
                               ETA: 00:04:50

################################################################################
                      [1m Learning iteration 381/500 [0m                      

                       Computation: 38735 steps/s (collection: 2.395s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0138
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 11.4717
                       Mean reward: 9.96
               Mean episode length: 903.44
Episode_Reward/track_lin_vel_xy_exp: 0.5995
Episode_Reward/track_ang_vel_z_exp: 0.3199
       Episode_Reward/lin_vel_z_l2: -0.0339
      Episode_Reward/ang_vel_xy_l2: -0.0900
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1312
     Episode_Reward/action_rate_l2: -0.1197
      Episode_Reward/feet_air_time: -0.0178
Episode_Reward/flat_orientation_l2: -0.0360
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.0706
Metrics/base_velocity/error_vel_xy: 0.6206
Metrics/base_velocity/error_vel_yaw: 0.5210
      Episode_Termination/time_out: 0.8588
  Episode_Termination/base_contact: 0.1412
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 2.54s
                      Time elapsed: 00:15:24
                               ETA: 00:04:48

################################################################################
                      [1m Learning iteration 382/500 [0m                      

                       Computation: 38670 steps/s (collection: 2.396s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0138
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 11.4730
                       Mean reward: 9.86
               Mean episode length: 894.54
Episode_Reward/track_lin_vel_xy_exp: 0.6289
Episode_Reward/track_ang_vel_z_exp: 0.3232
       Episode_Reward/lin_vel_z_l2: -0.0355
      Episode_Reward/ang_vel_xy_l2: -0.0903
     Episode_Reward/dof_torques_l2: -0.0043
         Episode_Reward/dof_acc_l2: -0.1342
     Episode_Reward/action_rate_l2: -0.1236
      Episode_Reward/feet_air_time: -0.0174
Episode_Reward/flat_orientation_l2: -0.0322
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.0797
Metrics/base_velocity/error_vel_xy: 0.5816
Metrics/base_velocity/error_vel_yaw: 0.5267
      Episode_Termination/time_out: 0.8605
  Episode_Termination/base_contact: 0.1395
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 2.54s
                      Time elapsed: 00:15:27
                               ETA: 00:04:45

################################################################################
                      [1m Learning iteration 383/500 [0m                      

                       Computation: 39133 steps/s (collection: 2.368s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0144
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 11.4676
                       Mean reward: 9.23
               Mean episode length: 882.78
Episode_Reward/track_lin_vel_xy_exp: 0.5742
Episode_Reward/track_ang_vel_z_exp: 0.3064
       Episode_Reward/lin_vel_z_l2: -0.0360
      Episode_Reward/ang_vel_xy_l2: -0.0895
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1341
     Episode_Reward/action_rate_l2: -0.1193
      Episode_Reward/feet_air_time: -0.0174
Episode_Reward/flat_orientation_l2: -0.0360
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.0905
Metrics/base_velocity/error_vel_xy: 0.6126
Metrics/base_velocity/error_vel_yaw: 0.5188
      Episode_Termination/time_out: 0.8599
  Episode_Termination/base_contact: 0.1401
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 2.51s
                      Time elapsed: 00:15:29
                               ETA: 00:04:43

################################################################################
                      [1m Learning iteration 384/500 [0m                      

                       Computation: 39017 steps/s (collection: 2.376s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0157
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 11.4648
                       Mean reward: 9.37
               Mean episode length: 872.06
Episode_Reward/track_lin_vel_xy_exp: 0.6090
Episode_Reward/track_ang_vel_z_exp: 0.3157
       Episode_Reward/lin_vel_z_l2: -0.0356
      Episode_Reward/ang_vel_xy_l2: -0.0898
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1363
     Episode_Reward/action_rate_l2: -0.1202
      Episode_Reward/feet_air_time: -0.0166
Episode_Reward/flat_orientation_l2: -0.0391
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.0955
Metrics/base_velocity/error_vel_xy: 0.5813
Metrics/base_velocity/error_vel_yaw: 0.5178
      Episode_Termination/time_out: 0.8590
  Episode_Termination/base_contact: 0.1410
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 2.52s
                      Time elapsed: 00:15:32
                               ETA: 00:04:40

################################################################################
                      [1m Learning iteration 385/500 [0m                      

                       Computation: 38942 steps/s (collection: 2.381s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0139
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 11.4832
                       Mean reward: 10.61
               Mean episode length: 881.82
Episode_Reward/track_lin_vel_xy_exp: 0.6193
Episode_Reward/track_ang_vel_z_exp: 0.3059
       Episode_Reward/lin_vel_z_l2: -0.0343
      Episode_Reward/ang_vel_xy_l2: -0.0868
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1261
     Episode_Reward/action_rate_l2: -0.1166
      Episode_Reward/feet_air_time: -0.0161
Episode_Reward/flat_orientation_l2: -0.0344
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.1057
Metrics/base_velocity/error_vel_xy: 0.5052
Metrics/base_velocity/error_vel_yaw: 0.5051
      Episode_Termination/time_out: 0.8580
  Episode_Termination/base_contact: 0.1420
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 2.52s
                      Time elapsed: 00:15:34
                               ETA: 00:04:38

################################################################################
                      [1m Learning iteration 386/500 [0m                      

                       Computation: 38947 steps/s (collection: 2.380s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0126
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 11.4833
                       Mean reward: 10.50
               Mean episode length: 906.04
Episode_Reward/track_lin_vel_xy_exp: 0.6182
Episode_Reward/track_ang_vel_z_exp: 0.3110
       Episode_Reward/lin_vel_z_l2: -0.0355
      Episode_Reward/ang_vel_xy_l2: -0.0895
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1350
     Episode_Reward/action_rate_l2: -0.1210
      Episode_Reward/feet_air_time: -0.0171
Episode_Reward/flat_orientation_l2: -0.0333
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.1167
Metrics/base_velocity/error_vel_xy: 0.5524
Metrics/base_velocity/error_vel_yaw: 0.5195
      Episode_Termination/time_out: 0.8587
  Episode_Termination/base_contact: 0.1413
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 2.52s
                      Time elapsed: 00:15:37
                               ETA: 00:04:36

################################################################################
                      [1m Learning iteration 387/500 [0m                      

                       Computation: 38737 steps/s (collection: 2.391s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0136
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 11.4772
                       Mean reward: 10.10
               Mean episode length: 902.51
Episode_Reward/track_lin_vel_xy_exp: 0.6323
Episode_Reward/track_ang_vel_z_exp: 0.3197
       Episode_Reward/lin_vel_z_l2: -0.0357
      Episode_Reward/ang_vel_xy_l2: -0.0922
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1297
     Episode_Reward/action_rate_l2: -0.1199
      Episode_Reward/feet_air_time: -0.0174
Episode_Reward/flat_orientation_l2: -0.0451
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.1252
Metrics/base_velocity/error_vel_xy: 0.5490
Metrics/base_velocity/error_vel_yaw: 0.4994
      Episode_Termination/time_out: 0.8590
  Episode_Termination/base_contact: 0.1410
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 2.54s
                      Time elapsed: 00:15:40
                               ETA: 00:04:33

################################################################################
                      [1m Learning iteration 388/500 [0m                      

                       Computation: 38579 steps/s (collection: 2.403s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0164
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 11.4799
                       Mean reward: 10.73
               Mean episode length: 915.67
Episode_Reward/track_lin_vel_xy_exp: 0.6333
Episode_Reward/track_ang_vel_z_exp: 0.3196
       Episode_Reward/lin_vel_z_l2: -0.0355
      Episode_Reward/ang_vel_xy_l2: -0.0893
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1318
     Episode_Reward/action_rate_l2: -0.1209
      Episode_Reward/feet_air_time: -0.0172
Episode_Reward/flat_orientation_l2: -0.0347
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.1322
Metrics/base_velocity/error_vel_xy: 0.5506
Metrics/base_velocity/error_vel_yaw: 0.5031
      Episode_Termination/time_out: 0.8598
  Episode_Termination/base_contact: 0.1402
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 2.55s
                      Time elapsed: 00:15:42
                               ETA: 00:04:31

################################################################################
                      [1m Learning iteration 389/500 [0m                      

                       Computation: 38516 steps/s (collection: 2.408s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0135
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 11.4809
                       Mean reward: 9.08
               Mean episode length: 863.64
Episode_Reward/track_lin_vel_xy_exp: 0.5929
Episode_Reward/track_ang_vel_z_exp: 0.3061
       Episode_Reward/lin_vel_z_l2: -0.0345
      Episode_Reward/ang_vel_xy_l2: -0.0868
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1315
     Episode_Reward/action_rate_l2: -0.1169
      Episode_Reward/feet_air_time: -0.0167
Episode_Reward/flat_orientation_l2: -0.0398
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.1428
Metrics/base_velocity/error_vel_xy: 0.5627
Metrics/base_velocity/error_vel_yaw: 0.4960
      Episode_Termination/time_out: 0.8601
  Episode_Termination/base_contact: 0.1399
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 2.55s
                      Time elapsed: 00:15:45
                               ETA: 00:04:28

################################################################################
                      [1m Learning iteration 390/500 [0m                      

                       Computation: 38538 steps/s (collection: 2.406s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0147
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 11.4741
                       Mean reward: 10.50
               Mean episode length: 945.04
Episode_Reward/track_lin_vel_xy_exp: 0.6087
Episode_Reward/track_ang_vel_z_exp: 0.3287
       Episode_Reward/lin_vel_z_l2: -0.0361
      Episode_Reward/ang_vel_xy_l2: -0.0932
     Episode_Reward/dof_torques_l2: -0.0043
         Episode_Reward/dof_acc_l2: -0.1379
     Episode_Reward/action_rate_l2: -0.1257
      Episode_Reward/feet_air_time: -0.0179
Episode_Reward/flat_orientation_l2: -0.0364
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.1527
Metrics/base_velocity/error_vel_xy: 0.6434
Metrics/base_velocity/error_vel_yaw: 0.5376
      Episode_Termination/time_out: 0.8601
  Episode_Termination/base_contact: 0.1399
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 2.55s
                      Time elapsed: 00:15:47
                               ETA: 00:04:26

################################################################################
                      [1m Learning iteration 391/500 [0m                      

                       Computation: 38683 steps/s (collection: 2.397s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0127
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 11.4662
                       Mean reward: 9.88
               Mean episode length: 890.87
Episode_Reward/track_lin_vel_xy_exp: 0.5982
Episode_Reward/track_ang_vel_z_exp: 0.3157
       Episode_Reward/lin_vel_z_l2: -0.0367
      Episode_Reward/ang_vel_xy_l2: -0.0916
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1319
     Episode_Reward/action_rate_l2: -0.1205
      Episode_Reward/feet_air_time: -0.0175
Episode_Reward/flat_orientation_l2: -0.0391
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.1656
Metrics/base_velocity/error_vel_xy: 0.6007
Metrics/base_velocity/error_vel_yaw: 0.5136
      Episode_Termination/time_out: 0.8597
  Episode_Termination/base_contact: 0.1403
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 2.54s
                      Time elapsed: 00:15:50
                               ETA: 00:04:24

################################################################################
                      [1m Learning iteration 392/500 [0m                      

                       Computation: 38566 steps/s (collection: 2.405s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0130
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 11.4562
                       Mean reward: 9.51
               Mean episode length: 871.83
Episode_Reward/track_lin_vel_xy_exp: 0.5924
Episode_Reward/track_ang_vel_z_exp: 0.3129
       Episode_Reward/lin_vel_z_l2: -0.0345
      Episode_Reward/ang_vel_xy_l2: -0.0892
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1315
     Episode_Reward/action_rate_l2: -0.1204
      Episode_Reward/feet_air_time: -0.0173
Episode_Reward/flat_orientation_l2: -0.0354
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.1732
Metrics/base_velocity/error_vel_xy: 0.5947
Metrics/base_velocity/error_vel_yaw: 0.5105
      Episode_Termination/time_out: 0.8574
  Episode_Termination/base_contact: 0.1426
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 2.55s
                      Time elapsed: 00:15:52
                               ETA: 00:04:21

################################################################################
                      [1m Learning iteration 393/500 [0m                      

                       Computation: 38357 steps/s (collection: 2.415s, learning 0.148s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0124
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 11.4540
                       Mean reward: 9.36
               Mean episode length: 861.92
Episode_Reward/track_lin_vel_xy_exp: 0.6082
Episode_Reward/track_ang_vel_z_exp: 0.3147
       Episode_Reward/lin_vel_z_l2: -0.0353
      Episode_Reward/ang_vel_xy_l2: -0.0888
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1360
     Episode_Reward/action_rate_l2: -0.1189
      Episode_Reward/feet_air_time: -0.0174
Episode_Reward/flat_orientation_l2: -0.0436
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.1830
Metrics/base_velocity/error_vel_xy: 0.5708
Metrics/base_velocity/error_vel_yaw: 0.5021
      Episode_Termination/time_out: 0.8563
  Episode_Termination/base_contact: 0.1437
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 2.56s
                      Time elapsed: 00:15:55
                               ETA: 00:04:19

################################################################################
                      [1m Learning iteration 394/500 [0m                      

                       Computation: 38515 steps/s (collection: 2.409s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0137
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 11.4454
                       Mean reward: 10.39
               Mean episode length: 895.99
Episode_Reward/track_lin_vel_xy_exp: 0.6316
Episode_Reward/track_ang_vel_z_exp: 0.3199
       Episode_Reward/lin_vel_z_l2: -0.0340
      Episode_Reward/ang_vel_xy_l2: -0.0893
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1352
     Episode_Reward/action_rate_l2: -0.1218
      Episode_Reward/feet_air_time: -0.0177
Episode_Reward/flat_orientation_l2: -0.0313
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.1904
Metrics/base_velocity/error_vel_xy: 0.5608
Metrics/base_velocity/error_vel_yaw: 0.5192
      Episode_Termination/time_out: 0.8534
  Episode_Termination/base_contact: 0.1466
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 2.55s
                      Time elapsed: 00:15:57
                               ETA: 00:04:17

################################################################################
                      [1m Learning iteration 395/500 [0m                      

                       Computation: 38913 steps/s (collection: 2.383s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0132
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 11.4490
                       Mean reward: 9.99
               Mean episode length: 880.57
Episode_Reward/track_lin_vel_xy_exp: 0.6157
Episode_Reward/track_ang_vel_z_exp: 0.3054
       Episode_Reward/lin_vel_z_l2: -0.0349
      Episode_Reward/ang_vel_xy_l2: -0.0869
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1301
     Episode_Reward/action_rate_l2: -0.1146
      Episode_Reward/feet_air_time: -0.0163
Episode_Reward/flat_orientation_l2: -0.0336
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.1984
Metrics/base_velocity/error_vel_xy: 0.4986
Metrics/base_velocity/error_vel_yaw: 0.4826
      Episode_Termination/time_out: 0.8520
  Episode_Termination/base_contact: 0.1480
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 2.53s
                      Time elapsed: 00:16:00
                               ETA: 00:04:14

################################################################################
                      [1m Learning iteration 396/500 [0m                      

                       Computation: 38547 steps/s (collection: 2.406s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0138
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 11.4502
                       Mean reward: 9.37
               Mean episode length: 844.88
Episode_Reward/track_lin_vel_xy_exp: 0.6046
Episode_Reward/track_ang_vel_z_exp: 0.3139
       Episode_Reward/lin_vel_z_l2: -0.0353
      Episode_Reward/ang_vel_xy_l2: -0.0908
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1305
     Episode_Reward/action_rate_l2: -0.1183
      Episode_Reward/feet_air_time: -0.0175
Episode_Reward/flat_orientation_l2: -0.0389
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.2051
Metrics/base_velocity/error_vel_xy: 0.5899
Metrics/base_velocity/error_vel_yaw: 0.5174
      Episode_Termination/time_out: 0.8509
  Episode_Termination/base_contact: 0.1491
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 2.55s
                      Time elapsed: 00:16:02
                               ETA: 00:04:12

################################################################################
                      [1m Learning iteration 397/500 [0m                      

                       Computation: 38525 steps/s (collection: 2.406s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0141
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 11.4459
                       Mean reward: 10.13
               Mean episode length: 894.76
Episode_Reward/track_lin_vel_xy_exp: 0.6460
Episode_Reward/track_ang_vel_z_exp: 0.3249
       Episode_Reward/lin_vel_z_l2: -0.0352
      Episode_Reward/ang_vel_xy_l2: -0.0906
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1393
     Episode_Reward/action_rate_l2: -0.1221
      Episode_Reward/feet_air_time: -0.0174
Episode_Reward/flat_orientation_l2: -0.0375
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.2176
Metrics/base_velocity/error_vel_xy: 0.5358
Metrics/base_velocity/error_vel_yaw: 0.5017
      Episode_Termination/time_out: 0.8502
  Episode_Termination/base_contact: 0.1498
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 2.55s
                      Time elapsed: 00:16:05
                               ETA: 00:04:09

################################################################################
                      [1m Learning iteration 398/500 [0m                      

                       Computation: 38658 steps/s (collection: 2.399s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0146
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 11.4524
                       Mean reward: 10.59
               Mean episode length: 870.68
Episode_Reward/track_lin_vel_xy_exp: 0.6104
Episode_Reward/track_ang_vel_z_exp: 0.3058
       Episode_Reward/lin_vel_z_l2: -0.0335
      Episode_Reward/ang_vel_xy_l2: -0.0857
     Episode_Reward/dof_torques_l2: -0.0038
         Episode_Reward/dof_acc_l2: -0.1273
     Episode_Reward/action_rate_l2: -0.1153
      Episode_Reward/feet_air_time: -0.0167
Episode_Reward/flat_orientation_l2: -0.0391
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.2310
Metrics/base_velocity/error_vel_xy: 0.4969
Metrics/base_velocity/error_vel_yaw: 0.4731
      Episode_Termination/time_out: 0.8498
  Episode_Termination/base_contact: 0.1502
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 2.54s
                      Time elapsed: 00:16:08
                               ETA: 00:04:07

################################################################################
                      [1m Learning iteration 399/500 [0m                      

                       Computation: 38679 steps/s (collection: 2.399s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0143
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 11.4551
                       Mean reward: 9.81
               Mean episode length: 848.45
Episode_Reward/track_lin_vel_xy_exp: 0.6068
Episode_Reward/track_ang_vel_z_exp: 0.3014
       Episode_Reward/lin_vel_z_l2: -0.0325
      Episode_Reward/ang_vel_xy_l2: -0.0827
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1254
     Episode_Reward/action_rate_l2: -0.1135
      Episode_Reward/feet_air_time: -0.0162
Episode_Reward/flat_orientation_l2: -0.0299
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.2397
Metrics/base_velocity/error_vel_xy: 0.4993
Metrics/base_velocity/error_vel_yaw: 0.4682
      Episode_Termination/time_out: 0.8489
  Episode_Termination/base_contact: 0.1511
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 2.54s
                      Time elapsed: 00:16:10
                               ETA: 00:04:05

################################################################################
                      [1m Learning iteration 400/500 [0m                      

                       Computation: 38385 steps/s (collection: 2.414s, learning 0.147s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0141
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 11.4718
                       Mean reward: 9.59
               Mean episode length: 867.23
Episode_Reward/track_lin_vel_xy_exp: 0.6013
Episode_Reward/track_ang_vel_z_exp: 0.3099
       Episode_Reward/lin_vel_z_l2: -0.0324
      Episode_Reward/ang_vel_xy_l2: -0.0854
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1266
     Episode_Reward/action_rate_l2: -0.1162
      Episode_Reward/feet_air_time: -0.0166
Episode_Reward/flat_orientation_l2: -0.0338
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.2489
Metrics/base_velocity/error_vel_xy: 0.5588
Metrics/base_velocity/error_vel_yaw: 0.5011
      Episode_Termination/time_out: 0.8466
  Episode_Termination/base_contact: 0.1534
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 2.56s
                      Time elapsed: 00:16:13
                               ETA: 00:04:02

################################################################################
                      [1m Learning iteration 401/500 [0m                      

                       Computation: 38517 steps/s (collection: 2.410s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0142
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 11.4907
                       Mean reward: 8.67
               Mean episode length: 826.88
Episode_Reward/track_lin_vel_xy_exp: 0.5643
Episode_Reward/track_ang_vel_z_exp: 0.2991
       Episode_Reward/lin_vel_z_l2: -0.0329
      Episode_Reward/ang_vel_xy_l2: -0.0854
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1258
     Episode_Reward/action_rate_l2: -0.1144
      Episode_Reward/feet_air_time: -0.0159
Episode_Reward/flat_orientation_l2: -0.0350
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.2532
Metrics/base_velocity/error_vel_xy: 0.5847
Metrics/base_velocity/error_vel_yaw: 0.4926
      Episode_Termination/time_out: 0.8450
  Episode_Termination/base_contact: 0.1550
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 2.55s
                      Time elapsed: 00:16:15
                               ETA: 00:04:00

################################################################################
                      [1m Learning iteration 402/500 [0m                      

                       Computation: 38476 steps/s (collection: 2.408s, learning 0.147s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0122
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 11.5043
                       Mean reward: 10.33
               Mean episode length: 895.68
Episode_Reward/track_lin_vel_xy_exp: 0.6474
Episode_Reward/track_ang_vel_z_exp: 0.3217
       Episode_Reward/lin_vel_z_l2: -0.0348
      Episode_Reward/ang_vel_xy_l2: -0.0884
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1400
     Episode_Reward/action_rate_l2: -0.1224
      Episode_Reward/feet_air_time: -0.0168
Episode_Reward/flat_orientation_l2: -0.0347
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.2606
Metrics/base_velocity/error_vel_xy: 0.5187
Metrics/base_velocity/error_vel_yaw: 0.5010
      Episode_Termination/time_out: 0.8427
  Episode_Termination/base_contact: 0.1573
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 2.55s
                      Time elapsed: 00:16:18
                               ETA: 00:03:57

################################################################################
                      [1m Learning iteration 403/500 [0m                      

                       Computation: 38395 steps/s (collection: 2.415s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0130
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 11.4968
                       Mean reward: 10.77
               Mean episode length: 884.02
Episode_Reward/track_lin_vel_xy_exp: 0.6473
Episode_Reward/track_ang_vel_z_exp: 0.3186
       Episode_Reward/lin_vel_z_l2: -0.0345
      Episode_Reward/ang_vel_xy_l2: -0.0886
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1350
     Episode_Reward/action_rate_l2: -0.1200
      Episode_Reward/feet_air_time: -0.0177
Episode_Reward/flat_orientation_l2: -0.0288
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.2688
Metrics/base_velocity/error_vel_xy: 0.5033
Metrics/base_velocity/error_vel_yaw: 0.4821
      Episode_Termination/time_out: 0.8417
  Episode_Termination/base_contact: 0.1583
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 2.56s
                      Time elapsed: 00:16:20
                               ETA: 00:03:55

################################################################################
                      [1m Learning iteration 404/500 [0m                      

                       Computation: 38469 steps/s (collection: 2.411s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0166
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 11.4809
                       Mean reward: 10.10
               Mean episode length: 842.65
Episode_Reward/track_lin_vel_xy_exp: 0.6159
Episode_Reward/track_ang_vel_z_exp: 0.3062
       Episode_Reward/lin_vel_z_l2: -0.0341
      Episode_Reward/ang_vel_xy_l2: -0.0879
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1364
     Episode_Reward/action_rate_l2: -0.1175
      Episode_Reward/feet_air_time: -0.0170
Episode_Reward/flat_orientation_l2: -0.0376
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.2799
Metrics/base_velocity/error_vel_xy: 0.5486
Metrics/base_velocity/error_vel_yaw: 0.5242
      Episode_Termination/time_out: 0.8394
  Episode_Termination/base_contact: 0.1606
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 2.56s
                      Time elapsed: 00:16:23
                               ETA: 00:03:53

################################################################################
                      [1m Learning iteration 405/500 [0m                      

                       Computation: 38179 steps/s (collection: 2.431s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0132
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 11.4961
                       Mean reward: 8.79
               Mean episode length: 869.00
Episode_Reward/track_lin_vel_xy_exp: 0.5444
Episode_Reward/track_ang_vel_z_exp: 0.2981
       Episode_Reward/lin_vel_z_l2: -0.0344
      Episode_Reward/ang_vel_xy_l2: -0.0868
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1310
     Episode_Reward/action_rate_l2: -0.1155
      Episode_Reward/feet_air_time: -0.0163
Episode_Reward/flat_orientation_l2: -0.0351
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.2932
Metrics/base_velocity/error_vel_xy: 0.6219
Metrics/base_velocity/error_vel_yaw: 0.5061
      Episode_Termination/time_out: 0.8390
  Episode_Termination/base_contact: 0.1610
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 2.57s
                      Time elapsed: 00:16:25
                               ETA: 00:03:50

################################################################################
                      [1m Learning iteration 406/500 [0m                      

                       Computation: 38219 steps/s (collection: 2.423s, learning 0.149s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0140
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 11.5048
                       Mean reward: 10.35
               Mean episode length: 898.94
Episode_Reward/track_lin_vel_xy_exp: 0.6175
Episode_Reward/track_ang_vel_z_exp: 0.3202
       Episode_Reward/lin_vel_z_l2: -0.0350
      Episode_Reward/ang_vel_xy_l2: -0.0916
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1365
     Episode_Reward/action_rate_l2: -0.1222
      Episode_Reward/feet_air_time: -0.0177
Episode_Reward/flat_orientation_l2: -0.0335
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.3015
Metrics/base_velocity/error_vel_xy: 0.5970
Metrics/base_velocity/error_vel_yaw: 0.5238
      Episode_Termination/time_out: 0.8385
  Episode_Termination/base_contact: 0.1615
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 2.57s
                      Time elapsed: 00:16:28
                               ETA: 00:03:48

################################################################################
                      [1m Learning iteration 407/500 [0m                      

                       Computation: 38638 steps/s (collection: 2.401s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0142
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 11.4991
                       Mean reward: 10.54
               Mean episode length: 875.18
Episode_Reward/track_lin_vel_xy_exp: 0.6399
Episode_Reward/track_ang_vel_z_exp: 0.3189
       Episode_Reward/lin_vel_z_l2: -0.0345
      Episode_Reward/ang_vel_xy_l2: -0.0890
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1324
     Episode_Reward/action_rate_l2: -0.1189
      Episode_Reward/feet_air_time: -0.0174
Episode_Reward/flat_orientation_l2: -0.0382
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.3139
Metrics/base_velocity/error_vel_xy: 0.5238
Metrics/base_velocity/error_vel_yaw: 0.4989
      Episode_Termination/time_out: 0.8369
  Episode_Termination/base_contact: 0.1631
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 2.54s
                      Time elapsed: 00:16:31
                               ETA: 00:03:45

################################################################################
                      [1m Learning iteration 408/500 [0m                      

                       Computation: 38352 steps/s (collection: 2.420s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0130
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 11.4878
                       Mean reward: 11.38
               Mean episode length: 905.83
Episode_Reward/track_lin_vel_xy_exp: 0.6540
Episode_Reward/track_ang_vel_z_exp: 0.3254
       Episode_Reward/lin_vel_z_l2: -0.0349
      Episode_Reward/ang_vel_xy_l2: -0.0899
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1323
     Episode_Reward/action_rate_l2: -0.1230
      Episode_Reward/feet_air_time: -0.0176
Episode_Reward/flat_orientation_l2: -0.0326
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.3252
Metrics/base_velocity/error_vel_xy: 0.5452
Metrics/base_velocity/error_vel_yaw: 0.5123
      Episode_Termination/time_out: 0.8350
  Episode_Termination/base_contact: 0.1650
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 2.56s
                      Time elapsed: 00:16:33
                               ETA: 00:03:43

################################################################################
                      [1m Learning iteration 409/500 [0m                      

                       Computation: 38053 steps/s (collection: 2.438s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0141
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 11.4877
                       Mean reward: 10.59
               Mean episode length: 895.77
Episode_Reward/track_lin_vel_xy_exp: 0.6162
Episode_Reward/track_ang_vel_z_exp: 0.3174
       Episode_Reward/lin_vel_z_l2: -0.0362
      Episode_Reward/ang_vel_xy_l2: -0.0894
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1382
     Episode_Reward/action_rate_l2: -0.1233
      Episode_Reward/feet_air_time: -0.0176
Episode_Reward/flat_orientation_l2: -0.0385
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.3348
Metrics/base_velocity/error_vel_xy: 0.5853
Metrics/base_velocity/error_vel_yaw: 0.5219
      Episode_Termination/time_out: 0.8344
  Episode_Termination/base_contact: 0.1656
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 2.58s
                      Time elapsed: 00:16:36
                               ETA: 00:03:41

################################################################################
                      [1m Learning iteration 410/500 [0m                      

                       Computation: 38285 steps/s (collection: 2.423s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0129
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 11.4968
                       Mean reward: 9.22
               Mean episode length: 909.21
Episode_Reward/track_lin_vel_xy_exp: 0.5856
Episode_Reward/track_ang_vel_z_exp: 0.3155
       Episode_Reward/lin_vel_z_l2: -0.0342
      Episode_Reward/ang_vel_xy_l2: -0.0902
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1354
     Episode_Reward/action_rate_l2: -0.1212
      Episode_Reward/feet_air_time: -0.0171
Episode_Reward/flat_orientation_l2: -0.0361
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.3437
Metrics/base_velocity/error_vel_xy: 0.6481
Metrics/base_velocity/error_vel_yaw: 0.5352
      Episode_Termination/time_out: 0.8351
  Episode_Termination/base_contact: 0.1649
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 2.57s
                      Time elapsed: 00:16:38
                               ETA: 00:03:38

################################################################################
                      [1m Learning iteration 411/500 [0m                      

                       Computation: 38166 steps/s (collection: 2.431s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0140
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 11.5066
                       Mean reward: 10.00
               Mean episode length: 910.86
Episode_Reward/track_lin_vel_xy_exp: 0.6467
Episode_Reward/track_ang_vel_z_exp: 0.3281
       Episode_Reward/lin_vel_z_l2: -0.0363
      Episode_Reward/ang_vel_xy_l2: -0.0924
     Episode_Reward/dof_torques_l2: -0.0043
         Episode_Reward/dof_acc_l2: -0.1416
     Episode_Reward/action_rate_l2: -0.1253
      Episode_Reward/feet_air_time: -0.0175
Episode_Reward/flat_orientation_l2: -0.0416
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.3529
Metrics/base_velocity/error_vel_xy: 0.5715
Metrics/base_velocity/error_vel_yaw: 0.5285
      Episode_Termination/time_out: 0.8361
  Episode_Termination/base_contact: 0.1639
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 2.58s
                      Time elapsed: 00:16:41
                               ETA: 00:03:36

################################################################################
                      [1m Learning iteration 412/500 [0m                      

                       Computation: 38542 steps/s (collection: 2.406s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0124
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 11.5096
                       Mean reward: 10.34
               Mean episode length: 899.83
Episode_Reward/track_lin_vel_xy_exp: 0.6386
Episode_Reward/track_ang_vel_z_exp: 0.3209
       Episode_Reward/lin_vel_z_l2: -0.0356
      Episode_Reward/ang_vel_xy_l2: -0.0918
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1363
     Episode_Reward/action_rate_l2: -0.1232
      Episode_Reward/feet_air_time: -0.0171
Episode_Reward/flat_orientation_l2: -0.0338
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.3594
Metrics/base_velocity/error_vel_xy: 0.5509
Metrics/base_velocity/error_vel_yaw: 0.5250
      Episode_Termination/time_out: 0.8351
  Episode_Termination/base_contact: 0.1649
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 2.55s
                      Time elapsed: 00:16:43
                               ETA: 00:03:33

################################################################################
                      [1m Learning iteration 413/500 [0m                      

                       Computation: 38305 steps/s (collection: 2.420s, learning 0.147s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0138
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 11.5027
                       Mean reward: 9.71
               Mean episode length: 836.41
Episode_Reward/track_lin_vel_xy_exp: 0.5825
Episode_Reward/track_ang_vel_z_exp: 0.2989
       Episode_Reward/lin_vel_z_l2: -0.0346
      Episode_Reward/ang_vel_xy_l2: -0.0849
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1272
     Episode_Reward/action_rate_l2: -0.1133
      Episode_Reward/feet_air_time: -0.0162
Episode_Reward/flat_orientation_l2: -0.0384
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.3690
Metrics/base_velocity/error_vel_xy: 0.5292
Metrics/base_velocity/error_vel_yaw: 0.4779
      Episode_Termination/time_out: 0.8327
  Episode_Termination/base_contact: 0.1673
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 2.57s
                      Time elapsed: 00:16:46
                               ETA: 00:03:31

################################################################################
                      [1m Learning iteration 414/500 [0m                      

                       Computation: 38439 steps/s (collection: 2.414s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0131
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 11.5134
                       Mean reward: 10.16
               Mean episode length: 859.15
Episode_Reward/track_lin_vel_xy_exp: 0.6151
Episode_Reward/track_ang_vel_z_exp: 0.3073
       Episode_Reward/lin_vel_z_l2: -0.0338
      Episode_Reward/ang_vel_xy_l2: -0.0864
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1290
     Episode_Reward/action_rate_l2: -0.1167
      Episode_Reward/feet_air_time: -0.0166
Episode_Reward/flat_orientation_l2: -0.0360
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.3777
Metrics/base_velocity/error_vel_xy: 0.5147
Metrics/base_velocity/error_vel_yaw: 0.4918
      Episode_Termination/time_out: 0.8320
  Episode_Termination/base_contact: 0.1680
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 2.56s
                      Time elapsed: 00:16:49
                               ETA: 00:03:29

################################################################################
                      [1m Learning iteration 415/500 [0m                      

                       Computation: 38781 steps/s (collection: 2.389s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0124
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 11.5195
                       Mean reward: 9.27
               Mean episode length: 909.66
Episode_Reward/track_lin_vel_xy_exp: 0.5853
Episode_Reward/track_ang_vel_z_exp: 0.3273
       Episode_Reward/lin_vel_z_l2: -0.0346
      Episode_Reward/ang_vel_xy_l2: -0.0943
     Episode_Reward/dof_torques_l2: -0.0043
         Episode_Reward/dof_acc_l2: -0.1315
     Episode_Reward/action_rate_l2: -0.1247
      Episode_Reward/feet_air_time: -0.0176
Episode_Reward/flat_orientation_l2: -0.0437
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.3859
Metrics/base_velocity/error_vel_xy: 0.7106
Metrics/base_velocity/error_vel_yaw: 0.5653
      Episode_Termination/time_out: 0.8327
  Episode_Termination/base_contact: 0.1673
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 2.53s
                      Time elapsed: 00:16:51
                               ETA: 00:03:26

################################################################################
                      [1m Learning iteration 416/500 [0m                      

                       Computation: 38379 steps/s (collection: 2.418s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0122
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 11.5117
                       Mean reward: 9.61
               Mean episode length: 898.44
Episode_Reward/track_lin_vel_xy_exp: 0.5771
Episode_Reward/track_ang_vel_z_exp: 0.3113
       Episode_Reward/lin_vel_z_l2: -0.0335
      Episode_Reward/ang_vel_xy_l2: -0.0868
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1251
     Episode_Reward/action_rate_l2: -0.1181
      Episode_Reward/feet_air_time: -0.0166
Episode_Reward/flat_orientation_l2: -0.0368
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.3916
Metrics/base_velocity/error_vel_xy: 0.6268
Metrics/base_velocity/error_vel_yaw: 0.5116
      Episode_Termination/time_out: 0.8330
  Episode_Termination/base_contact: 0.1670
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 2.56s
                      Time elapsed: 00:16:54
                               ETA: 00:03:24

################################################################################
                      [1m Learning iteration 417/500 [0m                      

                       Computation: 38427 steps/s (collection: 2.414s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0127
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 11.5134
                       Mean reward: 11.09
               Mean episode length: 956.41
Episode_Reward/track_lin_vel_xy_exp: 0.7055
Episode_Reward/track_ang_vel_z_exp: 0.3461
       Episode_Reward/lin_vel_z_l2: -0.0388
      Episode_Reward/ang_vel_xy_l2: -0.0989
     Episode_Reward/dof_torques_l2: -0.0045
         Episode_Reward/dof_acc_l2: -0.1524
     Episode_Reward/action_rate_l2: -0.1331
      Episode_Reward/feet_air_time: -0.0191
Episode_Reward/flat_orientation_l2: -0.0391
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.3997
Metrics/base_velocity/error_vel_xy: 0.5656
Metrics/base_velocity/error_vel_yaw: 0.5546
      Episode_Termination/time_out: 0.8339
  Episode_Termination/base_contact: 0.1661
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 2.56s
                      Time elapsed: 00:16:56
                               ETA: 00:03:21

################################################################################
                      [1m Learning iteration 418/500 [0m                      

                       Computation: 38433 steps/s (collection: 2.413s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0136
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 11.5224
                       Mean reward: 10.64
               Mean episode length: 942.26
Episode_Reward/track_lin_vel_xy_exp: 0.6697
Episode_Reward/track_ang_vel_z_exp: 0.3373
       Episode_Reward/lin_vel_z_l2: -0.0347
      Episode_Reward/ang_vel_xy_l2: -0.0947
     Episode_Reward/dof_torques_l2: -0.0044
         Episode_Reward/dof_acc_l2: -0.1366
     Episode_Reward/action_rate_l2: -0.1271
      Episode_Reward/feet_air_time: -0.0180
Episode_Reward/flat_orientation_l2: -0.0340
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.4084
Metrics/base_velocity/error_vel_xy: 0.5846
Metrics/base_velocity/error_vel_yaw: 0.5496
      Episode_Termination/time_out: 0.8346
  Episode_Termination/base_contact: 0.1654
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 2.56s
                      Time elapsed: 00:16:59
                               ETA: 00:03:19

################################################################################
                      [1m Learning iteration 419/500 [0m                      

                       Computation: 38738 steps/s (collection: 2.394s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0125
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 11.5376
                       Mean reward: 10.25
               Mean episode length: 902.80
Episode_Reward/track_lin_vel_xy_exp: 0.6200
Episode_Reward/track_ang_vel_z_exp: 0.3140
       Episode_Reward/lin_vel_z_l2: -0.0348
      Episode_Reward/ang_vel_xy_l2: -0.0871
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1329
     Episode_Reward/action_rate_l2: -0.1204
      Episode_Reward/feet_air_time: -0.0174
Episode_Reward/flat_orientation_l2: -0.0396
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.4150
Metrics/base_velocity/error_vel_xy: 0.5535
Metrics/base_velocity/error_vel_yaw: 0.5077
      Episode_Termination/time_out: 0.8350
  Episode_Termination/base_contact: 0.1650
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 2.54s
                      Time elapsed: 00:17:01
                               ETA: 00:03:17

################################################################################
                      [1m Learning iteration 420/500 [0m                      

                       Computation: 38276 steps/s (collection: 2.423s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0148
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 11.5497
                       Mean reward: 10.86
               Mean episode length: 886.17
Episode_Reward/track_lin_vel_xy_exp: 0.7123
Episode_Reward/track_ang_vel_z_exp: 0.3373
       Episode_Reward/lin_vel_z_l2: -0.0343
      Episode_Reward/ang_vel_xy_l2: -0.0939
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1394
     Episode_Reward/action_rate_l2: -0.1247
      Episode_Reward/feet_air_time: -0.0172
Episode_Reward/flat_orientation_l2: -0.0346
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.4213
Metrics/base_velocity/error_vel_xy: 0.4696
Metrics/base_velocity/error_vel_yaw: 0.5031
      Episode_Termination/time_out: 0.8346
  Episode_Termination/base_contact: 0.1654
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 2.57s
                      Time elapsed: 00:17:04
                               ETA: 00:03:14

################################################################################
                      [1m Learning iteration 421/500 [0m                      

                       Computation: 38431 steps/s (collection: 2.413s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0148
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 11.5534
                       Mean reward: 9.46
               Mean episode length: 875.44
Episode_Reward/track_lin_vel_xy_exp: 0.5419
Episode_Reward/track_ang_vel_z_exp: 0.2854
       Episode_Reward/lin_vel_z_l2: -0.0325
      Episode_Reward/ang_vel_xy_l2: -0.0831
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1212
     Episode_Reward/action_rate_l2: -0.1088
      Episode_Reward/feet_air_time: -0.0155
Episode_Reward/flat_orientation_l2: -0.0381
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.4274
Metrics/base_velocity/error_vel_xy: 0.5573
Metrics/base_velocity/error_vel_yaw: 0.4778
      Episode_Termination/time_out: 0.8352
  Episode_Termination/base_contact: 0.1648
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 2.56s
                      Time elapsed: 00:17:06
                               ETA: 00:03:12

################################################################################
                      [1m Learning iteration 422/500 [0m                      

                       Computation: 38342 steps/s (collection: 2.419s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0136
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 11.5554
                       Mean reward: 9.66
               Mean episode length: 895.67
Episode_Reward/track_lin_vel_xy_exp: 0.6298
Episode_Reward/track_ang_vel_z_exp: 0.3284
       Episode_Reward/lin_vel_z_l2: -0.0359
      Episode_Reward/ang_vel_xy_l2: -0.0934
     Episode_Reward/dof_torques_l2: -0.0043
         Episode_Reward/dof_acc_l2: -0.1391
     Episode_Reward/action_rate_l2: -0.1260
      Episode_Reward/feet_air_time: -0.0177
Episode_Reward/flat_orientation_l2: -0.0380
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.4354
Metrics/base_velocity/error_vel_xy: 0.6054
Metrics/base_velocity/error_vel_yaw: 0.5273
      Episode_Termination/time_out: 0.8342
  Episode_Termination/base_contact: 0.1658
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 2.56s
                      Time elapsed: 00:17:09
                               ETA: 00:03:09

################################################################################
                      [1m Learning iteration 423/500 [0m                      

                       Computation: 38134 steps/s (collection: 2.433s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0125
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 11.5432
                       Mean reward: 9.85
               Mean episode length: 901.53
Episode_Reward/track_lin_vel_xy_exp: 0.6029
Episode_Reward/track_ang_vel_z_exp: 0.3219
       Episode_Reward/lin_vel_z_l2: -0.0347
      Episode_Reward/ang_vel_xy_l2: -0.0913
     Episode_Reward/dof_torques_l2: -0.0043
         Episode_Reward/dof_acc_l2: -0.1336
     Episode_Reward/action_rate_l2: -0.1236
      Episode_Reward/feet_air_time: -0.0174
Episode_Reward/flat_orientation_l2: -0.0354
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.4422
Metrics/base_velocity/error_vel_xy: 0.6559
Metrics/base_velocity/error_vel_yaw: 0.5422
      Episode_Termination/time_out: 0.8339
  Episode_Termination/base_contact: 0.1661
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 2.58s
                      Time elapsed: 00:17:12
                               ETA: 00:03:07

################################################################################
                      [1m Learning iteration 424/500 [0m                      

                       Computation: 38090 steps/s (collection: 2.437s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0128
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 11.5414
                       Mean reward: 10.32
               Mean episode length: 903.01
Episode_Reward/track_lin_vel_xy_exp: 0.6111
Episode_Reward/track_ang_vel_z_exp: 0.3136
       Episode_Reward/lin_vel_z_l2: -0.0341
      Episode_Reward/ang_vel_xy_l2: -0.0882
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1319
     Episode_Reward/action_rate_l2: -0.1195
      Episode_Reward/feet_air_time: -0.0169
Episode_Reward/flat_orientation_l2: -0.0391
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.4488
Metrics/base_velocity/error_vel_xy: 0.5693
Metrics/base_velocity/error_vel_yaw: 0.5106
      Episode_Termination/time_out: 0.8343
  Episode_Termination/base_contact: 0.1657
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 2.58s
                      Time elapsed: 00:17:14
                               ETA: 00:03:05

################################################################################
                      [1m Learning iteration 425/500 [0m                      

                       Computation: 38007 steps/s (collection: 2.444s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0150
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 11.5336
                       Mean reward: 10.10
               Mean episode length: 891.79
Episode_Reward/track_lin_vel_xy_exp: 0.6433
Episode_Reward/track_ang_vel_z_exp: 0.3264
       Episode_Reward/lin_vel_z_l2: -0.0360
      Episode_Reward/ang_vel_xy_l2: -0.0931
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1387
     Episode_Reward/action_rate_l2: -0.1243
      Episode_Reward/feet_air_time: -0.0178
Episode_Reward/flat_orientation_l2: -0.0358
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.4586
Metrics/base_velocity/error_vel_xy: 0.5815
Metrics/base_velocity/error_vel_yaw: 0.5371
      Episode_Termination/time_out: 0.8341
  Episode_Termination/base_contact: 0.1659
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 2.59s
                      Time elapsed: 00:17:17
                               ETA: 00:03:02

################################################################################
                      [1m Learning iteration 426/500 [0m                      

                       Computation: 37984 steps/s (collection: 2.443s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0130
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 11.5360
                       Mean reward: 9.71
               Mean episode length: 878.64
Episode_Reward/track_lin_vel_xy_exp: 0.5822
Episode_Reward/track_ang_vel_z_exp: 0.2951
       Episode_Reward/lin_vel_z_l2: -0.0334
      Episode_Reward/ang_vel_xy_l2: -0.0838
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1303
     Episode_Reward/action_rate_l2: -0.1136
      Episode_Reward/feet_air_time: -0.0158
Episode_Reward/flat_orientation_l2: -0.0379
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.4660
Metrics/base_velocity/error_vel_xy: 0.5403
Metrics/base_velocity/error_vel_yaw: 0.4992
      Episode_Termination/time_out: 0.8313
  Episode_Termination/base_contact: 0.1687
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 2.59s
                      Time elapsed: 00:17:19
                               ETA: 00:03:00

################################################################################
                      [1m Learning iteration 427/500 [0m                      

                       Computation: 38063 steps/s (collection: 2.436s, learning 0.147s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0164
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 11.5396
                       Mean reward: 10.39
               Mean episode length: 931.32
Episode_Reward/track_lin_vel_xy_exp: 0.6340
Episode_Reward/track_ang_vel_z_exp: 0.3340
       Episode_Reward/lin_vel_z_l2: -0.0349
      Episode_Reward/ang_vel_xy_l2: -0.0942
     Episode_Reward/dof_torques_l2: -0.0043
         Episode_Reward/dof_acc_l2: -0.1425
     Episode_Reward/action_rate_l2: -0.1271
      Episode_Reward/feet_air_time: -0.0177
Episode_Reward/flat_orientation_l2: -0.0420
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.4754
Metrics/base_velocity/error_vel_xy: 0.6546
Metrics/base_velocity/error_vel_yaw: 0.5582
      Episode_Termination/time_out: 0.8309
  Episode_Termination/base_contact: 0.1691
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 2.58s
                      Time elapsed: 00:17:22
                               ETA: 00:02:57

################################################################################
                      [1m Learning iteration 428/500 [0m                      

                       Computation: 37801 steps/s (collection: 2.452s, learning 0.148s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0147
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 11.5448
                       Mean reward: 9.67
               Mean episode length: 851.44
Episode_Reward/track_lin_vel_xy_exp: 0.5970
Episode_Reward/track_ang_vel_z_exp: 0.2995
       Episode_Reward/lin_vel_z_l2: -0.0346
      Episode_Reward/ang_vel_xy_l2: -0.0868
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1331
     Episode_Reward/action_rate_l2: -0.1175
      Episode_Reward/feet_air_time: -0.0166
Episode_Reward/flat_orientation_l2: -0.0369
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.4828
Metrics/base_velocity/error_vel_xy: 0.5353
Metrics/base_velocity/error_vel_yaw: 0.5142
      Episode_Termination/time_out: 0.8308
  Episode_Termination/base_contact: 0.1692
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 2.60s
                      Time elapsed: 00:17:24
                               ETA: 00:02:55

################################################################################
                      [1m Learning iteration 429/500 [0m                      

                       Computation: 38097 steps/s (collection: 2.436s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0134
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 11.5333
                       Mean reward: 9.35
               Mean episode length: 838.27
Episode_Reward/track_lin_vel_xy_exp: 0.6233
Episode_Reward/track_ang_vel_z_exp: 0.3077
       Episode_Reward/lin_vel_z_l2: -0.0348
      Episode_Reward/ang_vel_xy_l2: -0.0891
     Episode_Reward/dof_torques_l2: -0.0038
         Episode_Reward/dof_acc_l2: -0.1375
     Episode_Reward/action_rate_l2: -0.1183
      Episode_Reward/feet_air_time: -0.0171
Episode_Reward/flat_orientation_l2: -0.0407
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.4892
Metrics/base_velocity/error_vel_xy: 0.5022
Metrics/base_velocity/error_vel_yaw: 0.4845
      Episode_Termination/time_out: 0.8306
  Episode_Termination/base_contact: 0.1694
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 2.58s
                      Time elapsed: 00:17:27
                               ETA: 00:02:52

################################################################################
                      [1m Learning iteration 430/500 [0m                      

                       Computation: 37943 steps/s (collection: 2.445s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0152
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 11.5462
                       Mean reward: 9.52
               Mean episode length: 853.98
Episode_Reward/track_lin_vel_xy_exp: 0.5905
Episode_Reward/track_ang_vel_z_exp: 0.3021
       Episode_Reward/lin_vel_z_l2: -0.0349
      Episode_Reward/ang_vel_xy_l2: -0.0869
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1366
     Episode_Reward/action_rate_l2: -0.1174
      Episode_Reward/feet_air_time: -0.0165
Episode_Reward/flat_orientation_l2: -0.0471
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.4987
Metrics/base_velocity/error_vel_xy: 0.5631
Metrics/base_velocity/error_vel_yaw: 0.5154
      Episode_Termination/time_out: 0.8277
  Episode_Termination/base_contact: 0.1723
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 2.59s
                      Time elapsed: 00:17:30
                               ETA: 00:02:50

################################################################################
                      [1m Learning iteration 431/500 [0m                      

                       Computation: 38168 steps/s (collection: 2.430s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0124
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 11.5378
                       Mean reward: 8.97
               Mean episode length: 846.13
Episode_Reward/track_lin_vel_xy_exp: 0.5534
Episode_Reward/track_ang_vel_z_exp: 0.2945
       Episode_Reward/lin_vel_z_l2: -0.0336
      Episode_Reward/ang_vel_xy_l2: -0.0850
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1317
     Episode_Reward/action_rate_l2: -0.1168
      Episode_Reward/feet_air_time: -0.0164
Episode_Reward/flat_orientation_l2: -0.0357
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.5051
Metrics/base_velocity/error_vel_xy: 0.6145
Metrics/base_velocity/error_vel_yaw: 0.5287
      Episode_Termination/time_out: 0.8267
  Episode_Termination/base_contact: 0.1733
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 2.58s
                      Time elapsed: 00:17:32
                               ETA: 00:02:48

################################################################################
                      [1m Learning iteration 432/500 [0m                      

                       Computation: 38281 steps/s (collection: 2.424s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0145
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 11.5389
                       Mean reward: 9.25
               Mean episode length: 892.10
Episode_Reward/track_lin_vel_xy_exp: 0.6105
Episode_Reward/track_ang_vel_z_exp: 0.3186
       Episode_Reward/lin_vel_z_l2: -0.0354
      Episode_Reward/ang_vel_xy_l2: -0.0917
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1408
     Episode_Reward/action_rate_l2: -0.1234
      Episode_Reward/feet_air_time: -0.0169
Episode_Reward/flat_orientation_l2: -0.0482
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.5122
Metrics/base_velocity/error_vel_xy: 0.6124
Metrics/base_velocity/error_vel_yaw: 0.5462
      Episode_Termination/time_out: 0.8256
  Episode_Termination/base_contact: 0.1744
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 2.57s
                      Time elapsed: 00:17:35
                               ETA: 00:02:45

################################################################################
                      [1m Learning iteration 433/500 [0m                      

                       Computation: 38408 steps/s (collection: 2.416s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0144
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 11.5433
                       Mean reward: 10.69
               Mean episode length: 880.88
Episode_Reward/track_lin_vel_xy_exp: 0.6085
Episode_Reward/track_ang_vel_z_exp: 0.3074
       Episode_Reward/lin_vel_z_l2: -0.0320
      Episode_Reward/ang_vel_xy_l2: -0.0856
     Episode_Reward/dof_torques_l2: -0.0038
         Episode_Reward/dof_acc_l2: -0.1190
     Episode_Reward/action_rate_l2: -0.1146
      Episode_Reward/feet_air_time: -0.0165
Episode_Reward/flat_orientation_l2: -0.0406
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.5215
Metrics/base_velocity/error_vel_xy: 0.5276
Metrics/base_velocity/error_vel_yaw: 0.4870
      Episode_Termination/time_out: 0.8244
  Episode_Termination/base_contact: 0.1756
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 2.56s
                      Time elapsed: 00:17:37
                               ETA: 00:02:43

################################################################################
                      [1m Learning iteration 434/500 [0m                      

                       Computation: 38327 steps/s (collection: 2.418s, learning 0.147s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0128
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 11.5361
                       Mean reward: 8.99
               Mean episode length: 848.90
Episode_Reward/track_lin_vel_xy_exp: 0.5800
Episode_Reward/track_ang_vel_z_exp: 0.2949
       Episode_Reward/lin_vel_z_l2: -0.0347
      Episode_Reward/ang_vel_xy_l2: -0.0852
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1302
     Episode_Reward/action_rate_l2: -0.1149
      Episode_Reward/feet_air_time: -0.0156
Episode_Reward/flat_orientation_l2: -0.0402
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.5316
Metrics/base_velocity/error_vel_xy: 0.5394
Metrics/base_velocity/error_vel_yaw: 0.5013
      Episode_Termination/time_out: 0.8247
  Episode_Termination/base_contact: 0.1753
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 2.56s
                      Time elapsed: 00:17:40
                               ETA: 00:02:40

################################################################################
                      [1m Learning iteration 435/500 [0m                      

                       Computation: 38603 steps/s (collection: 2.402s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0135
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 11.5411
                       Mean reward: 9.71
               Mean episode length: 837.94
Episode_Reward/track_lin_vel_xy_exp: 0.5754
Episode_Reward/track_ang_vel_z_exp: 0.2932
       Episode_Reward/lin_vel_z_l2: -0.0318
      Episode_Reward/ang_vel_xy_l2: -0.0837
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1252
     Episode_Reward/action_rate_l2: -0.1110
      Episode_Reward/feet_air_time: -0.0157
Episode_Reward/flat_orientation_l2: -0.0370
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.5397
Metrics/base_velocity/error_vel_xy: 0.5280
Metrics/base_velocity/error_vel_yaw: 0.4769
      Episode_Termination/time_out: 0.8254
  Episode_Termination/base_contact: 0.1746
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 2.55s
                      Time elapsed: 00:17:42
                               ETA: 00:02:38

################################################################################
                      [1m Learning iteration 436/500 [0m                      

                       Computation: 38487 steps/s (collection: 2.408s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0135
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 11.5398
                       Mean reward: 11.18
               Mean episode length: 920.60
Episode_Reward/track_lin_vel_xy_exp: 0.6530
Episode_Reward/track_ang_vel_z_exp: 0.3195
       Episode_Reward/lin_vel_z_l2: -0.0337
      Episode_Reward/ang_vel_xy_l2: -0.0885
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1329
     Episode_Reward/action_rate_l2: -0.1219
      Episode_Reward/feet_air_time: -0.0165
Episode_Reward/flat_orientation_l2: -0.0339
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.5474
Metrics/base_velocity/error_vel_xy: 0.5157
Metrics/base_velocity/error_vel_yaw: 0.5132
      Episode_Termination/time_out: 0.8261
  Episode_Termination/base_contact: 0.1739
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 2.55s
                      Time elapsed: 00:17:45
                               ETA: 00:02:36

################################################################################
                      [1m Learning iteration 437/500 [0m                      

                       Computation: 38467 steps/s (collection: 2.413s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0131
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 11.5416
                       Mean reward: 10.11
               Mean episode length: 869.87
Episode_Reward/track_lin_vel_xy_exp: 0.6345
Episode_Reward/track_ang_vel_z_exp: 0.3111
       Episode_Reward/lin_vel_z_l2: -0.0335
      Episode_Reward/ang_vel_xy_l2: -0.0853
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1292
     Episode_Reward/action_rate_l2: -0.1177
      Episode_Reward/feet_air_time: -0.0160
Episode_Reward/flat_orientation_l2: -0.0367
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.5582
Metrics/base_velocity/error_vel_xy: 0.5075
Metrics/base_velocity/error_vel_yaw: 0.4976
      Episode_Termination/time_out: 0.8273
  Episode_Termination/base_contact: 0.1727
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 2.56s
                      Time elapsed: 00:17:48
                               ETA: 00:02:33

################################################################################
                      [1m Learning iteration 438/500 [0m                      

                       Computation: 38495 steps/s (collection: 2.410s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0129
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 11.5427
                       Mean reward: 9.98
               Mean episode length: 907.18
Episode_Reward/track_lin_vel_xy_exp: 0.6462
Episode_Reward/track_ang_vel_z_exp: 0.3243
       Episode_Reward/lin_vel_z_l2: -0.0378
      Episode_Reward/ang_vel_xy_l2: -0.0929
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1449
     Episode_Reward/action_rate_l2: -0.1252
      Episode_Reward/feet_air_time: -0.0172
Episode_Reward/flat_orientation_l2: -0.0386
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.5671
Metrics/base_velocity/error_vel_xy: 0.5640
Metrics/base_velocity/error_vel_yaw: 0.5384
      Episode_Termination/time_out: 0.8286
  Episode_Termination/base_contact: 0.1714
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 2.55s
                      Time elapsed: 00:17:50
                               ETA: 00:02:31

################################################################################
                      [1m Learning iteration 439/500 [0m                      

                       Computation: 38462 steps/s (collection: 2.412s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0136
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 11.5393
                       Mean reward: 10.37
               Mean episode length: 897.58
Episode_Reward/track_lin_vel_xy_exp: 0.6525
Episode_Reward/track_ang_vel_z_exp: 0.3195
       Episode_Reward/lin_vel_z_l2: -0.0365
      Episode_Reward/ang_vel_xy_l2: -0.0925
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1452
     Episode_Reward/action_rate_l2: -0.1251
      Episode_Reward/feet_air_time: -0.0172
Episode_Reward/flat_orientation_l2: -0.0411
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.5773
Metrics/base_velocity/error_vel_xy: 0.5289
Metrics/base_velocity/error_vel_yaw: 0.5372
      Episode_Termination/time_out: 0.8283
  Episode_Termination/base_contact: 0.1717
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 2.56s
                      Time elapsed: 00:17:53
                               ETA: 00:02:28

################################################################################
                      [1m Learning iteration 440/500 [0m                      

                       Computation: 38433 steps/s (collection: 2.414s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0162
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 11.5410
                       Mean reward: 10.42
               Mean episode length: 864.87
Episode_Reward/track_lin_vel_xy_exp: 0.6183
Episode_Reward/track_ang_vel_z_exp: 0.3026
       Episode_Reward/lin_vel_z_l2: -0.0341
      Episode_Reward/ang_vel_xy_l2: -0.0847
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1294
     Episode_Reward/action_rate_l2: -0.1155
      Episode_Reward/feet_air_time: -0.0158
Episode_Reward/flat_orientation_l2: -0.0352
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.5875
Metrics/base_velocity/error_vel_xy: 0.4810
Metrics/base_velocity/error_vel_yaw: 0.4717
      Episode_Termination/time_out: 0.8271
  Episode_Termination/base_contact: 0.1729
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 2.56s
                      Time elapsed: 00:17:55
                               ETA: 00:02:26

################################################################################
                      [1m Learning iteration 441/500 [0m                      

                       Computation: 38638 steps/s (collection: 2.400s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0148
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 11.5534
                       Mean reward: 10.14
               Mean episode length: 889.75
Episode_Reward/track_lin_vel_xy_exp: 0.6440
Episode_Reward/track_ang_vel_z_exp: 0.3199
       Episode_Reward/lin_vel_z_l2: -0.0357
      Episode_Reward/ang_vel_xy_l2: -0.0905
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1389
     Episode_Reward/action_rate_l2: -0.1236
      Episode_Reward/feet_air_time: -0.0173
Episode_Reward/flat_orientation_l2: -0.0386
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.6000
Metrics/base_velocity/error_vel_xy: 0.5506
Metrics/base_velocity/error_vel_yaw: 0.5285
      Episode_Termination/time_out: 0.8281
  Episode_Termination/base_contact: 0.1719
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 2.54s
                      Time elapsed: 00:17:58
                               ETA: 00:02:23

################################################################################
                      [1m Learning iteration 442/500 [0m                      

                       Computation: 37908 steps/s (collection: 2.449s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0135
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 11.5446
                       Mean reward: 9.36
               Mean episode length: 868.97
Episode_Reward/track_lin_vel_xy_exp: 0.6103
Episode_Reward/track_ang_vel_z_exp: 0.3047
       Episode_Reward/lin_vel_z_l2: -0.0367
      Episode_Reward/ang_vel_xy_l2: -0.0882
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1351
     Episode_Reward/action_rate_l2: -0.1195
      Episode_Reward/feet_air_time: -0.0163
Episode_Reward/flat_orientation_l2: -0.0402
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.6093
Metrics/base_velocity/error_vel_xy: 0.5481
Metrics/base_velocity/error_vel_yaw: 0.5406
      Episode_Termination/time_out: 0.8291
  Episode_Termination/base_contact: 0.1709
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 2.59s
                      Time elapsed: 00:18:00
                               ETA: 00:02:21

################################################################################
                      [1m Learning iteration 443/500 [0m                      

                       Computation: 38601 steps/s (collection: 2.402s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0142
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 11.5436
                       Mean reward: 9.33
               Mean episode length: 879.01
Episode_Reward/track_lin_vel_xy_exp: 0.5949
Episode_Reward/track_ang_vel_z_exp: 0.2973
       Episode_Reward/lin_vel_z_l2: -0.0350
      Episode_Reward/ang_vel_xy_l2: -0.0849
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1297
     Episode_Reward/action_rate_l2: -0.1157
      Episode_Reward/feet_air_time: -0.0159
Episode_Reward/flat_orientation_l2: -0.0723
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.6172
Metrics/base_velocity/error_vel_xy: 0.5258
Metrics/base_velocity/error_vel_yaw: 0.5010
      Episode_Termination/time_out: 0.8301
  Episode_Termination/base_contact: 0.1699
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 2.55s
                      Time elapsed: 00:18:03
                               ETA: 00:02:19

################################################################################
                      [1m Learning iteration 444/500 [0m                      

                       Computation: 38940 steps/s (collection: 2.379s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0126
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 11.5482
                       Mean reward: 9.57
               Mean episode length: 849.86
Episode_Reward/track_lin_vel_xy_exp: 0.5896
Episode_Reward/track_ang_vel_z_exp: 0.2993
       Episode_Reward/lin_vel_z_l2: -0.0339
      Episode_Reward/ang_vel_xy_l2: -0.0845
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1285
     Episode_Reward/action_rate_l2: -0.1146
      Episode_Reward/feet_air_time: -0.0163
Episode_Reward/flat_orientation_l2: -0.0376
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.6256
Metrics/base_velocity/error_vel_xy: 0.5415
Metrics/base_velocity/error_vel_yaw: 0.5143
      Episode_Termination/time_out: 0.8309
  Episode_Termination/base_contact: 0.1691
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 2.52s
                      Time elapsed: 00:18:05
                               ETA: 00:02:16

################################################################################
                      [1m Learning iteration 445/500 [0m                      

                       Computation: 38582 steps/s (collection: 2.404s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0151
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 11.5556
                       Mean reward: 9.72
               Mean episode length: 884.82
Episode_Reward/track_lin_vel_xy_exp: 0.6129
Episode_Reward/track_ang_vel_z_exp: 0.3101
       Episode_Reward/lin_vel_z_l2: -0.0347
      Episode_Reward/ang_vel_xy_l2: -0.0894
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1443
     Episode_Reward/action_rate_l2: -0.1203
      Episode_Reward/feet_air_time: -0.0165
Episode_Reward/flat_orientation_l2: -0.0449
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.6332
Metrics/base_velocity/error_vel_xy: 0.5595
Metrics/base_velocity/error_vel_yaw: 0.5155
      Episode_Termination/time_out: 0.8292
  Episode_Termination/base_contact: 0.1708
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 2.55s
                      Time elapsed: 00:18:08
                               ETA: 00:02:14

################################################################################
                      [1m Learning iteration 446/500 [0m                      

                       Computation: 38491 steps/s (collection: 2.408s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0151
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 11.5602
                       Mean reward: 11.46
               Mean episode length: 928.05
Episode_Reward/track_lin_vel_xy_exp: 0.6955
Episode_Reward/track_ang_vel_z_exp: 0.3319
       Episode_Reward/lin_vel_z_l2: -0.0366
      Episode_Reward/ang_vel_xy_l2: -0.0942
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1464
     Episode_Reward/action_rate_l2: -0.1270
      Episode_Reward/feet_air_time: -0.0176
Episode_Reward/flat_orientation_l2: -0.0375
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.6446
Metrics/base_velocity/error_vel_xy: 0.4951
Metrics/base_velocity/error_vel_yaw: 0.5185
      Episode_Termination/time_out: 0.8306
  Episode_Termination/base_contact: 0.1695
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 2.55s
                      Time elapsed: 00:18:11
                               ETA: 00:02:11

################################################################################
                      [1m Learning iteration 447/500 [0m                      

                       Computation: 38385 steps/s (collection: 2.417s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0141
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 11.5614
                       Mean reward: 9.60
               Mean episode length: 853.00
Episode_Reward/track_lin_vel_xy_exp: 0.5987
Episode_Reward/track_ang_vel_z_exp: 0.3030
       Episode_Reward/lin_vel_z_l2: -0.0358
      Episode_Reward/ang_vel_xy_l2: -0.0888
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1327
     Episode_Reward/action_rate_l2: -0.1166
      Episode_Reward/feet_air_time: -0.0161
Episode_Reward/flat_orientation_l2: -0.0462
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.6546
Metrics/base_velocity/error_vel_xy: 0.5366
Metrics/base_velocity/error_vel_yaw: 0.4965
      Episode_Termination/time_out: 0.8305
  Episode_Termination/base_contact: 0.1697
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 2.56s
                      Time elapsed: 00:18:13
                               ETA: 00:02:09

################################################################################
                      [1m Learning iteration 448/500 [0m                      

                       Computation: 38191 steps/s (collection: 2.422s, learning 0.152s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0139
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 11.5471
                       Mean reward: 9.66
               Mean episode length: 920.92
Episode_Reward/track_lin_vel_xy_exp: 0.6232
Episode_Reward/track_ang_vel_z_exp: 0.3219
       Episode_Reward/lin_vel_z_l2: -0.0377
      Episode_Reward/ang_vel_xy_l2: -0.0957
     Episode_Reward/dof_torques_l2: -0.0044
         Episode_Reward/dof_acc_l2: -0.1482
     Episode_Reward/action_rate_l2: -0.1270
      Episode_Reward/feet_air_time: -0.0170
Episode_Reward/flat_orientation_l2: -0.0391
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.6638
Metrics/base_velocity/error_vel_xy: 0.6179
Metrics/base_velocity/error_vel_yaw: 0.5663
      Episode_Termination/time_out: 0.8302
  Episode_Termination/base_contact: 0.1701
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 2.57s
                      Time elapsed: 00:18:16
                               ETA: 00:02:06

################################################################################
                      [1m Learning iteration 449/500 [0m                      

                       Computation: 38785 steps/s (collection: 2.390s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0138
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 11.5434
                       Mean reward: 9.95
               Mean episode length: 888.73
Episode_Reward/track_lin_vel_xy_exp: 0.6208
Episode_Reward/track_ang_vel_z_exp: 0.3161
       Episode_Reward/lin_vel_z_l2: -0.0350
      Episode_Reward/ang_vel_xy_l2: -0.0905
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1357
     Episode_Reward/action_rate_l2: -0.1227
      Episode_Reward/feet_air_time: -0.0166
Episode_Reward/flat_orientation_l2: -0.0372
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.6749
Metrics/base_velocity/error_vel_xy: 0.5778
Metrics/base_velocity/error_vel_yaw: 0.5264
      Episode_Termination/time_out: 0.8313
  Episode_Termination/base_contact: 0.1690
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 2.53s
                      Time elapsed: 00:18:18
                               ETA: 00:02:04

################################################################################
                      [1m Learning iteration 450/500 [0m                      

                       Computation: 38658 steps/s (collection: 2.400s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0145
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 11.5359
                       Mean reward: 10.68
               Mean episode length: 906.00
Episode_Reward/track_lin_vel_xy_exp: 0.6686
Episode_Reward/track_ang_vel_z_exp: 0.3278
       Episode_Reward/lin_vel_z_l2: -0.0363
      Episode_Reward/ang_vel_xy_l2: -0.0931
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1428
     Episode_Reward/action_rate_l2: -0.1253
      Episode_Reward/feet_air_time: -0.0166
Episode_Reward/flat_orientation_l2: -0.0379
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.6836
Metrics/base_velocity/error_vel_xy: 0.5225
Metrics/base_velocity/error_vel_yaw: 0.5149
      Episode_Termination/time_out: 0.8317
  Episode_Termination/base_contact: 0.1685
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 2.54s
                      Time elapsed: 00:18:21
                               ETA: 00:02:02

################################################################################
                      [1m Learning iteration 451/500 [0m                      

                       Computation: 38370 steps/s (collection: 2.417s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0140
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 11.5425
                       Mean reward: 10.08
               Mean episode length: 891.59
Episode_Reward/track_lin_vel_xy_exp: 0.6535
Episode_Reward/track_ang_vel_z_exp: 0.3229
       Episode_Reward/lin_vel_z_l2: -0.0353
      Episode_Reward/ang_vel_xy_l2: -0.0918
     Episode_Reward/dof_torques_l2: -0.0043
         Episode_Reward/dof_acc_l2: -0.1444
     Episode_Reward/action_rate_l2: -0.1254
      Episode_Reward/feet_air_time: -0.0172
Episode_Reward/flat_orientation_l2: -0.0414
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.6924
Metrics/base_velocity/error_vel_xy: 0.5429
Metrics/base_velocity/error_vel_yaw: 0.5220
      Episode_Termination/time_out: 0.8304
  Episode_Termination/base_contact: 0.1699
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 2.56s
                      Time elapsed: 00:18:23
                               ETA: 00:01:59

################################################################################
                      [1m Learning iteration 452/500 [0m                      

                       Computation: 38575 steps/s (collection: 2.404s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0139
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 11.5412
                       Mean reward: 10.22
               Mean episode length: 908.76
Episode_Reward/track_lin_vel_xy_exp: 0.6082
Episode_Reward/track_ang_vel_z_exp: 0.3224
       Episode_Reward/lin_vel_z_l2: -0.0343
      Episode_Reward/ang_vel_xy_l2: -0.0910
     Episode_Reward/dof_torques_l2: -0.0043
         Episode_Reward/dof_acc_l2: -0.1356
     Episode_Reward/action_rate_l2: -0.1224
      Episode_Reward/feet_air_time: -0.0166
Episode_Reward/flat_orientation_l2: -0.0440
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.6999
Metrics/base_velocity/error_vel_xy: 0.6167
Metrics/base_velocity/error_vel_yaw: 0.5233
      Episode_Termination/time_out: 0.8303
  Episode_Termination/base_contact: 0.1700
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 2.55s
                      Time elapsed: 00:18:26
                               ETA: 00:01:57

################################################################################
                      [1m Learning iteration 453/500 [0m                      

                       Computation: 38499 steps/s (collection: 2.409s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0131
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 11.5497
                       Mean reward: 9.93
               Mean episode length: 886.20
Episode_Reward/track_lin_vel_xy_exp: 0.6452
Episode_Reward/track_ang_vel_z_exp: 0.3161
       Episode_Reward/lin_vel_z_l2: -0.0355
      Episode_Reward/ang_vel_xy_l2: -0.0898
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1416
     Episode_Reward/action_rate_l2: -0.1225
      Episode_Reward/feet_air_time: -0.0165
Episode_Reward/flat_orientation_l2: -0.0407
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.7099
Metrics/base_velocity/error_vel_xy: 0.5125
Metrics/base_velocity/error_vel_yaw: 0.5142
      Episode_Termination/time_out: 0.8303
  Episode_Termination/base_contact: 0.1700
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 2.55s
                      Time elapsed: 00:18:28
                               ETA: 00:01:54

################################################################################
                      [1m Learning iteration 454/500 [0m                      

                       Computation: 38283 steps/s (collection: 2.426s, learning 0.142s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0134
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 11.5597
                       Mean reward: 10.01
               Mean episode length: 869.95
Episode_Reward/track_lin_vel_xy_exp: 0.5925
Episode_Reward/track_ang_vel_z_exp: 0.3093
       Episode_Reward/lin_vel_z_l2: -0.0341
      Episode_Reward/ang_vel_xy_l2: -0.0879
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1351
     Episode_Reward/action_rate_l2: -0.1179
      Episode_Reward/feet_air_time: -0.0163
Episode_Reward/flat_orientation_l2: -0.0380
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.7188
Metrics/base_velocity/error_vel_xy: 0.5656
Metrics/base_velocity/error_vel_yaw: 0.4810
      Episode_Termination/time_out: 0.8291
  Episode_Termination/base_contact: 0.1711
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 2.57s
                      Time elapsed: 00:18:31
                               ETA: 00:01:52

################################################################################
                      [1m Learning iteration 455/500 [0m                      

                       Computation: 38878 steps/s (collection: 2.384s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0136
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 11.5833
                       Mean reward: 9.77
               Mean episode length: 909.04
Episode_Reward/track_lin_vel_xy_exp: 0.6352
Episode_Reward/track_ang_vel_z_exp: 0.3208
       Episode_Reward/lin_vel_z_l2: -0.0358
      Episode_Reward/ang_vel_xy_l2: -0.0925
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1348
     Episode_Reward/action_rate_l2: -0.1227
      Episode_Reward/feet_air_time: -0.0167
Episode_Reward/flat_orientation_l2: -0.0477
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.7301
Metrics/base_velocity/error_vel_xy: 0.5561
Metrics/base_velocity/error_vel_yaw: 0.5174
      Episode_Termination/time_out: 0.8301
  Episode_Termination/base_contact: 0.1702
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 2.53s
                      Time elapsed: 00:18:34
                               ETA: 00:01:49

################################################################################
                      [1m Learning iteration 456/500 [0m                      

                       Computation: 38604 steps/s (collection: 2.400s, learning 0.146s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0124
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 11.5880
                       Mean reward: 9.99
               Mean episode length: 902.93
Episode_Reward/track_lin_vel_xy_exp: 0.6476
Episode_Reward/track_ang_vel_z_exp: 0.3252
       Episode_Reward/lin_vel_z_l2: -0.0355
      Episode_Reward/ang_vel_xy_l2: -0.0931
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1381
     Episode_Reward/action_rate_l2: -0.1244
      Episode_Reward/feet_air_time: -0.0166
Episode_Reward/flat_orientation_l2: -0.0433
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.7391
Metrics/base_velocity/error_vel_xy: 0.5668
Metrics/base_velocity/error_vel_yaw: 0.5418
      Episode_Termination/time_out: 0.8304
  Episode_Termination/base_contact: 0.1698
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 2.55s
                      Time elapsed: 00:18:36
                               ETA: 00:01:47

################################################################################
                      [1m Learning iteration 457/500 [0m                      

                       Computation: 38628 steps/s (collection: 2.400s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0124
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 11.5896
                       Mean reward: 9.02
               Mean episode length: 831.19
Episode_Reward/track_lin_vel_xy_exp: 0.5430
Episode_Reward/track_ang_vel_z_exp: 0.2725
       Episode_Reward/lin_vel_z_l2: -0.0318
      Episode_Reward/ang_vel_xy_l2: -0.0808
     Episode_Reward/dof_torques_l2: -0.0035
         Episode_Reward/dof_acc_l2: -0.1270
     Episode_Reward/action_rate_l2: -0.1057
      Episode_Reward/feet_air_time: -0.0139
Episode_Reward/flat_orientation_l2: -0.0377
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.7477
Metrics/base_velocity/error_vel_xy: 0.4771
Metrics/base_velocity/error_vel_yaw: 0.4481
      Episode_Termination/time_out: 0.8295
  Episode_Termination/base_contact: 0.1707
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 2.54s
                      Time elapsed: 00:18:39
                               ETA: 00:01:45

################################################################################
                      [1m Learning iteration 458/500 [0m                      

                       Computation: 38568 steps/s (collection: 2.405s, learning 0.143s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0129
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 11.5903
                       Mean reward: 9.17
               Mean episode length: 852.60
Episode_Reward/track_lin_vel_xy_exp: 0.5971
Episode_Reward/track_ang_vel_z_exp: 0.3110
       Episode_Reward/lin_vel_z_l2: -0.0347
      Episode_Reward/ang_vel_xy_l2: -0.0906
     Episode_Reward/dof_torques_l2: -0.0043
         Episode_Reward/dof_acc_l2: -0.1344
     Episode_Reward/action_rate_l2: -0.1209
      Episode_Reward/feet_air_time: -0.0158
Episode_Reward/flat_orientation_l2: -0.0453
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.7543
Metrics/base_velocity/error_vel_xy: 0.6238
Metrics/base_velocity/error_vel_yaw: 0.5432
      Episode_Termination/time_out: 0.8268
  Episode_Termination/base_contact: 0.1735
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 2.55s
                      Time elapsed: 00:18:41
                               ETA: 00:01:42

################################################################################
                      [1m Learning iteration 459/500 [0m                      

                       Computation: 38712 steps/s (collection: 2.396s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0140
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 11.5907
                       Mean reward: 10.31
               Mean episode length: 877.83
Episode_Reward/track_lin_vel_xy_exp: 0.6519
Episode_Reward/track_ang_vel_z_exp: 0.3104
       Episode_Reward/lin_vel_z_l2: -0.0343
      Episode_Reward/ang_vel_xy_l2: -0.0882
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1397
     Episode_Reward/action_rate_l2: -0.1208
      Episode_Reward/feet_air_time: -0.0155
Episode_Reward/flat_orientation_l2: -0.0341
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.7611
Metrics/base_velocity/error_vel_xy: 0.4737
Metrics/base_velocity/error_vel_yaw: 0.5053
      Episode_Termination/time_out: 0.8240
  Episode_Termination/base_contact: 0.1762
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 2.54s
                      Time elapsed: 00:18:44
                               ETA: 00:01:40

################################################################################
                      [1m Learning iteration 460/500 [0m                      

                       Computation: 38284 steps/s (collection: 2.423s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0127
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 11.5807
                       Mean reward: 9.73
               Mean episode length: 862.93
Episode_Reward/track_lin_vel_xy_exp: 0.6323
Episode_Reward/track_ang_vel_z_exp: 0.3139
       Episode_Reward/lin_vel_z_l2: -0.0345
      Episode_Reward/ang_vel_xy_l2: -0.0910
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1395
     Episode_Reward/action_rate_l2: -0.1208
      Episode_Reward/feet_air_time: -0.0165
Episode_Reward/flat_orientation_l2: -0.0403
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.7713
Metrics/base_velocity/error_vel_xy: 0.5366
Metrics/base_velocity/error_vel_yaw: 0.5061
      Episode_Termination/time_out: 0.8223
  Episode_Termination/base_contact: 0.1780
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 2.57s
                      Time elapsed: 00:18:46
                               ETA: 00:01:37

################################################################################
                      [1m Learning iteration 461/500 [0m                      

                       Computation: 39132 steps/s (collection: 2.368s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0131
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 11.5750
                       Mean reward: 10.32
               Mean episode length: 900.08
Episode_Reward/track_lin_vel_xy_exp: 0.6652
Episode_Reward/track_ang_vel_z_exp: 0.3341
       Episode_Reward/lin_vel_z_l2: -0.0369
      Episode_Reward/ang_vel_xy_l2: -0.0940
     Episode_Reward/dof_torques_l2: -0.0044
         Episode_Reward/dof_acc_l2: -0.1486
     Episode_Reward/action_rate_l2: -0.1281
      Episode_Reward/feet_air_time: -0.0173
Episode_Reward/flat_orientation_l2: -0.0392
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.7817
Metrics/base_velocity/error_vel_xy: 0.5730
Metrics/base_velocity/error_vel_yaw: 0.5225
      Episode_Termination/time_out: 0.8203
  Episode_Termination/base_contact: 0.1799
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 2.51s
                      Time elapsed: 00:18:49
                               ETA: 00:01:35

################################################################################
                      [1m Learning iteration 462/500 [0m                      

                       Computation: 38818 steps/s (collection: 2.383s, learning 0.150s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0143
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 11.5790
                       Mean reward: 10.52
               Mean episode length: 907.37
Episode_Reward/track_lin_vel_xy_exp: 0.6565
Episode_Reward/track_ang_vel_z_exp: 0.3229
       Episode_Reward/lin_vel_z_l2: -0.0358
      Episode_Reward/ang_vel_xy_l2: -0.0941
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1430
     Episode_Reward/action_rate_l2: -0.1236
      Episode_Reward/feet_air_time: -0.0173
Episode_Reward/flat_orientation_l2: -0.0429
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.7901
Metrics/base_velocity/error_vel_xy: 0.5285
Metrics/base_velocity/error_vel_yaw: 0.5169
      Episode_Termination/time_out: 0.8201
  Episode_Termination/base_contact: 0.1801
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 2.53s
                      Time elapsed: 00:18:51
                               ETA: 00:01:32

################################################################################
                      [1m Learning iteration 463/500 [0m                      

                       Computation: 38933 steps/s (collection: 2.381s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0131
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 11.5749
                       Mean reward: 9.56
               Mean episode length: 822.01
Episode_Reward/track_lin_vel_xy_exp: 0.5804
Episode_Reward/track_ang_vel_z_exp: 0.2863
       Episode_Reward/lin_vel_z_l2: -0.0327
      Episode_Reward/ang_vel_xy_l2: -0.0818
     Episode_Reward/dof_torques_l2: -0.0037
         Episode_Reward/dof_acc_l2: -0.1218
     Episode_Reward/action_rate_l2: -0.1094
      Episode_Reward/feet_air_time: -0.0147
Episode_Reward/flat_orientation_l2: -0.0375
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.7969
Metrics/base_velocity/error_vel_xy: 0.4762
Metrics/base_velocity/error_vel_yaw: 0.4601
      Episode_Termination/time_out: 0.8184
  Episode_Termination/base_contact: 0.1818
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 2.52s
                      Time elapsed: 00:18:54
                               ETA: 00:01:30

################################################################################
                      [1m Learning iteration 464/500 [0m                      

                       Computation: 38904 steps/s (collection: 2.380s, learning 0.147s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0123
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 11.5752
                       Mean reward: 8.96
               Mean episode length: 905.80
Episode_Reward/track_lin_vel_xy_exp: 0.6120
Episode_Reward/track_ang_vel_z_exp: 0.3189
       Episode_Reward/lin_vel_z_l2: -0.0362
      Episode_Reward/ang_vel_xy_l2: -0.0929
     Episode_Reward/dof_torques_l2: -0.0043
         Episode_Reward/dof_acc_l2: -0.1501
     Episode_Reward/action_rate_l2: -0.1239
      Episode_Reward/feet_air_time: -0.0171
Episode_Reward/flat_orientation_l2: -0.0439
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.8059
Metrics/base_velocity/error_vel_xy: 0.6149
Metrics/base_velocity/error_vel_yaw: 0.5391
      Episode_Termination/time_out: 0.8177
  Episode_Termination/base_contact: 0.1825
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 2.53s
                      Time elapsed: 00:18:56
                               ETA: 00:01:28

################################################################################
                      [1m Learning iteration 465/500 [0m                      

                       Computation: 39118 steps/s (collection: 2.368s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0134
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 11.5693
                       Mean reward: 10.20
               Mean episode length: 922.28
Episode_Reward/track_lin_vel_xy_exp: 0.6531
Episode_Reward/track_ang_vel_z_exp: 0.3242
       Episode_Reward/lin_vel_z_l2: -0.0370
      Episode_Reward/ang_vel_xy_l2: -0.0923
     Episode_Reward/dof_torques_l2: -0.0044
         Episode_Reward/dof_acc_l2: -0.1434
     Episode_Reward/action_rate_l2: -0.1264
      Episode_Reward/feet_air_time: -0.0169
Episode_Reward/flat_orientation_l2: -0.0473
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.8129
Metrics/base_velocity/error_vel_xy: 0.5502
Metrics/base_velocity/error_vel_yaw: 0.5278
      Episode_Termination/time_out: 0.8165
  Episode_Termination/base_contact: 0.1837
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 2.51s
                      Time elapsed: 00:18:59
                               ETA: 00:01:25

################################################################################
                      [1m Learning iteration 466/500 [0m                      

                       Computation: 39046 steps/s (collection: 2.373s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0138
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 11.5440
                       Mean reward: 9.09
               Mean episode length: 872.54
Episode_Reward/track_lin_vel_xy_exp: 0.5789
Episode_Reward/track_ang_vel_z_exp: 0.3031
       Episode_Reward/lin_vel_z_l2: -0.0342
      Episode_Reward/ang_vel_xy_l2: -0.0879
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1308
     Episode_Reward/action_rate_l2: -0.1173
      Episode_Reward/feet_air_time: -0.0157
Episode_Reward/flat_orientation_l2: -0.0476
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.8184
Metrics/base_velocity/error_vel_xy: 0.5873
Metrics/base_velocity/error_vel_yaw: 0.5137
      Episode_Termination/time_out: 0.8161
  Episode_Termination/base_contact: 0.1841
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 2.52s
                      Time elapsed: 00:19:01
                               ETA: 00:01:23

################################################################################
                      [1m Learning iteration 467/500 [0m                      

                       Computation: 39068 steps/s (collection: 2.372s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0146
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 11.5399
                       Mean reward: 10.33
               Mean episode length: 926.80
Episode_Reward/track_lin_vel_xy_exp: 0.6743
Episode_Reward/track_ang_vel_z_exp: 0.3389
       Episode_Reward/lin_vel_z_l2: -0.0365
      Episode_Reward/ang_vel_xy_l2: -0.0967
     Episode_Reward/dof_torques_l2: -0.0044
         Episode_Reward/dof_acc_l2: -0.1434
     Episode_Reward/action_rate_l2: -0.1291
      Episode_Reward/feet_air_time: -0.0171
Episode_Reward/flat_orientation_l2: -0.0444
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.8276
Metrics/base_velocity/error_vel_xy: 0.5726
Metrics/base_velocity/error_vel_yaw: 0.5335
      Episode_Termination/time_out: 0.8174
  Episode_Termination/base_contact: 0.1828
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 2.52s
                      Time elapsed: 00:19:04
                               ETA: 00:01:20

################################################################################
                      [1m Learning iteration 468/500 [0m                      

                       Computation: 39324 steps/s (collection: 2.356s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0135
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 11.5402
                       Mean reward: 10.27
               Mean episode length: 901.43
Episode_Reward/track_lin_vel_xy_exp: 0.6395
Episode_Reward/track_ang_vel_z_exp: 0.3251
       Episode_Reward/lin_vel_z_l2: -0.0366
      Episode_Reward/ang_vel_xy_l2: -0.0930
     Episode_Reward/dof_torques_l2: -0.0043
         Episode_Reward/dof_acc_l2: -0.1384
     Episode_Reward/action_rate_l2: -0.1258
      Episode_Reward/feet_air_time: -0.0166
Episode_Reward/flat_orientation_l2: -0.0440
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.8396
Metrics/base_velocity/error_vel_xy: 0.5721
Metrics/base_velocity/error_vel_yaw: 0.5336
      Episode_Termination/time_out: 0.8189
  Episode_Termination/base_contact: 0.1813
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 2.50s
                      Time elapsed: 00:19:06
                               ETA: 00:01:18

################################################################################
                      [1m Learning iteration 469/500 [0m                      

                       Computation: 39215 steps/s (collection: 2.357s, learning 0.149s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0125
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 11.5281
                       Mean reward: 10.79
               Mean episode length: 921.43
Episode_Reward/track_lin_vel_xy_exp: 0.6868
Episode_Reward/track_ang_vel_z_exp: 0.3390
       Episode_Reward/lin_vel_z_l2: -0.0391
      Episode_Reward/ang_vel_xy_l2: -0.0984
     Episode_Reward/dof_torques_l2: -0.0043
         Episode_Reward/dof_acc_l2: -0.1620
     Episode_Reward/action_rate_l2: -0.1310
      Episode_Reward/feet_air_time: -0.0172
Episode_Reward/flat_orientation_l2: -0.0433
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.8524
Metrics/base_velocity/error_vel_xy: 0.5556
Metrics/base_velocity/error_vel_yaw: 0.5310
      Episode_Termination/time_out: 0.8196
  Episode_Termination/base_contact: 0.1806
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 2.51s
                      Time elapsed: 00:19:09
                               ETA: 00:01:15

################################################################################
                      [1m Learning iteration 470/500 [0m                      

                       Computation: 39030 steps/s (collection: 2.373s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0127
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 11.5283
                       Mean reward: 10.95
               Mean episode length: 893.64
Episode_Reward/track_lin_vel_xy_exp: 0.6590
Episode_Reward/track_ang_vel_z_exp: 0.3187
       Episode_Reward/lin_vel_z_l2: -0.0341
      Episode_Reward/ang_vel_xy_l2: -0.0898
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1353
     Episode_Reward/action_rate_l2: -0.1198
      Episode_Reward/feet_air_time: -0.0158
Episode_Reward/flat_orientation_l2: -0.0422
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.8628
Metrics/base_velocity/error_vel_xy: 0.4722
Metrics/base_velocity/error_vel_yaw: 0.4807
      Episode_Termination/time_out: 0.8205
  Episode_Termination/base_contact: 0.1797
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 2.52s
                      Time elapsed: 00:19:11
                               ETA: 00:01:13

################################################################################
                      [1m Learning iteration 471/500 [0m                      

                       Computation: 39137 steps/s (collection: 2.368s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0130
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 11.5232
                       Mean reward: 9.49
               Mean episode length: 870.69
Episode_Reward/track_lin_vel_xy_exp: 0.6228
Episode_Reward/track_ang_vel_z_exp: 0.3096
       Episode_Reward/lin_vel_z_l2: -0.0380
      Episode_Reward/ang_vel_xy_l2: -0.0906
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1477
     Episode_Reward/action_rate_l2: -0.1208
      Episode_Reward/feet_air_time: -0.0149
Episode_Reward/flat_orientation_l2: -0.0412
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.8726
Metrics/base_velocity/error_vel_xy: 0.5235
Metrics/base_velocity/error_vel_yaw: 0.4847
      Episode_Termination/time_out: 0.8217
  Episode_Termination/base_contact: 0.1785
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 2.51s
                      Time elapsed: 00:19:14
                               ETA: 00:01:10

################################################################################
                      [1m Learning iteration 472/500 [0m                      

                       Computation: 38807 steps/s (collection: 2.390s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0135
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 11.5350
                       Mean reward: 10.67
               Mean episode length: 915.50
Episode_Reward/track_lin_vel_xy_exp: 0.6938
Episode_Reward/track_ang_vel_z_exp: 0.3367
       Episode_Reward/lin_vel_z_l2: -0.0372
      Episode_Reward/ang_vel_xy_l2: -0.0952
     Episode_Reward/dof_torques_l2: -0.0043
         Episode_Reward/dof_acc_l2: -0.1519
     Episode_Reward/action_rate_l2: -0.1289
      Episode_Reward/feet_air_time: -0.0165
Episode_Reward/flat_orientation_l2: -0.0474
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.8842
Metrics/base_velocity/error_vel_xy: 0.5079
Metrics/base_velocity/error_vel_yaw: 0.5160
      Episode_Termination/time_out: 0.8221
  Episode_Termination/base_contact: 0.1782
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 2.53s
                      Time elapsed: 00:19:16
                               ETA: 00:01:08

################################################################################
                      [1m Learning iteration 473/500 [0m                      

                       Computation: 39244 steps/s (collection: 2.362s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0140
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 11.5347
                       Mean reward: 9.98
               Mean episode length: 901.18
Episode_Reward/track_lin_vel_xy_exp: 0.6234
Episode_Reward/track_ang_vel_z_exp: 0.3171
       Episode_Reward/lin_vel_z_l2: -0.0350
      Episode_Reward/ang_vel_xy_l2: -0.0921
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1370
     Episode_Reward/action_rate_l2: -0.1224
      Episode_Reward/feet_air_time: -0.0165
Episode_Reward/flat_orientation_l2: -0.0407
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.8925
Metrics/base_velocity/error_vel_xy: 0.5791
Metrics/base_velocity/error_vel_yaw: 0.5313
      Episode_Termination/time_out: 0.8223
  Episode_Termination/base_contact: 0.1779
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 2.50s
                      Time elapsed: 00:19:19
                               ETA: 00:01:06

################################################################################
                      [1m Learning iteration 474/500 [0m                      

                       Computation: 38867 steps/s (collection: 2.386s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0134
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 11.5338
                       Mean reward: 10.20
               Mean episode length: 907.86
Episode_Reward/track_lin_vel_xy_exp: 0.6343
Episode_Reward/track_ang_vel_z_exp: 0.3220
       Episode_Reward/lin_vel_z_l2: -0.0360
      Episode_Reward/ang_vel_xy_l2: -0.0926
     Episode_Reward/dof_torques_l2: -0.0043
         Episode_Reward/dof_acc_l2: -0.1414
     Episode_Reward/action_rate_l2: -0.1247
      Episode_Reward/feet_air_time: -0.0168
Episode_Reward/flat_orientation_l2: -0.0409
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.9035
Metrics/base_velocity/error_vel_xy: 0.5787
Metrics/base_velocity/error_vel_yaw: 0.5399
      Episode_Termination/time_out: 0.8231
  Episode_Termination/base_contact: 0.1771
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 2.53s
                      Time elapsed: 00:19:22
                               ETA: 00:01:03

################################################################################
                      [1m Learning iteration 475/500 [0m                      

                       Computation: 39125 steps/s (collection: 2.369s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0148
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 11.5460
                       Mean reward: 10.49
               Mean episode length: 882.16
Episode_Reward/track_lin_vel_xy_exp: 0.6248
Episode_Reward/track_ang_vel_z_exp: 0.3153
       Episode_Reward/lin_vel_z_l2: -0.0351
      Episode_Reward/ang_vel_xy_l2: -0.0899
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1373
     Episode_Reward/action_rate_l2: -0.1200
      Episode_Reward/feet_air_time: -0.0155
Episode_Reward/flat_orientation_l2: -0.0440
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.9176
Metrics/base_velocity/error_vel_xy: 0.5392
Metrics/base_velocity/error_vel_yaw: 0.4922
      Episode_Termination/time_out: 0.8246
  Episode_Termination/base_contact: 0.1757
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 2.51s
                      Time elapsed: 00:19:24
                               ETA: 00:01:01

################################################################################
                      [1m Learning iteration 476/500 [0m                      

                       Computation: 39196 steps/s (collection: 2.362s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0133
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 11.5607
                       Mean reward: 9.08
               Mean episode length: 871.34
Episode_Reward/track_lin_vel_xy_exp: 0.6175
Episode_Reward/track_ang_vel_z_exp: 0.3126
       Episode_Reward/lin_vel_z_l2: -0.0351
      Episode_Reward/ang_vel_xy_l2: -0.0904
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1484
     Episode_Reward/action_rate_l2: -0.1214
      Episode_Reward/feet_air_time: -0.0158
Episode_Reward/flat_orientation_l2: -0.0422
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.9309
Metrics/base_velocity/error_vel_xy: 0.5563
Metrics/base_velocity/error_vel_yaw: 0.5014
      Episode_Termination/time_out: 0.8260
  Episode_Termination/base_contact: 0.1742
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 2.51s
                      Time elapsed: 00:19:27
                               ETA: 00:00:58

################################################################################
                      [1m Learning iteration 477/500 [0m                      

                       Computation: 38938 steps/s (collection: 2.380s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0151
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 11.5533
                       Mean reward: 9.10
               Mean episode length: 902.11
Episode_Reward/track_lin_vel_xy_exp: 0.5719
Episode_Reward/track_ang_vel_z_exp: 0.3084
       Episode_Reward/lin_vel_z_l2: -0.0357
      Episode_Reward/ang_vel_xy_l2: -0.0919
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1330
     Episode_Reward/action_rate_l2: -0.1191
      Episode_Reward/feet_air_time: -0.0158
Episode_Reward/flat_orientation_l2: -0.0573
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.9403
Metrics/base_velocity/error_vel_xy: 0.6284
Metrics/base_velocity/error_vel_yaw: 0.5150
      Episode_Termination/time_out: 0.8256
  Episode_Termination/base_contact: 0.1747
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 2.52s
                      Time elapsed: 00:19:29
                               ETA: 00:00:56

################################################################################
                      [1m Learning iteration 478/500 [0m                      

                       Computation: 39084 steps/s (collection: 2.370s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0147
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 11.5599
                       Mean reward: 10.38
               Mean episode length: 898.46
Episode_Reward/track_lin_vel_xy_exp: 0.6560
Episode_Reward/track_ang_vel_z_exp: 0.3296
       Episode_Reward/lin_vel_z_l2: -0.0357
      Episode_Reward/ang_vel_xy_l2: -0.0927
     Episode_Reward/dof_torques_l2: -0.0043
         Episode_Reward/dof_acc_l2: -0.1391
     Episode_Reward/action_rate_l2: -0.1253
      Episode_Reward/feet_air_time: -0.0161
Episode_Reward/flat_orientation_l2: -0.0412
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.9528
Metrics/base_velocity/error_vel_xy: 0.5487
Metrics/base_velocity/error_vel_yaw: 0.5004
      Episode_Termination/time_out: 0.8258
  Episode_Termination/base_contact: 0.1744
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 2.52s
                      Time elapsed: 00:19:32
                               ETA: 00:00:53

################################################################################
                      [1m Learning iteration 479/500 [0m                      

                       Computation: 39113 steps/s (collection: 2.368s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0128
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 11.5551
                       Mean reward: 9.82
               Mean episode length: 848.47
Episode_Reward/track_lin_vel_xy_exp: 0.6164
Episode_Reward/track_ang_vel_z_exp: 0.3050
       Episode_Reward/lin_vel_z_l2: -0.0335
      Episode_Reward/ang_vel_xy_l2: -0.0882
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1339
     Episode_Reward/action_rate_l2: -0.1174
      Episode_Reward/feet_air_time: -0.0159
Episode_Reward/flat_orientation_l2: -0.0403
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.9629
Metrics/base_velocity/error_vel_xy: 0.5046
Metrics/base_velocity/error_vel_yaw: 0.4917
      Episode_Termination/time_out: 0.8249
  Episode_Termination/base_contact: 0.1753
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 2.51s
                      Time elapsed: 00:19:34
                               ETA: 00:00:51

################################################################################
                      [1m Learning iteration 480/500 [0m                      

                       Computation: 38885 steps/s (collection: 2.384s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0127
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 11.5652
                       Mean reward: 11.19
               Mean episode length: 910.01
Episode_Reward/track_lin_vel_xy_exp: 0.6810
Episode_Reward/track_ang_vel_z_exp: 0.3318
       Episode_Reward/lin_vel_z_l2: -0.0363
      Episode_Reward/ang_vel_xy_l2: -0.0927
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1487
     Episode_Reward/action_rate_l2: -0.1258
      Episode_Reward/feet_air_time: -0.0168
Episode_Reward/flat_orientation_l2: -0.0399
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.9681
Metrics/base_velocity/error_vel_xy: 0.4968
Metrics/base_velocity/error_vel_yaw: 0.4954
      Episode_Termination/time_out: 0.8222
  Episode_Termination/base_contact: 0.1780
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 2.53s
                      Time elapsed: 00:19:37
                               ETA: 00:00:48

################################################################################
                      [1m Learning iteration 481/500 [0m                      

                       Computation: 38807 steps/s (collection: 2.390s, learning 0.143s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0130
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 11.5732
                       Mean reward: 10.78
               Mean episode length: 918.86
Episode_Reward/track_lin_vel_xy_exp: 0.6546
Episode_Reward/track_ang_vel_z_exp: 0.3267
       Episode_Reward/lin_vel_z_l2: -0.0374
      Episode_Reward/ang_vel_xy_l2: -0.0952
     Episode_Reward/dof_torques_l2: -0.0043
         Episode_Reward/dof_acc_l2: -0.1434
     Episode_Reward/action_rate_l2: -0.1264
      Episode_Reward/feet_air_time: -0.0170
Episode_Reward/flat_orientation_l2: -0.0452
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.9807
Metrics/base_velocity/error_vel_xy: 0.5725
Metrics/base_velocity/error_vel_yaw: 0.5453
      Episode_Termination/time_out: 0.8225
  Episode_Termination/base_contact: 0.1777
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 2.53s
                      Time elapsed: 00:19:39
                               ETA: 00:00:46

################################################################################
                      [1m Learning iteration 482/500 [0m                      

                       Computation: 39143 steps/s (collection: 2.368s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0130
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 11.5700
                       Mean reward: 11.07
               Mean episode length: 901.24
Episode_Reward/track_lin_vel_xy_exp: 0.6666
Episode_Reward/track_ang_vel_z_exp: 0.3269
       Episode_Reward/lin_vel_z_l2: -0.0364
      Episode_Reward/ang_vel_xy_l2: -0.0927
     Episode_Reward/dof_torques_l2: -0.0043
         Episode_Reward/dof_acc_l2: -0.1398
     Episode_Reward/action_rate_l2: -0.1248
      Episode_Reward/feet_air_time: -0.0168
Episode_Reward/flat_orientation_l2: -0.0395
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.9884
Metrics/base_velocity/error_vel_xy: 0.5140
Metrics/base_velocity/error_vel_yaw: 0.5003
      Episode_Termination/time_out: 0.8214
  Episode_Termination/base_contact: 0.1788
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 2.51s
                      Time elapsed: 00:19:42
                               ETA: 00:00:44

################################################################################
                      [1m Learning iteration 483/500 [0m                      

                       Computation: 38861 steps/s (collection: 2.385s, learning 0.145s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0131
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 11.5803
                       Mean reward: 9.81
               Mean episode length: 885.06
Episode_Reward/track_lin_vel_xy_exp: 0.6383
Episode_Reward/track_ang_vel_z_exp: 0.3263
       Episode_Reward/lin_vel_z_l2: -0.0350
      Episode_Reward/ang_vel_xy_l2: -0.0943
     Episode_Reward/dof_torques_l2: -0.0044
         Episode_Reward/dof_acc_l2: -0.1472
     Episode_Reward/action_rate_l2: -0.1255
      Episode_Reward/feet_air_time: -0.0165
Episode_Reward/flat_orientation_l2: -0.0446
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 2.9997
Metrics/base_velocity/error_vel_xy: 0.5737
Metrics/base_velocity/error_vel_yaw: 0.5180
      Episode_Termination/time_out: 0.8228
  Episode_Termination/base_contact: 0.1775
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 2.53s
                      Time elapsed: 00:19:44
                               ETA: 00:00:41

################################################################################
                      [1m Learning iteration 484/500 [0m                      

                       Computation: 38855 steps/s (collection: 2.385s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0135
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 11.5746
                       Mean reward: 9.70
               Mean episode length: 848.63
Episode_Reward/track_lin_vel_xy_exp: 0.6191
Episode_Reward/track_ang_vel_z_exp: 0.3067
       Episode_Reward/lin_vel_z_l2: -0.0335
      Episode_Reward/ang_vel_xy_l2: -0.0879
     Episode_Reward/dof_torques_l2: -0.0040
         Episode_Reward/dof_acc_l2: -0.1339
     Episode_Reward/action_rate_l2: -0.1183
      Episode_Reward/feet_air_time: -0.0156
Episode_Reward/flat_orientation_l2: -0.0423
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.0065
Metrics/base_velocity/error_vel_xy: 0.4985
Metrics/base_velocity/error_vel_yaw: 0.4836
      Episode_Termination/time_out: 0.8241
  Episode_Termination/base_contact: 0.1761
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 2.53s
                      Time elapsed: 00:19:47
                               ETA: 00:00:39

################################################################################
                      [1m Learning iteration 485/500 [0m                      

                       Computation: 39180 steps/s (collection: 2.364s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0130
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 11.5693
                       Mean reward: 11.16
               Mean episode length: 892.69
Episode_Reward/track_lin_vel_xy_exp: 0.6371
Episode_Reward/track_ang_vel_z_exp: 0.3024
       Episode_Reward/lin_vel_z_l2: -0.0310
      Episode_Reward/ang_vel_xy_l2: -0.0839
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1306
     Episode_Reward/action_rate_l2: -0.1140
      Episode_Reward/feet_air_time: -0.0151
Episode_Reward/flat_orientation_l2: -0.0321
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.0143
Metrics/base_velocity/error_vel_xy: 0.4177
Metrics/base_velocity/error_vel_yaw: 0.4451
      Episode_Termination/time_out: 0.8232
  Episode_Termination/base_contact: 0.1770
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 2.51s
                      Time elapsed: 00:19:49
                               ETA: 00:00:36

################################################################################
                      [1m Learning iteration 486/500 [0m                      

                       Computation: 39066 steps/s (collection: 2.372s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0141
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 11.5687
                       Mean reward: 10.31
               Mean episode length: 880.69
Episode_Reward/track_lin_vel_xy_exp: 0.6229
Episode_Reward/track_ang_vel_z_exp: 0.3110
       Episode_Reward/lin_vel_z_l2: -0.0337
      Episode_Reward/ang_vel_xy_l2: -0.0900
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1368
     Episode_Reward/action_rate_l2: -0.1173
      Episode_Reward/feet_air_time: -0.0158
Episode_Reward/flat_orientation_l2: -0.0377
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.0241
Metrics/base_velocity/error_vel_xy: 0.5025
Metrics/base_velocity/error_vel_yaw: 0.4698
      Episode_Termination/time_out: 0.8233
  Episode_Termination/base_contact: 0.1769
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 2.52s
                      Time elapsed: 00:19:52
                               ETA: 00:00:34

################################################################################
                      [1m Learning iteration 487/500 [0m                      

                       Computation: 38789 steps/s (collection: 2.390s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0141
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 11.5821
                       Mean reward: 11.24
               Mean episode length: 910.16
Episode_Reward/track_lin_vel_xy_exp: 0.6992
Episode_Reward/track_ang_vel_z_exp: 0.3333
       Episode_Reward/lin_vel_z_l2: -0.0361
      Episode_Reward/ang_vel_xy_l2: -0.0958
     Episode_Reward/dof_torques_l2: -0.0043
         Episode_Reward/dof_acc_l2: -0.1640
     Episode_Reward/action_rate_l2: -0.1285
      Episode_Reward/feet_air_time: -0.0167
Episode_Reward/flat_orientation_l2: -0.0399
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.0344
Metrics/base_velocity/error_vel_xy: 0.4903
Metrics/base_velocity/error_vel_yaw: 0.5118
      Episode_Termination/time_out: 0.8243
  Episode_Termination/base_contact: 0.1760
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 2.53s
                      Time elapsed: 00:19:54
                               ETA: 00:00:31

################################################################################
                      [1m Learning iteration 488/500 [0m                      

                       Computation: 38747 steps/s (collection: 2.393s, learning 0.144s)
             Mean action noise std: 0.65
          Mean value_function loss: 0.0144
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 11.5810
                       Mean reward: 10.61
               Mean episode length: 906.09
Episode_Reward/track_lin_vel_xy_exp: 0.6616
Episode_Reward/track_ang_vel_z_exp: 0.3221
       Episode_Reward/lin_vel_z_l2: -0.0367
      Episode_Reward/ang_vel_xy_l2: -0.0932
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1489
     Episode_Reward/action_rate_l2: -0.1234
      Episode_Reward/feet_air_time: -0.0166
Episode_Reward/flat_orientation_l2: -0.0409
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.0474
Metrics/base_velocity/error_vel_xy: 0.5017
Metrics/base_velocity/error_vel_yaw: 0.4972
      Episode_Termination/time_out: 0.8245
  Episode_Termination/base_contact: 0.1757
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 2.54s
                      Time elapsed: 00:19:57
                               ETA: 00:00:29

################################################################################
                      [1m Learning iteration 489/500 [0m                      

                       Computation: 38683 steps/s (collection: 2.394s, learning 0.147s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0132
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 11.5803
                       Mean reward: 10.56
               Mean episode length: 891.41
Episode_Reward/track_lin_vel_xy_exp: 0.6610
Episode_Reward/track_ang_vel_z_exp: 0.3253
       Episode_Reward/lin_vel_z_l2: -0.0348
      Episode_Reward/ang_vel_xy_l2: -0.0919
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1354
     Episode_Reward/action_rate_l2: -0.1231
      Episode_Reward/feet_air_time: -0.0165
Episode_Reward/flat_orientation_l2: -0.0395
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.0592
Metrics/base_velocity/error_vel_xy: 0.5060
Metrics/base_velocity/error_vel_yaw: 0.4937
      Episode_Termination/time_out: 0.8268
  Episode_Termination/base_contact: 0.1732
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 2.54s
                      Time elapsed: 00:19:59
                               ETA: 00:00:26

################################################################################
                      [1m Learning iteration 490/500 [0m                      

                       Computation: 38819 steps/s (collection: 2.389s, learning 0.144s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0125
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 11.5687
                       Mean reward: 10.48
               Mean episode length: 894.32
Episode_Reward/track_lin_vel_xy_exp: 0.6630
Episode_Reward/track_ang_vel_z_exp: 0.3211
       Episode_Reward/lin_vel_z_l2: -0.0360
      Episode_Reward/ang_vel_xy_l2: -0.0926
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1470
     Episode_Reward/action_rate_l2: -0.1250
      Episode_Reward/feet_air_time: -0.0162
Episode_Reward/flat_orientation_l2: -0.0392
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.0687
Metrics/base_velocity/error_vel_xy: 0.5015
Metrics/base_velocity/error_vel_yaw: 0.5093
      Episode_Termination/time_out: 0.8268
  Episode_Termination/base_contact: 0.1732
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 2.53s
                      Time elapsed: 00:20:02
                               ETA: 00:00:24

################################################################################
                      [1m Learning iteration 491/500 [0m                      

                       Computation: 38707 steps/s (collection: 2.394s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0133
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 11.5512
                       Mean reward: 10.65
               Mean episode length: 890.58
Episode_Reward/track_lin_vel_xy_exp: 0.6548
Episode_Reward/track_ang_vel_z_exp: 0.3199
       Episode_Reward/lin_vel_z_l2: -0.0336
      Episode_Reward/ang_vel_xy_l2: -0.0896
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1319
     Episode_Reward/action_rate_l2: -0.1203
      Episode_Reward/feet_air_time: -0.0159
Episode_Reward/flat_orientation_l2: -0.0407
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.0811
Metrics/base_velocity/error_vel_xy: 0.4896
Metrics/base_velocity/error_vel_yaw: 0.4946
      Episode_Termination/time_out: 0.8265
  Episode_Termination/base_contact: 0.1735
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 2.54s
                      Time elapsed: 00:20:04
                               ETA: 00:00:22

################################################################################
                      [1m Learning iteration 492/500 [0m                      

                       Computation: 38572 steps/s (collection: 2.401s, learning 0.147s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0137
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 11.5563
                       Mean reward: 11.50
               Mean episode length: 900.50
Episode_Reward/track_lin_vel_xy_exp: 0.6911
Episode_Reward/track_ang_vel_z_exp: 0.3259
       Episode_Reward/lin_vel_z_l2: -0.0348
      Episode_Reward/ang_vel_xy_l2: -0.0918
     Episode_Reward/dof_torques_l2: -0.0041
         Episode_Reward/dof_acc_l2: -0.1380
     Episode_Reward/action_rate_l2: -0.1226
      Episode_Reward/feet_air_time: -0.0167
Episode_Reward/flat_orientation_l2: -0.0415
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.0905
Metrics/base_velocity/error_vel_xy: 0.4516
Metrics/base_velocity/error_vel_yaw: 0.4876
      Episode_Termination/time_out: 0.8257
  Episode_Termination/base_contact: 0.1743
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 2.55s
                      Time elapsed: 00:20:07
                               ETA: 00:00:19

################################################################################
                      [1m Learning iteration 493/500 [0m                      

                       Computation: 38812 steps/s (collection: 2.387s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0133
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 11.5570
                       Mean reward: 11.01
               Mean episode length: 906.42
Episode_Reward/track_lin_vel_xy_exp: 0.6746
Episode_Reward/track_ang_vel_z_exp: 0.3311
       Episode_Reward/lin_vel_z_l2: -0.0356
      Episode_Reward/ang_vel_xy_l2: -0.0956
     Episode_Reward/dof_torques_l2: -0.0044
         Episode_Reward/dof_acc_l2: -0.1447
     Episode_Reward/action_rate_l2: -0.1280
      Episode_Reward/feet_air_time: -0.0168
Episode_Reward/flat_orientation_l2: -0.0369
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.1017
Metrics/base_velocity/error_vel_xy: 0.5378
Metrics/base_velocity/error_vel_yaw: 0.5273
      Episode_Termination/time_out: 0.8257
  Episode_Termination/base_contact: 0.1743
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 2.53s
                      Time elapsed: 00:20:10
                               ETA: 00:00:17

################################################################################
                      [1m Learning iteration 494/500 [0m                      

                       Computation: 39195 steps/s (collection: 2.362s, learning 0.146s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0131
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 11.5477
                       Mean reward: 10.51
               Mean episode length: 885.82
Episode_Reward/track_lin_vel_xy_exp: 0.6554
Episode_Reward/track_ang_vel_z_exp: 0.3220
       Episode_Reward/lin_vel_z_l2: -0.0359
      Episode_Reward/ang_vel_xy_l2: -0.0914
     Episode_Reward/dof_torques_l2: -0.0042
         Episode_Reward/dof_acc_l2: -0.1430
     Episode_Reward/action_rate_l2: -0.1249
      Episode_Reward/feet_air_time: -0.0166
Episode_Reward/flat_orientation_l2: -0.0350
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.1149
Metrics/base_velocity/error_vel_xy: 0.5109
Metrics/base_velocity/error_vel_yaw: 0.4911
      Episode_Termination/time_out: 0.8254
  Episode_Termination/base_contact: 0.1746
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 2.51s
                      Time elapsed: 00:20:12
                               ETA: 00:00:14

################################################################################
                      [1m Learning iteration 495/500 [0m                      

                       Computation: 38919 steps/s (collection: 2.381s, learning 0.145s)
             Mean action noise std: 0.64
          Mean value_function loss: 0.0127
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 11.5613
                       Mean reward: 8.96
               Mean episode length: 880.62
Episode_Reward/track_lin_vel_xy_exp: 0.5632
Episode_Reward/track_ang_vel_z_exp: 0.2890
       Episode_Reward/lin_vel_z_l2: -0.0340
      Episode_Reward/ang_vel_xy_l2: -0.0867
     Episode_Reward/dof_torques_l2: -0.0039
         Episode_Reward/dof_acc_l2: -0.1444
     Episode_Reward/action_rate_l2: -0.1131
      Episode_Reward/feet_air_time: -0.0147
Episode_Reward/flat_orientation_l2: -0.0508
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.1248
Metrics/base_velocity/error_vel_xy: 0.5304
Metrics/base_velocity/error_vel_yaw: 0.4727
      Episode_Termination/time_out: 0.8253
  Episode_Termination/base_contact: 0.1747
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 2.53s
                      Time elapsed: 00:20:15
                               ETA: 00:00:12
rce/plugins/carb.cudainterop/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest.cu:681: 'peer access is already enabled'
2025-11-17T01:18:08Z [18,098ms] [Warning] [omni.physx.fabric.plugin] FabricManager::initializePointInstancer mismatched prototypes on point instancer: /Visuals/Command/velocity_goal.
2025-11-17T01:18:08Z [18,098ms] [Warning] [omni.physx.fabric.plugin] FabricManager::initializePointInstancer mismatched prototypes on point instancer: /Visuals/Command/velocity_current.

[0;32mTraining completed![0m
Logs saved to: [0;34mlogs/rsl_rl/[0m
